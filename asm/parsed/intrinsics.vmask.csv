Sequence  | Address         | Length  | TermCode            | Uri                                                                                                           | OpSig                                                                                                         | Data
0         | 7ff7c85f5ea0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?veven#veven_g[8u](n128,n2,n1,8u)                                                       | Vector128<byte> veven<byte>(N128 w, N2 f, N1 d, byte t)                                                       | 50 c5 f8 77 90 c7 44 24 04 55 00 00 00 48 8d 44 24 04 c4 e2 79 78 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
1         | 7ff7c85f5ee0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?veven#veven_g[16u](n128,n2,n1,16u)                                                     | Vector128<ushort> veven<ushort>(N128 w, N2 f, N1 d, ushort t)                                                 | 50 c5 f8 77 90 c7 44 24 04 55 55 00 00 48 8d 44 24 04 c4 e2 79 79 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
2         | 7ff7c85f5f20h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?veven#veven_g[32u](n128,n2,n1,32u)                                                     | Vector128<uint> veven<uint>(N128 w, N2 f, N1 d, uint t)                                                       | 50 c5 f8 77 90 c7 44 24 04 55 55 55 55 48 8d 44 24 04 c4 e2 79 58 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
3         | 7ff7c85f5f60h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?veven#veven_g[64u](n128,n2,n1,64u)                                                     | Vector128<ulong> veven<ulong>(N128 w, N2 f, N1 d, ulong t)                                                    | 50 c5 f8 77 90 48 b8 55 55 55 55 55 55 55 55 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
4         | 7ff7c85f5fa0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?veven#veven_g[8u](n256,n2,n1,8u)                                                       | Vector256<byte> veven<byte>(N256 w, N2 f, N1 d, byte t)                                                       | 50 c5 f8 77 90 c7 44 24 04 55 00 00 00 48 8d 44 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
5         | 7ff7c85f5fe0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?veven#veven_g[16u](n256,n2,n1,16u)                                                     | Vector256<ushort> veven<ushort>(N256 w, N2 f, N1 d, ushort t)                                                 | 50 c5 f8 77 90 c7 44 24 04 55 55 00 00 48 8d 44 24 04 c4 e2 7d 79 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
6         | 7ff7c85f6020h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?veven#veven_g[32u](n256,n2,n1,32u)                                                     | Vector256<uint> veven<uint>(N256 w, N2 f, N1 d, uint t)                                                       | 50 c5 f8 77 90 c7 44 24 04 55 55 55 55 48 8d 44 24 04 c4 e2 7d 58 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
7         | 7ff7c85f6060h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?veven#veven_g[64u](n256,n2,n1,64u)                                                     | Vector256<ulong> veven<ulong>(N256 w, N2 f, N1 d, ulong t)                                                    | 50 c5 f8 77 90 48 b8 55 55 55 55 55 55 55 55 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
8         | 7ff7c85f64b0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?veven#veven_g[8u](n128,n2,n2,8u)                                                       | Vector128<byte> veven<byte>(N128 w, N2 f, N2 d, byte t)                                                       | 50 c5 f8 77 90 c7 44 24 04 33 00 00 00 48 8d 44 24 04 c4 e2 79 78 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
9         | 7ff7c85f64f0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?veven#veven_g[16u](n128,n2,n2,16u)                                                     | Vector128<ushort> veven<ushort>(N128 w, N2 f, N2 d, ushort t)                                                 | 50 c5 f8 77 90 c7 44 24 04 33 33 00 00 48 8d 44 24 04 c4 e2 79 79 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
10        | 7ff7c85f6530h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?veven#veven_g[32u](n128,n2,n2,32u)                                                     | Vector128<uint> veven<uint>(N128 w, N2 f, N2 d, uint t)                                                       | 50 c5 f8 77 90 c7 44 24 04 33 33 33 33 48 8d 44 24 04 c4 e2 79 58 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
11        | 7ff7c85f6570h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?veven#veven_g[64u](n128,n2,n2,64u)                                                     | Vector128<ulong> veven<ulong>(N128 w, N2 f, N2 d, ulong t)                                                    | 50 c5 f8 77 90 48 b8 33 33 33 33 33 33 33 33 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
12        | 7ff7c85f65b0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?veven#veven_g[8u](n256,n2,n2,8u)                                                       | Vector256<byte> veven<byte>(N256 w, N2 f, N2 d, byte t)                                                       | 50 c5 f8 77 90 c7 44 24 04 33 00 00 00 48 8d 44 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
13        | 7ff7c85f65f0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?veven#veven_g[16u](n256,n2,n2,16u)                                                     | Vector256<ushort> veven<ushort>(N256 w, N2 f, N2 d, ushort t)                                                 | 50 c5 f8 77 90 c7 44 24 04 33 33 00 00 48 8d 44 24 04 c4 e2 7d 79 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
14        | 7ff7c85f6630h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?veven#veven_g[32u](n256,n2,n2,32u)                                                     | Vector256<uint> veven<uint>(N256 w, N2 f, N2 d, uint t)                                                       | 50 c5 f8 77 90 c7 44 24 04 33 33 33 33 48 8d 44 24 04 c4 e2 7d 58 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
15        | 7ff7c85f6670h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?veven#veven_g[64u](n256,n2,n2,64u)                                                     | Vector256<ulong> veven<ulong>(N256 w, N2 f, N2 d, ulong t)                                                    | 50 c5 f8 77 90 48 b8 33 33 33 33 33 33 33 33 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
16        | 7ff7c85f66c0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[8u](n128,n1,n1,8u)                                                         | Vector128<byte> vlsb<byte>(N128 w, N1 f, N1 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 01 00 00 00 48 8d 44 24 04 c4 e2 79 78 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
17        | 7ff7c85f6700h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[16u](n128,n1,n1,16u)                                                       | Vector128<ushort> vlsb<ushort>(N128 w, N1 f, N1 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 01 00 00 00 48 8d 44 24 04 c4 e2 79 79 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
18        | 7ff7c85f6740h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[32u](n128,n1,n1,32u)                                                       | Vector128<uint> vlsb<uint>(N128 w, N1 f, N1 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 01 00 00 00 48 8d 44 24 04 c4 e2 79 58 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
19        | 7ff7c85f6780h   | 35      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[64u](n128,n1,n1,64u)                                                       | Vector128<ulong> vlsb<ulong>(N128 w, N1 f, N1 d, ulong t)                                                     | 50 c5 f8 77 90 48 c7 04 24 01 00 00 00 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
20        | 7ff7c85f67c0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[8u](n128,n2,n1,8u)                                                         | Vector128<byte> vlsb<byte>(N128 w, N2 f, N1 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 55 00 00 00 48 8d 44 24 04 c4 e2 79 78 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
21        | 7ff7c85f6800h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[16u](n128,n2,n1,16u)                                                       | Vector128<ushort> vlsb<ushort>(N128 w, N2 f, N1 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 55 55 00 00 48 8d 44 24 04 c4 e2 79 79 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
22        | 7ff7c85f6840h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[32u](n128,n2,n1,32u)                                                       | Vector128<uint> vlsb<uint>(N128 w, N2 f, N1 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 55 55 55 55 48 8d 44 24 04 c4 e2 79 58 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
23        | 7ff7c85f6880h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[64u](n128,n2,n1,64u)                                                       | Vector128<ulong> vlsb<ulong>(N128 w, N2 f, N1 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 55 55 55 55 55 55 55 55 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
24        | 7ff7c85f6cd0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[8u](n128,n4,n1,8u)                                                         | Vector128<byte> vlsb<byte>(N128 w, N4 f, N1 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 11 00 00 00 48 8d 44 24 04 c4 e2 79 78 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
25        | 7ff7c85f6d10h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[16u](n128,n4,n1,16u)                                                       | Vector128<ushort> vlsb<ushort>(N128 w, N4 f, N1 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 11 11 00 00 48 8d 44 24 04 c4 e2 79 79 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
26        | 7ff7c85f6d50h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[32u](n128,n4,n1,32u)                                                       | Vector128<uint> vlsb<uint>(N128 w, N4 f, N1 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 11 11 11 11 48 8d 44 24 04 c4 e2 79 58 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
27        | 7ff7c85f6d90h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[64u](n128,n4,n1,64u)                                                       | Vector128<ulong> vlsb<ulong>(N128 w, N4 f, N1 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 11 11 11 11 11 11 11 11 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
28        | 7ff7c85f6dd0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[8u](n128,n8,n1,8u)                                                         | Vector128<byte> vlsb<byte>(N128 w, N8 f, N1 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 01 00 00 00 48 8d 44 24 04 c4 e2 79 78 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
29        | 7ff7c85f6e10h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[16u](n128,n8,n1,16u)                                                       | Vector128<ushort> vlsb<ushort>(N128 w, N8 f, N1 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 01 01 00 00 48 8d 44 24 04 c4 e2 79 79 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
30        | 7ff7c85f6e50h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[32u](n128,n8,n1,32u)                                                       | Vector128<uint> vlsb<uint>(N128 w, N8 f, N1 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 01 01 01 01 48 8d 44 24 04 c4 e2 79 58 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
31        | 7ff7c85f6e90h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[64u](n128,n8,n1,64u)                                                       | Vector128<ulong> vlsb<ulong>(N128 w, N8 f, N1 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 01 01 01 01 01 01 01 01 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
32        | 7ff7c85f6ed0h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[8u](n128,n16,n1,8u)                                                        | Vector128<byte> vlsb<byte>(N128 w, N16 f, N1 d, byte t)                                                       | 50 c5 f8 77 90 48 b8 01 00 01 00 01 00 01 00 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
33        | 7ff7c85f6f10h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[16u](n128,n16,n1,16u)                                                      | Vector128<ushort> vlsb<ushort>(N128 w, N16 f, N1 d, ushort t)                                                 | 50 c5 f8 77 90 48 b8 01 00 01 00 01 00 01 00 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
34        | 7ff7c85f6f50h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[32u](n128,n16,n1,32u)                                                      | Vector128<uint> vlsb<uint>(N128 w, N16 f, N1 d, uint t)                                                       | 50 c5 f8 77 90 48 b8 01 00 01 00 01 00 01 00 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
35        | 7ff7c85f6f90h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[64u](n128,n16,n1,64u)                                                      | Vector128<ulong> vlsb<ulong>(N128 w, N16 f, N1 d, ulong t)                                                    | 50 c5 f8 77 90 48 b8 01 00 01 00 01 00 01 00 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
36        | 7ff7c85f6fd0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[8u](n128,n8,n2,8u)                                                         | Vector128<byte> vlsb<byte>(N128 w, N8 f, N2 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 03 00 00 00 48 8d 44 24 04 c4 e2 79 78 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
37        | 7ff7c85f7010h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[16u](n128,n8,n2,16u)                                                       | Vector128<ushort> vlsb<ushort>(N128 w, N8 f, N2 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 03 03 00 00 48 8d 44 24 04 c4 e2 79 79 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
38        | 7ff7c85f7050h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[32u](n128,n8,n2,32u)                                                       | Vector128<uint> vlsb<uint>(N128 w, N8 f, N2 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 03 03 03 03 48 8d 44 24 04 c4 e2 79 58 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
39        | 7ff7c85f7090h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[64u](n128,n8,n2,64u)                                                       | Vector128<ulong> vlsb<ulong>(N128 w, N8 f, N2 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 03 03 03 03 03 03 03 03 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
40        | 7ff7c85f70d0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[8u](n128,n8,n3,8u)                                                         | Vector128<byte> vlsb<byte>(N128 w, N8 f, N3 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 07 00 00 00 48 8d 44 24 04 c4 e2 79 78 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
41        | 7ff7c85f7110h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[16u](n128,n8,n3,16u)                                                       | Vector128<ushort> vlsb<ushort>(N128 w, N8 f, N3 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 07 07 00 00 48 8d 44 24 04 c4 e2 79 79 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
42        | 7ff7c85f7150h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[32u](n128,n8,n3,32u)                                                       | Vector128<uint> vlsb<uint>(N128 w, N8 f, N3 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 07 07 07 07 48 8d 44 24 04 c4 e2 79 58 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
43        | 7ff7c85f7190h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[64u](n128,n8,n3,64u)                                                       | Vector128<ulong> vlsb<ulong>(N128 w, N8 f, N3 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 07 07 07 07 07 07 07 07 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
44        | 7ff7c85f75e0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[8u](n128,n8,n4,8u)                                                         | Vector128<byte> vlsb<byte>(N128 w, N8 f, N4 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 0f 00 00 00 48 8d 44 24 04 c4 e2 79 78 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
45        | 7ff7c85f7620h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[16u](n128,n8,n4,16u)                                                       | Vector128<ushort> vlsb<ushort>(N128 w, N8 f, N4 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 0f 0f 00 00 48 8d 44 24 04 c4 e2 79 79 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
46        | 7ff7c85f7660h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[32u](n128,n8,n4,32u)                                                       | Vector128<uint> vlsb<uint>(N128 w, N8 f, N4 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 0f 0f 0f 0f 48 8d 44 24 04 c4 e2 79 58 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
47        | 7ff7c85f76a0h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[64u](n128,n8,n4,64u)                                                       | Vector128<ulong> vlsb<ulong>(N128 w, N8 f, N4 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 0f 0f 0f 0f 0f 0f 0f 0f 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
48        | 7ff7c85f76e0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[8u](n128,n8,n5,8u)                                                         | Vector128<byte> vlsb<byte>(N128 w, N8 f, N5 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 1f 00 00 00 48 8d 44 24 04 c4 e2 79 78 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
49        | 7ff7c85f7720h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[16u](n128,n8,n5,16u)                                                       | Vector128<ushort> vlsb<ushort>(N128 w, N8 f, N5 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 1f 1f 00 00 48 8d 44 24 04 c4 e2 79 79 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
50        | 7ff7c85f7760h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[32u](n128,n8,n5,32u)                                                       | Vector128<uint> vlsb<uint>(N128 w, N8 f, N5 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 1f 1f 1f 1f 48 8d 44 24 04 c4 e2 79 58 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
51        | 7ff7c85f77a0h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[64u](n128,n8,n5,64u)                                                       | Vector128<ulong> vlsb<ulong>(N128 w, N8 f, N5 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 1f 1f 1f 1f 1f 1f 1f 1f 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
52        | 7ff7c85f77e0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[8u](n128,n8,n6,8u)                                                         | Vector128<byte> vlsb<byte>(N128 w, N8 f, N6 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 3f 00 00 00 48 8d 44 24 04 c4 e2 79 78 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
53        | 7ff7c85f7820h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[16u](n128,n8,n6,16u)                                                       | Vector128<ushort> vlsb<ushort>(N128 w, N8 f, N6 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 3f 3f 00 00 48 8d 44 24 04 c4 e2 79 79 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
54        | 7ff7c85f7860h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[32u](n128,n8,n6,32u)                                                       | Vector128<uint> vlsb<uint>(N128 w, N8 f, N6 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 3f 3f 3f 3f 48 8d 44 24 04 c4 e2 79 58 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
55        | 7ff7c85f78a0h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[64u](n128,n8,n6,64u)                                                       | Vector128<ulong> vlsb<ulong>(N128 w, N8 f, N6 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 3f 3f 3f 3f 3f 3f 3f 3f 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
56        | 7ff7c85f78e0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[8u](n128,n8,n7,8u)                                                         | Vector128<byte> vlsb<byte>(N128 w, N8 f, N7 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 7f 00 00 00 48 8d 44 24 04 c4 e2 79 78 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
57        | 7ff7c85f7920h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[16u](n128,n8,n7,16u)                                                       | Vector128<ushort> vlsb<ushort>(N128 w, N8 f, N7 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 7f 7f 00 00 48 8d 44 24 04 c4 e2 79 79 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
58        | 7ff7c85f7960h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[32u](n128,n8,n7,32u)                                                       | Vector128<uint> vlsb<uint>(N128 w, N8 f, N7 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 7f 7f 7f 7f 48 8d 44 24 04 c4 e2 79 58 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
59        | 7ff7c85f79a0h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[64u](n128,n8,n7,64u)                                                       | Vector128<ulong> vlsb<ulong>(N128 w, N8 f, N7 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 7f 7f 7f 7f 7f 7f 7f 7f 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
60        | 7ff7c85f79e0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[8u](n256,n1,n1,8u)                                                         | Vector256<byte> vlsb<byte>(N256 w, N1 f, N1 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 01 00 00 00 48 8d 44 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
61        | 7ff7c85f7a20h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[16u](n256,n1,n1,16u)                                                       | Vector256<ushort> vlsb<ushort>(N256 w, N1 f, N1 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 01 00 00 00 48 8d 44 24 04 c4 e2 7d 79 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
62        | 7ff7c85f7e70h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[32u](n256,n1,n1,32u)                                                       | Vector256<uint> vlsb<uint>(N256 w, N1 f, N1 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 01 00 00 00 48 8d 44 24 04 c4 e2 7d 58 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
63        | 7ff7c85f7eb0h   | 38      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[64u](n256,n1,n1,64u)                                                       | Vector256<ulong> vlsb<ulong>(N256 w, N1 f, N1 d, ulong t)                                                     | 50 c5 f8 77 90 48 c7 04 24 01 00 00 00 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
64        | 7ff7c85f7ef0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[8u](n256,n2,n1,8u)                                                         | Vector256<byte> vlsb<byte>(N256 w, N2 f, N1 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 55 00 00 00 48 8d 44 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
65        | 7ff7c85f7f30h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[16u](n256,n2,n1,16u)                                                       | Vector256<ushort> vlsb<ushort>(N256 w, N2 f, N1 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 55 55 00 00 48 8d 44 24 04 c4 e2 7d 79 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
66        | 7ff7c85f7f70h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[32u](n256,n2,n1,32u)                                                       | Vector256<uint> vlsb<uint>(N256 w, N2 f, N1 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 55 55 55 55 48 8d 44 24 04 c4 e2 7d 58 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
67        | 7ff7c85f7fb0h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[64u](n256,n2,n1,64u)                                                       | Vector256<ulong> vlsb<ulong>(N256 w, N2 f, N1 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 55 55 55 55 55 55 55 55 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
68        | 7ff7c85f8000h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[8u](n256,n4,n1,8u)                                                         | Vector256<byte> vlsb<byte>(N256 w, N4 f, N1 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 11 00 00 00 48 8d 44 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
69        | 7ff7c85f8040h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[16u](n256,n4,n1,16u)                                                       | Vector256<ushort> vlsb<ushort>(N256 w, N4 f, N1 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 11 11 00 00 48 8d 44 24 04 c4 e2 7d 79 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
70        | 7ff7c85f8080h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[32u](n256,n4,n1,32u)                                                       | Vector256<uint> vlsb<uint>(N256 w, N4 f, N1 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 11 11 11 11 48 8d 44 24 04 c4 e2 7d 58 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
71        | 7ff7c85f80c0h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[64u](n256,n4,n1,64u)                                                       | Vector256<ulong> vlsb<ulong>(N256 w, N4 f, N1 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 11 11 11 11 11 11 11 11 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
72        | 7ff7c85f8110h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[8u](n256,n8,n1,8u)                                                         | Vector256<byte> vlsb<byte>(N256 w, N8 f, N1 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 01 00 00 00 48 8d 44 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
73        | 7ff7c85f8150h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[16u](n256,n8,n1,16u)                                                       | Vector256<ushort> vlsb<ushort>(N256 w, N8 f, N1 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 01 01 00 00 48 8d 44 24 04 c4 e2 7d 79 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
74        | 7ff7c85f8190h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[32u](n256,n8,n1,32u)                                                       | Vector256<uint> vlsb<uint>(N256 w, N8 f, N1 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 01 01 01 01 48 8d 44 24 04 c4 e2 7d 58 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
75        | 7ff7c85f81d0h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[64u](n256,n8,n1,64u)                                                       | Vector256<ulong> vlsb<ulong>(N256 w, N8 f, N1 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 01 01 01 01 01 01 01 01 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
76        | 7ff7c85f8220h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[8u](n256,n16,n1,8u)                                                        | Vector256<byte> vlsb<byte>(N256 w, N16 f, N1 d, byte t)                                                       | 50 c5 f8 77 90 48 b8 01 00 01 00 01 00 01 00 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
77        | 7ff7c85f8270h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[16u](n256,n16,n1,16u)                                                      | Vector256<ushort> vlsb<ushort>(N256 w, N16 f, N1 d, ushort t)                                                 | 50 c5 f8 77 90 48 b8 01 00 01 00 01 00 01 00 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
78        | 7ff7c85f82c0h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[32u](n256,n16,n1,32u)                                                      | Vector256<uint> vlsb<uint>(N256 w, N16 f, N1 d, uint t)                                                       | 50 c5 f8 77 90 48 b8 01 00 01 00 01 00 01 00 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
79        | 7ff7c85f8310h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[64u](n256,n16,n1,64u)                                                      | Vector256<ulong> vlsb<ulong>(N256 w, N16 f, N1 d, ulong t)                                                    | 50 c5 f8 77 90 48 b8 01 00 01 00 01 00 01 00 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
80        | 7ff7c85f8760h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[8u](n256,n8,n2,8u)                                                         | Vector256<byte> vlsb<byte>(N256 w, N8 f, N2 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 03 00 00 00 48 8d 44 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
81        | 7ff7c85f87a0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[16u](n256,n8,n2,16u)                                                       | Vector256<ushort> vlsb<ushort>(N256 w, N8 f, N2 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 03 03 00 00 48 8d 44 24 04 c4 e2 7d 79 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
82        | 7ff7c85f87e0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[32u](n256,n8,n2,32u)                                                       | Vector256<uint> vlsb<uint>(N256 w, N8 f, N2 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 03 03 03 03 48 8d 44 24 04 c4 e2 7d 58 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
83        | 7ff7c85f8820h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[64u](n256,n8,n2,64u)                                                       | Vector256<ulong> vlsb<ulong>(N256 w, N8 f, N2 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 03 03 03 03 03 03 03 03 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
84        | 7ff7c85f8870h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[8u](n256,n8,n3,8u)                                                         | Vector256<byte> vlsb<byte>(N256 w, N8 f, N3 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 07 00 00 00 48 8d 44 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
85        | 7ff7c85f88b0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[16u](n256,n8,n3,16u)                                                       | Vector256<ushort> vlsb<ushort>(N256 w, N8 f, N3 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 07 07 00 00 48 8d 44 24 04 c4 e2 7d 79 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
86        | 7ff7c85f88f0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[32u](n256,n8,n3,32u)                                                       | Vector256<uint> vlsb<uint>(N256 w, N8 f, N3 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 07 07 07 07 48 8d 44 24 04 c4 e2 7d 58 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
87        | 7ff7c85f8930h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[64u](n256,n8,n3,64u)                                                       | Vector256<ulong> vlsb<ulong>(N256 w, N8 f, N3 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 07 07 07 07 07 07 07 07 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
88        | 7ff7c85f8980h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[8u](n256,n8,n4,8u)                                                         | Vector256<byte> vlsb<byte>(N256 w, N8 f, N4 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 0f 00 00 00 48 8d 44 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
89        | 7ff7c85f89c0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[16u](n256,n8,n4,16u)                                                       | Vector256<ushort> vlsb<ushort>(N256 w, N8 f, N4 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 0f 0f 00 00 48 8d 44 24 04 c4 e2 7d 79 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
90        | 7ff7c85f8a00h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[32u](n256,n8,n4,32u)                                                       | Vector256<uint> vlsb<uint>(N256 w, N8 f, N4 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 0f 0f 0f 0f 48 8d 44 24 04 c4 e2 7d 58 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
91        | 7ff7c85f8a40h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[64u](n256,n8,n4,64u)                                                       | Vector256<ulong> vlsb<ulong>(N256 w, N8 f, N4 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 0f 0f 0f 0f 0f 0f 0f 0f 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
92        | 7ff7c85f8a90h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[8u](n256,n8,n5,8u)                                                         | Vector256<byte> vlsb<byte>(N256 w, N8 f, N5 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 1f 00 00 00 48 8d 44 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
93        | 7ff7c85f8ad0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[16u](n256,n8,n5,16u)                                                       | Vector256<ushort> vlsb<ushort>(N256 w, N8 f, N5 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 1f 1f 00 00 48 8d 44 24 04 c4 e2 7d 79 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
94        | 7ff7c85f8b10h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[32u](n256,n8,n5,32u)                                                       | Vector256<uint> vlsb<uint>(N256 w, N8 f, N5 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 1f 1f 1f 1f 48 8d 44 24 04 c4 e2 7d 58 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
95        | 7ff7c85f8b50h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[64u](n256,n8,n5,64u)                                                       | Vector256<ulong> vlsb<ulong>(N256 w, N8 f, N5 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 1f 1f 1f 1f 1f 1f 1f 1f 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
96        | 7ff7c85f8fa0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[8u](n256,n8,n6,8u)                                                         | Vector256<byte> vlsb<byte>(N256 w, N8 f, N6 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 3f 00 00 00 48 8d 44 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
97        | 7ff7c85f8fe0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[16u](n256,n8,n6,16u)                                                       | Vector256<ushort> vlsb<ushort>(N256 w, N8 f, N6 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 3f 3f 00 00 48 8d 44 24 04 c4 e2 7d 79 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
98        | 7ff7c85f9020h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[32u](n256,n8,n6,32u)                                                       | Vector256<uint> vlsb<uint>(N256 w, N8 f, N6 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 3f 3f 3f 3f 48 8d 44 24 04 c4 e2 7d 58 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
99        | 7ff7c85f9060h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[64u](n256,n8,n6,64u)                                                       | Vector256<ulong> vlsb<ulong>(N256 w, N8 f, N6 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 3f 3f 3f 3f 3f 3f 3f 3f 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
100       | 7ff7c85f90b0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[8u](n256,n8,n7,8u)                                                         | Vector256<byte> vlsb<byte>(N256 w, N8 f, N7 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 7f 00 00 00 48 8d 44 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
101       | 7ff7c85f90f0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[16u](n256,n8,n7,16u)                                                       | Vector256<ushort> vlsb<ushort>(N256 w, N8 f, N7 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 7f 7f 00 00 48 8d 44 24 04 c4 e2 7d 79 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
102       | 7ff7c85f9130h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[32u](n256,n8,n7,32u)                                                       | Vector256<uint> vlsb<uint>(N256 w, N8 f, N7 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 7f 7f 7f 7f 48 8d 44 24 04 c4 e2 7d 58 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
103       | 7ff7c85f9170h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[64u](n256,n8,n7,64u)                                                       | Vector256<ulong> vlsb<ulong>(N256 w, N8 f, N7 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 7f 7f 7f 7f 7f 7f 7f 7f 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
104       | 7ff7c85f91c0h   | 52      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[8u](n128,n8,8u,8u)                                                         | Vector128<byte> vlsb<byte>(N128 w, N8 f, byte d, byte t)                                                      | 50 c5 f8 77 90 48 8b c1 41 0f b6 c9 f7 d9 83 c1 08 ba ff 00 00 00 d3 fa 0f b6 d2 88 54 24 04 48 8d 54 24 04 c4 e2 79 78 44 24 04 c5 f9 11 00 48 83 c4 08 c3
105       | 7ff7c85f9210h   | 52      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[16u](n128,n8,8u,16u)                                                       | Vector128<ushort> vlsb<ushort>(N128 w, N8 f, byte d, ushort t)                                                | 50 c5 f8 77 90 48 8b c1 41 0f b6 c9 f7 d9 83 c1 08 ba ff 00 00 00 d3 fa 0f b6 d2 88 54 24 04 48 8d 54 24 04 c4 e2 79 78 44 24 04 c5 f9 11 00 48 83 c4 08 c3
106       | 7ff7c85f9260h   | 52      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[32u](n128,n8,8u,32u)                                                       | Vector128<uint> vlsb<uint>(N128 w, N8 f, byte d, uint t)                                                      | 50 c5 f8 77 90 48 8b c1 41 0f b6 c9 f7 d9 83 c1 08 ba ff 00 00 00 d3 fa 0f b6 d2 88 54 24 04 48 8d 54 24 04 c4 e2 79 78 44 24 04 c5 f9 11 00 48 83 c4 08 c3
107       | 7ff7c85f92b0h   | 52      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[64u](n128,n8,8u,64u)                                                       | Vector128<ulong> vlsb<ulong>(N128 w, N8 f, byte d, ulong t)                                                   | 50 c5 f8 77 90 48 8b c1 41 0f b6 c9 f7 d9 83 c1 08 ba ff 00 00 00 d3 fa 0f b6 d2 88 54 24 04 48 8d 54 24 04 c4 e2 79 78 44 24 04 c5 f9 11 00 48 83 c4 08 c3
108       | 7ff7c85f9300h   | 55      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[8u](n256,n8,8u,8u)                                                         | Vector256<byte> vlsb<byte>(N256 w, N8 f, byte d, byte t)                                                      | 50 c5 f8 77 90 48 8b c1 41 0f b6 c9 f7 d9 83 c1 08 ba ff 00 00 00 d3 fa 0f b6 d2 88 54 24 04 48 8d 54 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 00 c5 f8 77 48 83 c4 08 c3
109       | 7ff7c85f9350h   | 55      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[16u](n256,n8,8u,16u)                                                       | Vector256<ushort> vlsb<ushort>(N256 w, N8 f, byte d, ushort t)                                                | 50 c5 f8 77 90 48 8b c1 41 0f b6 c9 f7 d9 83 c1 08 ba ff 00 00 00 d3 fa 0f b6 d2 88 54 24 04 48 8d 54 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 00 c5 f8 77 48 83 c4 08 c3
110       | 7ff7c85f93a0h   | 55      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[32u](n256,n8,8u,32u)                                                       | Vector256<uint> vlsb<uint>(N256 w, N8 f, byte d, uint t)                                                      | 50 c5 f8 77 90 48 8b c1 41 0f b6 c9 f7 d9 83 c1 08 ba ff 00 00 00 d3 fa 0f b6 d2 88 54 24 04 48 8d 54 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 00 c5 f8 77 48 83 c4 08 c3
111       | 7ff7c85f93f0h   | 55      | CTC_RET_INTR        | hex://intrinsics/vmask?vlsb#vlsb_g[64u](n256,n8,8u,64u)                                                       | Vector256<ulong> vlsb<ulong>(N256 w, N8 f, byte d, ulong t)                                                   | 50 c5 f8 77 90 48 8b c1 41 0f b6 c9 f7 d9 83 c1 08 ba ff 00 00 00 d3 fa 0f b6 d2 88 54 24 04 48 8d 54 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 00 c5 f8 77 48 83 c4 08 c3
112       | 7ff7c85f9440h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[8u](n128,8u)                                                               | Vector128<byte> vmsb<byte>(N128 w, byte t)                                                                    | 50 c5 f8 77 90 c7 44 24 04 80 00 00 00 48 8d 44 24 04 c4 e2 79 78 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
113       | 7ff7c85f9480h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[16u](n128,16u)                                                             | Vector128<ushort> vmsb<ushort>(N128 w, ushort t)                                                              | 50 c5 f8 77 90 c7 44 24 04 00 80 00 00 48 8d 44 24 04 c4 e2 79 79 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
114       | 7ff7c85f94c0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[32u](n128,32u)                                                             | Vector128<uint> vmsb<uint>(N128 w, uint t)                                                                    | 50 c5 f8 77 90 c7 44 24 04 00 00 00 80 48 8d 44 24 04 c4 e2 79 58 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
115       | 7ff7c85f9500h   | 0       | CTC_Zx7             | hex://intrinsics/vmask?vmsb#vmsb_g[64u](n128,64u)                                                             | Vector128<ulong> vmsb<ulong>(N128 w, ulong t)                                                                 |  
116       | 7ff7c85f9950h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[8u](n128,n2,n1,8u)                                                         | Vector128<byte> vmsb<byte>(N128 w, N2 f, N1 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 aa 00 00 00 48 8d 44 24 04 c4 e2 79 78 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
117       | 7ff7c85f9990h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[16u](n128,n2,n1,16u)                                                       | Vector128<ushort> vmsb<ushort>(N128 w, N2 f, N1 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 aa aa 00 00 48 8d 44 24 04 c4 e2 79 79 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
118       | 7ff7c85f99d0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[32u](n128,n2,n1,32u)                                                       | Vector128<uint> vmsb<uint>(N128 w, N2 f, N1 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 aa aa aa aa 48 8d 44 24 04 c4 e2 79 58 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
119       | 7ff7c85f9a10h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[64u](n128,n2,n1,64u)                                                       | Vector128<ulong> vmsb<ulong>(N128 w, N2 f, N1 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 aa aa aa aa aa aa aa aa 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
120       | 7ff7c85f9a50h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[8u](n128,n4,n1,8u)                                                         | Vector128<byte> vmsb<byte>(N128 w, N4 f, N1 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 88 00 00 00 48 8d 44 24 04 c4 e2 79 78 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
121       | 7ff7c85f9a90h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[16u](n128,n4,n1,16u)                                                       | Vector128<ushort> vmsb<ushort>(N128 w, N4 f, N1 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 88 88 00 00 48 8d 44 24 04 c4 e2 79 79 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
122       | 7ff7c85f9ad0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[32u](n128,n4,n1,32u)                                                       | Vector128<uint> vmsb<uint>(N128 w, N4 f, N1 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 88 88 88 88 48 8d 44 24 04 c4 e2 79 58 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
123       | 7ff7c85f9b10h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[64u](n128,n4,n1,64u)                                                       | Vector128<ulong> vmsb<ulong>(N128 w, N4 f, N1 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 88 88 88 88 88 88 00 00 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
124       | 7ff7c85f9b50h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[8u](n128,n8,n1,8u)                                                         | Vector128<byte> vmsb<byte>(N128 w, N8 f, N1 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 80 00 00 00 48 8d 44 24 04 c4 e2 79 78 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
125       | 7ff7c85f9b90h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[16u](n128,n8,n1,16u)                                                       | Vector128<ushort> vmsb<ushort>(N128 w, N8 f, N1 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 80 80 00 00 48 8d 44 24 04 c4 e2 79 79 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
126       | 7ff7c85f9bd0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[32u](n128,n8,n1,32u)                                                       | Vector128<uint> vmsb<uint>(N128 w, N8 f, N1 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 80 80 80 80 48 8d 44 24 04 c4 e2 79 58 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
127       | 7ff7c85fa020h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[64u](n128,n8,n1,64u)                                                       | Vector128<ulong> vmsb<ulong>(N128 w, N8 f, N1 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 80 80 80 80 80 80 80 80 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
128       | 7ff7c85fa060h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[8u](n128,n16,n1,8u)                                                        | Vector128<byte> vmsb<byte>(N128 w, N16 f, N1 d, byte t)                                                       | 50 c5 f8 77 90 48 b8 00 80 00 80 00 80 00 80 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
129       | 7ff7c85fa0a0h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[16u](n128,n16,n1,16u)                                                      | Vector128<ushort> vmsb<ushort>(N128 w, N16 f, N1 d, ushort t)                                                 | 50 c5 f8 77 90 48 b8 00 80 00 80 00 80 00 80 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
130       | 7ff7c85fa0e0h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[32u](n128,n16,n1,32u)                                                      | Vector128<uint> vmsb<uint>(N128 w, N16 f, N1 d, uint t)                                                       | 50 c5 f8 77 90 48 b8 00 80 00 80 00 80 00 80 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
131       | 7ff7c85fa120h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[64u](n128,n16,n1,64u)                                                      | Vector128<ulong> vmsb<ulong>(N128 w, N16 f, N1 d, ulong t)                                                    | 50 c5 f8 77 90 48 b8 00 80 00 80 00 80 00 80 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
132       | 7ff7c85fa160h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[8u](n128,n8,n2,8u)                                                         | Vector128<byte> vmsb<byte>(N128 w, N8 f, N2 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 c0 00 00 00 48 8d 44 24 04 c4 e2 79 78 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
133       | 7ff7c85fa1a0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[16u](n128,n8,n2,16u)                                                       | Vector128<ushort> vmsb<ushort>(N128 w, N8 f, N2 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 c0 c0 00 00 48 8d 44 24 04 c4 e2 79 79 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
134       | 7ff7c85fa1e0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[32u](n128,n8,n2,32u)                                                       | Vector128<uint> vmsb<uint>(N128 w, N8 f, N2 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 c0 c0 c0 c0 48 8d 44 24 04 c4 e2 79 58 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
135       | 7ff7c85fa220h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[64u](n128,n8,n2,64u)                                                       | Vector128<ulong> vmsb<ulong>(N128 w, N8 f, N2 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 c0 c0 c0 c0 c0 c0 c0 c0 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
136       | 7ff7c85fa260h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[8u](n128,n8,n3,8u)                                                         | Vector128<byte> vmsb<byte>(N128 w, N8 f, N3 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 e0 00 00 00 48 8d 44 24 04 c4 e2 79 78 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
137       | 7ff7c85fa2a0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[16u](n128,n8,n3,16u)                                                       | Vector128<ushort> vmsb<ushort>(N128 w, N8 f, N3 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 e0 e0 00 00 48 8d 44 24 04 c4 e2 79 79 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
138       | 7ff7c85fa2e0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[32u](n128,n8,n3,32u)                                                       | Vector128<uint> vmsb<uint>(N128 w, N8 f, N3 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 e0 e0 e0 e0 48 8d 44 24 04 c4 e2 79 58 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
139       | 7ff7c85fa320h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[64u](n128,n8,n3,64u)                                                       | Vector128<ulong> vmsb<ulong>(N128 w, N8 f, N3 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 e0 e0 e0 e0 e0 e0 e0 e0 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
140       | 7ff7c85fa770h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[8u](n128,n8,n4,8u)                                                         | Vector128<byte> vmsb<byte>(N128 w, N8 f, N4 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 f0 00 00 00 48 8d 44 24 04 c4 e2 79 78 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
141       | 7ff7c85fa7b0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[16u](n128,n8,n4,16u)                                                       | Vector128<ushort> vmsb<ushort>(N128 w, N8 f, N4 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 f0 f0 00 00 48 8d 44 24 04 c4 e2 79 79 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
142       | 7ff7c85fa7f0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[32u](n128,n8,n4,32u)                                                       | Vector128<uint> vmsb<uint>(N128 w, N8 f, N4 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 f0 f0 f0 f0 48 8d 44 24 04 c4 e2 79 58 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
143       | 7ff7c85fa830h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[64u](n128,n8,n4,64u)                                                       | Vector128<ulong> vmsb<ulong>(N128 w, N8 f, N4 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 f0 f0 f0 f0 f0 f0 f0 f0 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
144       | 7ff7c85fa870h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[8u](n128,n8,n5,8u)                                                         | Vector128<byte> vmsb<byte>(N128 w, N8 f, N5 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 f8 00 00 00 48 8d 44 24 04 c4 e2 79 78 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
145       | 7ff7c85fa8b0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[16u](n128,n8,n5,16u)                                                       | Vector128<ushort> vmsb<ushort>(N128 w, N8 f, N5 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 f8 f8 00 00 48 8d 44 24 04 c4 e2 79 79 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
146       | 7ff7c85fa8f0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[32u](n128,n8,n5,32u)                                                       | Vector128<uint> vmsb<uint>(N128 w, N8 f, N5 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 f8 f8 f8 f8 48 8d 44 24 04 c4 e2 79 58 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
147       | 7ff7c85fa930h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[64u](n128,n8,n5,64u)                                                       | Vector128<ulong> vmsb<ulong>(N128 w, N8 f, N5 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 f8 f8 f8 f8 f8 f8 f8 f8 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
148       | 7ff7c85fa970h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[8u](n128,n8,n6,8u)                                                         | Vector128<byte> vmsb<byte>(N128 w, N8 f, N6 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 fc 00 00 00 48 8d 44 24 04 c4 e2 79 78 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
149       | 7ff7c85fa9b0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[16u](n128,n8,n6,16u)                                                       | Vector128<ushort> vmsb<ushort>(N128 w, N8 f, N6 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 fc fc 00 00 48 8d 44 24 04 c4 e2 79 79 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
150       | 7ff7c85fa9f0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[32u](n128,n8,n6,32u)                                                       | Vector128<uint> vmsb<uint>(N128 w, N8 f, N6 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 fc fc fc fc 48 8d 44 24 04 c4 e2 79 58 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
151       | 7ff7c85faa30h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[64u](n128,n8,n6,64u)                                                       | Vector128<ulong> vmsb<ulong>(N128 w, N8 f, N6 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 fc fc fc fc fc fc fc fc 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
152       | 7ff7c85fae80h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[8u](n128,n8,n7,8u)                                                         | Vector128<byte> vmsb<byte>(N128 w, N8 f, N7 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 fe 00 00 00 48 8d 44 24 04 c4 e2 79 78 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
153       | 7ff7c85faec0h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[16u](n128,n8,n7,16u)                                                       | Vector128<ushort> vmsb<ushort>(N128 w, N8 f, N7 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 fe fe 00 00 48 8d 44 24 04 c4 e2 79 79 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
154       | 7ff7c85faf00h   | 37      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[32u](n128,n8,n7,32u)                                                       | Vector128<uint> vmsb<uint>(N128 w, N8 f, N7 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 fe fe fe fe 48 8d 44 24 04 c4 e2 79 58 44 24 04 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
155       | 7ff7c85faf40h   | 41      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[64u](n128,n8,n7,64u)                                                       | Vector128<ulong> vmsb<ulong>(N128 w, N8 f, N7 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 fe fe fe fe fe fe fe fe 48 89 04 24 48 8d 04 24 c4 e2 79 59 04 24 c5 f9 11 01 48 8b c1 48 83 c4 08 c3
156       | 7ff7c85faf80h   | 52      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[8u](n128,n8,8u,8u)                                                         | Vector128<byte> vmsb<byte>(N128 w, N8 f, byte d, byte t)                                                      | 50 c5 f8 77 90 48 8b c1 41 0f b6 c9 f7 d9 83 c1 08 ba ff 00 00 00 d3 e2 0f b6 d2 88 54 24 04 48 8d 54 24 04 c4 e2 79 78 44 24 04 c5 f9 11 00 48 83 c4 08 c3
157       | 7ff7c85fafd0h   | 52      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[16u](n128,n8,8u,16u)                                                       | Vector128<ushort> vmsb<ushort>(N128 w, N8 f, byte d, ushort t)                                                | 50 c5 f8 77 90 48 8b c1 41 0f b6 c9 f7 d9 83 c1 08 ba ff 00 00 00 d3 e2 0f b6 d2 88 54 24 04 48 8d 54 24 04 c4 e2 79 78 44 24 04 c5 f9 11 00 48 83 c4 08 c3
158       | 7ff7c85fb020h   | 52      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[32u](n128,n8,8u,32u)                                                       | Vector128<uint> vmsb<uint>(N128 w, N8 f, byte d, uint t)                                                      | 50 c5 f8 77 90 48 8b c1 41 0f b6 c9 f7 d9 83 c1 08 ba ff 00 00 00 d3 e2 0f b6 d2 88 54 24 04 48 8d 54 24 04 c4 e2 79 78 44 24 04 c5 f9 11 00 48 83 c4 08 c3
159       | 7ff7c85fb070h   | 52      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[64u](n128,n8,8u,64u)                                                       | Vector128<ulong> vmsb<ulong>(N128 w, N8 f, byte d, ulong t)                                                   | 50 c5 f8 77 90 48 8b c1 41 0f b6 c9 f7 d9 83 c1 08 ba ff 00 00 00 d3 e2 0f b6 d2 88 54 24 04 48 8d 54 24 04 c4 e2 79 78 44 24 04 c5 f9 11 00 48 83 c4 08 c3
160       | 7ff7c85fb0c0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[8u](n256,8u)                                                               | Vector256<byte> vmsb<byte>(N256 w, byte t)                                                                    | 50 c5 f8 77 90 c7 44 24 04 80 00 00 00 48 8d 44 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
161       | 7ff7c85fb100h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[16u](n256,16u)                                                             | Vector256<ushort> vmsb<ushort>(N256 w, ushort t)                                                              | 50 c5 f8 77 90 c7 44 24 04 00 80 00 00 48 8d 44 24 04 c4 e2 7d 79 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
162       | 7ff7c85fb140h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[32u](n256,32u)                                                             | Vector256<uint> vmsb<uint>(N256 w, uint t)                                                                    | 50 c5 f8 77 90 c7 44 24 04 00 00 00 80 48 8d 44 24 04 c4 e2 7d 58 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
163       | 7ff7c85fb180h   | 0       | CTC_Zx7             | hex://intrinsics/vmask?vmsb#vmsb_g[64u](n256,64u)                                                             | Vector256<ulong> vmsb<ulong>(N256 w, ulong t)                                                                 |  
164       | 7ff7c85fb1d0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[8u](n256,n2,n1,8u)                                                         | Vector256<byte> vmsb<byte>(N256 w, N2 f, N1 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 aa 00 00 00 48 8d 44 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
165       | 7ff7c85fb210h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[16u](n256,n2,n1,16u)                                                       | Vector256<ushort> vmsb<ushort>(N256 w, N2 f, N1 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 aa aa 00 00 48 8d 44 24 04 c4 e2 7d 79 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
166       | 7ff7c85fb250h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[32u](n256,n2,n1,32u)                                                       | Vector256<uint> vmsb<uint>(N256 w, N2 f, N1 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 aa aa aa aa 48 8d 44 24 04 c4 e2 7d 58 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
167       | 7ff7c85fb290h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[64u](n256,n2,n1,64u)                                                       | Vector256<ulong> vmsb<ulong>(N256 w, N2 f, N1 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 aa aa aa aa aa aa aa aa 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
168       | 7ff7c85fb6e0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[8u](n256,n4,n1,8u)                                                         | Vector256<byte> vmsb<byte>(N256 w, N4 f, N1 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 88 00 00 00 48 8d 44 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
169       | 7ff7c85fb720h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[16u](n256,n4,n1,16u)                                                       | Vector256<ushort> vmsb<ushort>(N256 w, N4 f, N1 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 88 88 00 00 48 8d 44 24 04 c4 e2 7d 79 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
170       | 7ff7c85fb760h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[32u](n256,n4,n1,32u)                                                       | Vector256<uint> vmsb<uint>(N256 w, N4 f, N1 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 88 88 88 88 48 8d 44 24 04 c4 e2 7d 58 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
171       | 7ff7c85fb7a0h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[64u](n256,n4,n1,64u)                                                       | Vector256<ulong> vmsb<ulong>(N256 w, N4 f, N1 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 88 88 88 88 88 88 00 00 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
172       | 7ff7c85fb7f0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[8u](n256,n8,n1,8u)                                                         | Vector256<byte> vmsb<byte>(N256 w, N8 f, N1 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 80 00 00 00 48 8d 44 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
173       | 7ff7c85fb830h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[16u](n256,n8,n1,16u)                                                       | Vector256<ushort> vmsb<ushort>(N256 w, N8 f, N1 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 80 80 00 00 48 8d 44 24 04 c4 e2 7d 79 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
174       | 7ff7c85fb870h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[32u](n256,n8,n1,32u)                                                       | Vector256<uint> vmsb<uint>(N256 w, N8 f, N1 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 80 80 80 80 48 8d 44 24 04 c4 e2 7d 58 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
175       | 7ff7c85fb8b0h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[64u](n256,n8,n1,64u)                                                       | Vector256<ulong> vmsb<ulong>(N256 w, N8 f, N1 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 80 80 80 80 80 80 80 80 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
176       | 7ff7c85fb900h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[8u](n256,n16,n1,8u)                                                        | Vector256<byte> vmsb<byte>(N256 w, N16 f, N1 d, byte t)                                                       | 50 c5 f8 77 90 48 b8 00 80 00 80 00 80 00 80 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
177       | 7ff7c85fb950h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[16u](n256,n16,n1,16u)                                                      | Vector256<ushort> vmsb<ushort>(N256 w, N16 f, N1 d, ushort t)                                                 | 50 c5 f8 77 90 48 b8 00 80 00 80 00 80 00 80 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
178       | 7ff7c85fb9a0h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[32u](n256,n16,n1,32u)                                                      | Vector256<uint> vmsb<uint>(N256 w, N16 f, N1 d, uint t)                                                       | 50 c5 f8 77 90 48 b8 00 80 00 80 00 80 00 80 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
179       | 7ff7c85fb9f0h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[64u](n256,n16,n1,64u)                                                      | Vector256<ulong> vmsb<ulong>(N256 w, N16 f, N1 d, ulong t)                                                    | 50 c5 f8 77 90 48 b8 00 80 00 80 00 80 00 80 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
180       | 7ff7c85fba40h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[8u](n256,n8,n2,8u)                                                         | Vector256<byte> vmsb<byte>(N256 w, N8 f, N2 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 c0 00 00 00 48 8d 44 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
181       | 7ff7c85fba80h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[16u](n256,n8,n2,16u)                                                       | Vector256<ushort> vmsb<ushort>(N256 w, N8 f, N2 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 c0 c0 00 00 48 8d 44 24 04 c4 e2 7d 79 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
182       | 7ff7c85fbac0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[32u](n256,n8,n2,32u)                                                       | Vector256<uint> vmsb<uint>(N256 w, N8 f, N2 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 c0 c0 c0 c0 48 8d 44 24 04 c4 e2 7d 58 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
183       | 7ff7c85fbb00h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[64u](n256,n8,n2,64u)                                                       | Vector256<ulong> vmsb<ulong>(N256 w, N8 f, N2 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 c0 c0 c0 c0 c0 c0 c0 c0 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
184       | 7ff7c85fbb50h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[8u](n256,n8,n3,8u)                                                         | Vector256<byte> vmsb<byte>(N256 w, N8 f, N3 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 e0 00 00 00 48 8d 44 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
185       | 7ff7c85fbb90h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[16u](n256,n8,n3,16u)                                                       | Vector256<ushort> vmsb<ushort>(N256 w, N8 f, N3 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 e0 e0 00 00 48 8d 44 24 04 c4 e2 7d 79 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
186       | 7ff7c85fbbd0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[32u](n256,n8,n3,32u)                                                       | Vector256<uint> vmsb<uint>(N256 w, N8 f, N3 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 e0 e0 e0 e0 48 8d 44 24 04 c4 e2 7d 58 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
187       | 7ff7c85fbc10h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[64u](n256,n8,n3,64u)                                                       | Vector256<ulong> vmsb<ulong>(N256 w, N8 f, N3 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 e0 e0 e0 e0 e0 e0 e0 e0 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
188       | 7ff7c85fc060h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[8u](n256,n8,n4,8u)                                                         | Vector256<byte> vmsb<byte>(N256 w, N8 f, N4 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 f0 00 00 00 48 8d 44 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
189       | 7ff7c85fc0a0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[16u](n256,n8,n4,16u)                                                       | Vector256<ushort> vmsb<ushort>(N256 w, N8 f, N4 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 f0 f0 00 00 48 8d 44 24 04 c4 e2 7d 79 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
190       | 7ff7c85fc0e0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[32u](n256,n8,n4,32u)                                                       | Vector256<uint> vmsb<uint>(N256 w, N8 f, N4 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 f0 f0 f0 f0 48 8d 44 24 04 c4 e2 7d 58 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
191       | 7ff7c85fc120h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[64u](n256,n8,n4,64u)                                                       | Vector256<ulong> vmsb<ulong>(N256 w, N8 f, N4 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 f0 f0 f0 f0 f0 f0 f0 f0 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
192       | 7ff7c85fc170h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[8u](n256,n8,n5,8u)                                                         | Vector256<byte> vmsb<byte>(N256 w, N8 f, N5 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 f8 00 00 00 48 8d 44 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
193       | 7ff7c85fc1b0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[16u](n256,n8,n5,16u)                                                       | Vector256<ushort> vmsb<ushort>(N256 w, N8 f, N5 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 f8 f8 00 00 48 8d 44 24 04 c4 e2 7d 79 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
194       | 7ff7c85fc1f0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[32u](n256,n8,n5,32u)                                                       | Vector256<uint> vmsb<uint>(N256 w, N8 f, N5 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 f8 f8 f8 f8 48 8d 44 24 04 c4 e2 7d 58 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
195       | 7ff7c85fc230h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[64u](n256,n8,n5,64u)                                                       | Vector256<ulong> vmsb<ulong>(N256 w, N8 f, N5 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 f8 f8 f8 f8 f8 f8 f8 f8 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
196       | 7ff7c85fc280h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[8u](n256,n8,n6,8u)                                                         | Vector256<byte> vmsb<byte>(N256 w, N8 f, N6 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 fc 00 00 00 48 8d 44 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
197       | 7ff7c85fc2c0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[16u](n256,n8,n6,16u)                                                       | Vector256<ushort> vmsb<ushort>(N256 w, N8 f, N6 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 fc fc 00 00 48 8d 44 24 04 c4 e2 7d 79 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
198       | 7ff7c85fc300h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[32u](n256,n8,n6,32u)                                                       | Vector256<uint> vmsb<uint>(N256 w, N8 f, N6 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 fc fc fc fc 48 8d 44 24 04 c4 e2 7d 58 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
199       | 7ff7c85fc340h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[64u](n256,n8,n6,64u)                                                       | Vector256<ulong> vmsb<ulong>(N256 w, N8 f, N6 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 fc fc fc fc fc fc fc fc 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
200       | 7ff7c85fc390h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[8u](n256,n8,n7,8u)                                                         | Vector256<byte> vmsb<byte>(N256 w, N8 f, N7 d, byte t)                                                        | 50 c5 f8 77 90 c7 44 24 04 fe 00 00 00 48 8d 44 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
201       | 7ff7c85fc3d0h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[16u](n256,n8,n7,16u)                                                       | Vector256<ushort> vmsb<ushort>(N256 w, N8 f, N7 d, ushort t)                                                  | 50 c5 f8 77 90 c7 44 24 04 fe fe 00 00 48 8d 44 24 04 c4 e2 7d 79 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
202       | 7ff7c85fc410h   | 40      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[32u](n256,n8,n7,32u)                                                       | Vector256<uint> vmsb<uint>(N256 w, N8 f, N7 d, uint t)                                                        | 50 c5 f8 77 90 c7 44 24 04 fe fe fe fe 48 8d 44 24 04 c4 e2 7d 58 44 24 04 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
203       | 7ff7c85fc450h   | 44      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[64u](n256,n8,n7,64u)                                                       | Vector256<ulong> vmsb<ulong>(N256 w, N8 f, N7 d, ulong t)                                                     | 50 c5 f8 77 90 48 b8 fe fe fe fe fe fe fe fe 48 89 04 24 48 8d 04 24 c4 e2 7d 59 04 24 c5 fd 11 01 48 8b c1 c5 f8 77 48 83 c4 08 c3
204       | 7ff7c85fc4a0h   | 55      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[8u](n256,n8,8u,8u)                                                         | Vector256<byte> vmsb<byte>(N256 w, N8 f, byte d, byte t)                                                      | 50 c5 f8 77 90 48 8b c1 41 0f b6 c9 f7 d9 83 c1 08 ba ff 00 00 00 d3 e2 0f b6 d2 88 54 24 04 48 8d 54 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 00 c5 f8 77 48 83 c4 08 c3
205       | 7ff7c85fc4f0h   | 55      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[16u](n256,n8,8u,16u)                                                       | Vector256<ushort> vmsb<ushort>(N256 w, N8 f, byte d, ushort t)                                                | 50 c5 f8 77 90 48 8b c1 41 0f b6 c9 f7 d9 83 c1 08 ba ff 00 00 00 d3 e2 0f b6 d2 88 54 24 04 48 8d 54 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 00 c5 f8 77 48 83 c4 08 c3
206       | 7ff7c85fc540h   | 55      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[32u](n256,n8,8u,32u)                                                       | Vector256<uint> vmsb<uint>(N256 w, N8 f, byte d, uint t)                                                      | 50 c5 f8 77 90 48 8b c1 41 0f b6 c9 f7 d9 83 c1 08 ba ff 00 00 00 d3 e2 0f b6 d2 88 54 24 04 48 8d 54 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 00 c5 f8 77 48 83 c4 08 c3
207       | 7ff7c85fc9a0h   | 55      | CTC_RET_INTR        | hex://intrinsics/vmask?vmsb#vmsb_g[64u](n256,n8,8u,64u)                                                       | Vector256<ulong> vmsb<ulong>(N256 w, N8 f, byte d, ulong t)                                                   | 50 c5 f8 77 90 48 8b c1 41 0f b6 c9 f7 d9 83 c1 08 ba ff 00 00 00 d3 e2 0f b6 d2 88 54 24 04 48 8d 54 24 04 c4 e2 7d 78 44 24 04 c5 fd 11 00 c5 f8 77 48 83 c4 08 c3

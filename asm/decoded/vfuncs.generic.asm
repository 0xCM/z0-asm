------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> v8u<byte>(Vector128<byte> x), hex://vfuncs/generic?v8u#v8u_g[8u](v128x8u)
; v8u_g[8u](v128x8u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> v8u<sbyte>(Vector128<sbyte> x), hex://vfuncs/generic?v8u#v8u_g[8i](v128x8i)
; v8u_g[8i](v128x8i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> v8u<ushort>(Vector128<ushort> x), hex://vfuncs/generic?v8u#v8u_g[16u](v128x16u)
; v8u_g[16u](v128x16u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> v8u<short>(Vector128<short> x), hex://vfuncs/generic?v8u#v8u_g[16i](v128x16i)
; v8u_g[16i](v128x16i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> v8u<uint>(Vector128<uint> x), hex://vfuncs/generic?v8u#v8u_g[32u](v128x32u)
; v8u_g[32u](v128x32u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> v8u<int>(Vector128<int> x), hex://vfuncs/generic?v8u#v8u_g[32i](v128x32i)
; v8u_g[32i](v128x32i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> v8u<ulong>(Vector128<ulong> x), hex://vfuncs/generic?v8u#v8u_g[64u](v128x64u)
; v8u_g[64u](v128x64u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> v8u<long>(Vector128<long> x), hex://vfuncs/generic?v8u#v8u_g[64i](v128x64i)
; v8u_g[64i](v128x64i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> v8u<float>(Vector128<float> x), hex://vfuncs/generic?v8u#v8u_g[32f](v128x32f)
; v8u_g[32f](v128x32f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> v8u<double>(Vector128<double> x), hex://vfuncs/generic?v8u#v8u_g[64f](v128x64f)
; v8u_g[64f](v128x64f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> v16i<byte>(Vector128<byte> x), hex://vfuncs/generic?v16i#v16i_g[8u](v128x8u)
; v16i_g[8u](v128x8u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> v16i<sbyte>(Vector128<sbyte> x), hex://vfuncs/generic?v16i#v16i_g[8i](v128x8i)
; v16i_g[8i](v128x8i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> v16i<ushort>(Vector128<ushort> x), hex://vfuncs/generic?v16i#v16i_g[16u](v128x16u)
; v16i_g[16u](v128x16u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> v16i<short>(Vector128<short> x), hex://vfuncs/generic?v16i#v16i_g[16i](v128x16i)
; v16i_g[16i](v128x16i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> v16i<uint>(Vector128<uint> x), hex://vfuncs/generic?v16i#v16i_g[32u](v128x32u)
; v16i_g[32u](v128x32u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> v16i<int>(Vector128<int> x), hex://vfuncs/generic?v16i#v16i_g[32i](v128x32i)
; v16i_g[32i](v128x32i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> v16i<ulong>(Vector128<ulong> x), hex://vfuncs/generic?v16i#v16i_g[64u](v128x64u)
; v16i_g[64u](v128x64u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> v16i<long>(Vector128<long> x), hex://vfuncs/generic?v16i#v16i_g[64i](v128x64i)
; v16i_g[64i](v128x64i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> v16i<float>(Vector128<float> x), hex://vfuncs/generic?v16i#v16i_g[32f](v128x32f)
; v16i_g[32f](v128x32f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> v16i<double>(Vector128<double> x), hex://vfuncs/generic?v16i#v16i_g[64f](v128x64f)
; v16i_g[64f](v128x64f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> v16u<byte>(Vector128<byte> x), hex://vfuncs/generic?v16u#v16u_g[8u](v128x8u)
; v16u_g[8u](v128x8u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> v16u<sbyte>(Vector128<sbyte> x), hex://vfuncs/generic?v16u#v16u_g[8i](v128x8i)
; v16u_g[8i](v128x8i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> v16u<ushort>(Vector128<ushort> x), hex://vfuncs/generic?v16u#v16u_g[16u](v128x16u)
; v16u_g[16u](v128x16u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> v16u<short>(Vector128<short> x), hex://vfuncs/generic?v16u#v16u_g[16i](v128x16i)
; v16u_g[16i](v128x16i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> v16u<uint>(Vector128<uint> x), hex://vfuncs/generic?v16u#v16u_g[32u](v128x32u)
; v16u_g[32u](v128x32u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> v16u<int>(Vector128<int> x), hex://vfuncs/generic?v16u#v16u_g[32i](v128x32i)
; v16u_g[32i](v128x32i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> v16u<ulong>(Vector128<ulong> x), hex://vfuncs/generic?v16u#v16u_g[64u](v128x64u)
; v16u_g[64u](v128x64u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> v16u<long>(Vector128<long> x), hex://vfuncs/generic?v16u#v16u_g[64i](v128x64i)
; v16u_g[64i](v128x64i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> v16u<float>(Vector128<float> x), hex://vfuncs/generic?v16u#v16u_g[32f](v128x32f)
; v16u_g[32f](v128x32f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> v16u<double>(Vector128<double> x), hex://vfuncs/generic?v16u#v16u_g[64f](v128x64f)
; v16u_g[64f](v128x64f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> v32i<byte>(Vector128<byte> x), hex://vfuncs/generic?v32i#v32i_g[8u](v128x8u)
; v32i_g[8u](v128x8u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> v32i<sbyte>(Vector128<sbyte> x), hex://vfuncs/generic?v32i#v32i_g[8i](v128x8i)
; v32i_g[8i](v128x8i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> v32i<ushort>(Vector128<ushort> x), hex://vfuncs/generic?v32i#v32i_g[16u](v128x16u)
; v32i_g[16u](v128x16u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> v32i<short>(Vector128<short> x), hex://vfuncs/generic?v32i#v32i_g[16i](v128x16i)
; v32i_g[16i](v128x16i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> v32i<uint>(Vector128<uint> x), hex://vfuncs/generic?v32i#v32i_g[32u](v128x32u)
; v32i_g[32u](v128x32u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> v32i<int>(Vector128<int> x), hex://vfuncs/generic?v32i#v32i_g[32i](v128x32i)
; v32i_g[32i](v128x32i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> v32i<ulong>(Vector128<ulong> x), hex://vfuncs/generic?v32i#v32i_g[64u](v128x64u)
; v32i_g[64u](v128x64u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> v32i<long>(Vector128<long> x), hex://vfuncs/generic?v32i#v32i_g[64i](v128x64i)
; v32i_g[64i](v128x64i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> v32i<float>(Vector128<float> x), hex://vfuncs/generic?v32i#v32i_g[32f](v128x32f)
; v32i_g[32f](v128x32f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> v32i<double>(Vector128<double> x), hex://vfuncs/generic?v32i#v32i_g[64f](v128x64f)
; v32i_g[64f](v128x64f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> v32u<byte>(Vector128<byte> x), hex://vfuncs/generic?v32u#v32u_g[8u](v128x8u)
; v32u_g[8u](v128x8u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> v32u<sbyte>(Vector128<sbyte> x), hex://vfuncs/generic?v32u#v32u_g[8i](v128x8i)
; v32u_g[8i](v128x8i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> v32u<ushort>(Vector128<ushort> x), hex://vfuncs/generic?v32u#v32u_g[16u](v128x16u)
; v32u_g[16u](v128x16u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> v32u<short>(Vector128<short> x), hex://vfuncs/generic?v32u#v32u_g[16i](v128x16i)
; v32u_g[16i](v128x16i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> v32u<uint>(Vector128<uint> x), hex://vfuncs/generic?v32u#v32u_g[32u](v128x32u)
; v32u_g[32u](v128x32u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> v32u<int>(Vector128<int> x), hex://vfuncs/generic?v32u#v32u_g[32i](v128x32i)
; v32u_g[32i](v128x32i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> v32u<ulong>(Vector128<ulong> x), hex://vfuncs/generic?v32u#v32u_g[64u](v128x64u)
; v32u_g[64u](v128x64u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> v32u<long>(Vector128<long> x), hex://vfuncs/generic?v32u#v32u_g[64i](v128x64i)
; v32u_g[64i](v128x64i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> v32u<float>(Vector128<float> x), hex://vfuncs/generic?v32u#v32u_g[32f](v128x32f)
; v32u_g[32f](v128x32f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> v32u<double>(Vector128<double> x), hex://vfuncs/generic?v32u#v32u_g[64f](v128x64f)
; v32u_g[64f](v128x64f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> v64i<byte>(Vector128<byte> x), hex://vfuncs/generic?v64i#v64i_g[8u](v128x8u)
; v64i_g[8u](v128x8u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> v64i<sbyte>(Vector128<sbyte> x), hex://vfuncs/generic?v64i#v64i_g[8i](v128x8i)
; v64i_g[8i](v128x8i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> v64i<ushort>(Vector128<ushort> x), hex://vfuncs/generic?v64i#v64i_g[16u](v128x16u)
; v64i_g[16u](v128x16u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> v64i<short>(Vector128<short> x), hex://vfuncs/generic?v64i#v64i_g[16i](v128x16i)
; v64i_g[16i](v128x16i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> v64i<uint>(Vector128<uint> x), hex://vfuncs/generic?v64i#v64i_g[32u](v128x32u)
; v64i_g[32u](v128x32u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> v64i<int>(Vector128<int> x), hex://vfuncs/generic?v64i#v64i_g[32i](v128x32i)
; v64i_g[32i](v128x32i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> v64i<ulong>(Vector128<ulong> x), hex://vfuncs/generic?v64i#v64i_g[64u](v128x64u)
; v64i_g[64u](v128x64u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> v64i<long>(Vector128<long> x), hex://vfuncs/generic?v64i#v64i_g[64i](v128x64i)
; v64i_g[64i](v128x64i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> v64i<float>(Vector128<float> x), hex://vfuncs/generic?v64i#v64i_g[32f](v128x32f)
; v64i_g[32f](v128x32f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> v64i<double>(Vector128<double> x), hex://vfuncs/generic?v64i#v64i_g[64f](v128x64f)
; v64i_g[64f](v128x64f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> v64u<byte>(Vector128<byte> x), hex://vfuncs/generic?v64u#v64u_g[8u](v128x8u)
; v64u_g[8u](v128x8u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> v64u<sbyte>(Vector128<sbyte> x), hex://vfuncs/generic?v64u#v64u_g[8i](v128x8i)
; v64u_g[8i](v128x8i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> v64u<ushort>(Vector128<ushort> x), hex://vfuncs/generic?v64u#v64u_g[16u](v128x16u)
; v64u_g[16u](v128x16u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> v64u<short>(Vector128<short> x), hex://vfuncs/generic?v64u#v64u_g[16i](v128x16i)
; v64u_g[16i](v128x16i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> v64u<uint>(Vector128<uint> x), hex://vfuncs/generic?v64u#v64u_g[32u](v128x32u)
; v64u_g[32u](v128x32u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> v64u<int>(Vector128<int> x), hex://vfuncs/generic?v64u#v64u_g[32i](v128x32i)
; v64u_g[32i](v128x32i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> v64u<ulong>(Vector128<ulong> x), hex://vfuncs/generic?v64u#v64u_g[64u](v128x64u)
; v64u_g[64u](v128x64u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> v64u<long>(Vector128<long> x), hex://vfuncs/generic?v64u#v64u_g[64i](v128x64i)
; v64u_g[64i](v128x64i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> v64u<float>(Vector128<float> x), hex://vfuncs/generic?v64u#v64u_g[32f](v128x32f)
; v64u_g[32f](v128x32f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> v64u<double>(Vector128<double> x), hex://vfuncs/generic?v64u#v64u_g[64f](v128x64f)
; v64u_g[64f](v128x64f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> v32f<byte>(Vector128<byte> x), hex://vfuncs/generic?v32f#v32f_g[8u](v128x8u)
; v32f_g[8u](v128x8u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> v32f<sbyte>(Vector128<sbyte> x), hex://vfuncs/generic?v32f#v32f_g[8i](v128x8i)
; v32f_g[8i](v128x8i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> v32f<ushort>(Vector128<ushort> x), hex://vfuncs/generic?v32f#v32f_g[16u](v128x16u)
; v32f_g[16u](v128x16u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> v32f<short>(Vector128<short> x), hex://vfuncs/generic?v32f#v32f_g[16i](v128x16i)
; v32f_g[16i](v128x16i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> v32f<uint>(Vector128<uint> x), hex://vfuncs/generic?v32f#v32f_g[32u](v128x32u)
; v32f_g[32u](v128x32u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> v32f<int>(Vector128<int> x), hex://vfuncs/generic?v32f#v32f_g[32i](v128x32i)
; v32f_g[32i](v128x32i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> v32f<ulong>(Vector128<ulong> x), hex://vfuncs/generic?v32f#v32f_g[64u](v128x64u)
; v32f_g[64u](v128x64u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> v32f<long>(Vector128<long> x), hex://vfuncs/generic?v32f#v32f_g[64i](v128x64i)
; v32f_g[64i](v128x64i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> v32f<float>(Vector128<float> x), hex://vfuncs/generic?v32f#v32f_g[32f](v128x32f)
; v32f_g[32f](v128x32f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> v32f<double>(Vector128<double> x), hex://vfuncs/generic?v32f#v32f_g[64f](v128x64f)
; v32f_g[64f](v128x64f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> v64f<byte>(Vector128<byte> x), hex://vfuncs/generic?v64f#v64f_g[8u](v128x8u)
; v64f_g[8u](v128x8u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> v64f<sbyte>(Vector128<sbyte> x), hex://vfuncs/generic?v64f#v64f_g[8i](v128x8i)
; v64f_g[8i](v128x8i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> v64f<ushort>(Vector128<ushort> x), hex://vfuncs/generic?v64f#v64f_g[16u](v128x16u)
; v64f_g[16u](v128x16u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> v64f<short>(Vector128<short> x), hex://vfuncs/generic?v64f#v64f_g[16i](v128x16i)
; v64f_g[16i](v128x16i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> v64f<uint>(Vector128<uint> x), hex://vfuncs/generic?v64f#v64f_g[32u](v128x32u)
; v64f_g[32u](v128x32u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> v64f<int>(Vector128<int> x), hex://vfuncs/generic?v64f#v64f_g[32i](v128x32i)
; v64f_g[32i](v128x32i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> v64f<ulong>(Vector128<ulong> x), hex://vfuncs/generic?v64f#v64f_g[64u](v128x64u)
; v64f_g[64u](v128x64u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> v64f<long>(Vector128<long> x), hex://vfuncs/generic?v64f#v64f_g[64i](v128x64i)
; v64f_g[64i](v128x64i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> v64f<float>(Vector128<float> x), hex://vfuncs/generic?v64f#v64f_g[32f](v128x32f)
; v64f_g[32f](v128x32f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> v64f<double>(Vector128<double> x), hex://vfuncs/generic?v64f#v64f_g[64f](v128x64f)
; v64f_g[64f](v128x64f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<sbyte> v8i<byte>(Vector256<byte> x), hex://vfuncs/generic?v8i#v8i_g[8u](v256x8u)
; v8i_g[8u](v256x8u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<sbyte> v8i<sbyte>(Vector256<sbyte> x), hex://vfuncs/generic?v8i#v8i_g[8i](v256x8i)
; v8i_g[8i](v256x8i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<sbyte> v8i<ushort>(Vector256<ushort> x), hex://vfuncs/generic?v8i#v8i_g[16u](v256x16u)
; v8i_g[16u](v256x16u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<sbyte> v8i<short>(Vector256<short> x), hex://vfuncs/generic?v8i#v8i_g[16i](v256x16i)
; v8i_g[16i](v256x16i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<sbyte> v8i<uint>(Vector256<uint> x), hex://vfuncs/generic?v8i#v8i_g[32u](v256x32u)
; v8i_g[32u](v256x32u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<sbyte> v8i<int>(Vector256<int> x), hex://vfuncs/generic?v8i#v8i_g[32i](v256x32i)
; v8i_g[32i](v256x32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<sbyte> v8i<ulong>(Vector256<ulong> x), hex://vfuncs/generic?v8i#v8i_g[64u](v256x64u)
; v8i_g[64u](v256x64u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<sbyte> v8i<long>(Vector256<long> x), hex://vfuncs/generic?v8i#v8i_g[64i](v256x64i)
; v8i_g[64i](v256x64i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<sbyte> v8i<float>(Vector256<float> x), hex://vfuncs/generic?v8i#v8i_g[32f](v256x32f)
; v8i_g[32f](v256x32f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<sbyte> v8i<double>(Vector256<double> x), hex://vfuncs/generic?v8i#v8i_g[64f](v256x64f)
; v8i_g[64f](v256x64f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<byte> v8u<byte>(Vector256<byte> x), hex://vfuncs/generic?v8u#v8u_g[8u](v256x8u)
; v8u_g[8u](v256x8u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<byte> v8u<sbyte>(Vector256<sbyte> x), hex://vfuncs/generic?v8u#v8u_g[8i](v256x8i)
; v8u_g[8i](v256x8i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<byte> v8u<ushort>(Vector256<ushort> x), hex://vfuncs/generic?v8u#v8u_g[16u](v256x16u)
; v8u_g[16u](v256x16u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<byte> v8u<short>(Vector256<short> x), hex://vfuncs/generic?v8u#v8u_g[16i](v256x16i)
; v8u_g[16i](v256x16i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<byte> v8u<uint>(Vector256<uint> x), hex://vfuncs/generic?v8u#v8u_g[32u](v256x32u)
; v8u_g[32u](v256x32u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<byte> v8u<int>(Vector256<int> x), hex://vfuncs/generic?v8u#v8u_g[32i](v256x32i)
; v8u_g[32i](v256x32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<byte> v8u<ulong>(Vector256<ulong> x), hex://vfuncs/generic?v8u#v8u_g[64u](v256x64u)
; v8u_g[64u](v256x64u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<byte> v8u<long>(Vector256<long> x), hex://vfuncs/generic?v8u#v8u_g[64i](v256x64i)
; v8u_g[64i](v256x64i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<byte> v8u<float>(Vector256<float> x), hex://vfuncs/generic?v8u#v8u_g[32f](v256x32f)
; v8u_g[32f](v256x32f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<byte> v8u<double>(Vector256<double> x), hex://vfuncs/generic?v8u#v8u_g[64f](v256x64f)
; v8u_g[64f](v256x64f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<short> v16i<byte>(Vector256<byte> x), hex://vfuncs/generic?v16i#v16i_g[8u](v256x8u)
; v16i_g[8u](v256x8u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<short> v16i<sbyte>(Vector256<sbyte> x), hex://vfuncs/generic?v16i#v16i_g[8i](v256x8i)
; v16i_g[8i](v256x8i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<short> v16i<ushort>(Vector256<ushort> x), hex://vfuncs/generic?v16i#v16i_g[16u](v256x16u)
; v16i_g[16u](v256x16u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<short> v16i<short>(Vector256<short> x), hex://vfuncs/generic?v16i#v16i_g[16i](v256x16i)
; v16i_g[16i](v256x16i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<short> v16i<uint>(Vector256<uint> x), hex://vfuncs/generic?v16i#v16i_g[32u](v256x32u)
; v16i_g[32u](v256x32u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<short> v16i<int>(Vector256<int> x), hex://vfuncs/generic?v16i#v16i_g[32i](v256x32i)
; v16i_g[32i](v256x32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<short> v16i<ulong>(Vector256<ulong> x), hex://vfuncs/generic?v16i#v16i_g[64u](v256x64u)
; v16i_g[64u](v256x64u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<short> v16i<long>(Vector256<long> x), hex://vfuncs/generic?v16i#v16i_g[64i](v256x64i)
; v16i_g[64i](v256x64i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<short> v16i<float>(Vector256<float> x), hex://vfuncs/generic?v16i#v16i_g[32f](v256x32f)
; v16i_g[32f](v256x32f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<short> v16i<double>(Vector256<double> x), hex://vfuncs/generic?v16i#v16i_g[64f](v256x64f)
; v16i_g[64f](v256x64f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ushort> v16u<byte>(Vector256<byte> x), hex://vfuncs/generic?v16u#v16u_g[8u](v256x8u)
; v16u_g[8u](v256x8u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ushort> v16u<sbyte>(Vector256<sbyte> x), hex://vfuncs/generic?v16u#v16u_g[8i](v256x8i)
; v16u_g[8i](v256x8i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ushort> v16u<ushort>(Vector256<ushort> x), hex://vfuncs/generic?v16u#v16u_g[16u](v256x16u)
; v16u_g[16u](v256x16u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ushort> v16u<short>(Vector256<short> x), hex://vfuncs/generic?v16u#v16u_g[16i](v256x16i)
; v16u_g[16i](v256x16i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ushort> v16u<uint>(Vector256<uint> x), hex://vfuncs/generic?v16u#v16u_g[32u](v256x32u)
; v16u_g[32u](v256x32u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ushort> v16u<int>(Vector256<int> x), hex://vfuncs/generic?v16u#v16u_g[32i](v256x32i)
; v16u_g[32i](v256x32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ushort> v16u<ulong>(Vector256<ulong> x), hex://vfuncs/generic?v16u#v16u_g[64u](v256x64u)
; v16u_g[64u](v256x64u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ushort> v16u<long>(Vector256<long> x), hex://vfuncs/generic?v16u#v16u_g[64i](v256x64i)
; v16u_g[64i](v256x64i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ushort> v16u<float>(Vector256<float> x), hex://vfuncs/generic?v16u#v16u_g[32f](v256x32f)
; v16u_g[32f](v256x32f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ushort> v16u<double>(Vector256<double> x), hex://vfuncs/generic?v16u#v16u_g[64f](v256x64f)
; v16u_g[64f](v256x64f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<int> v32i<byte>(Vector256<byte> x), hex://vfuncs/generic?v32i#v32i_g[8u](v256x8u)
; v32i_g[8u](v256x8u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<int> v32i<sbyte>(Vector256<sbyte> x), hex://vfuncs/generic?v32i#v32i_g[8i](v256x8i)
; v32i_g[8i](v256x8i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<int> v32i<ushort>(Vector256<ushort> x), hex://vfuncs/generic?v32i#v32i_g[16u](v256x16u)
; v32i_g[16u](v256x16u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<int> v32i<short>(Vector256<short> x), hex://vfuncs/generic?v32i#v32i_g[16i](v256x16i)
; v32i_g[16i](v256x16i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<int> v32i<uint>(Vector256<uint> x), hex://vfuncs/generic?v32i#v32i_g[32u](v256x32u)
; v32i_g[32u](v256x32u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<int> v32i<int>(Vector256<int> x), hex://vfuncs/generic?v32i#v32i_g[32i](v256x32i)
; v32i_g[32i](v256x32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<int> v32i<ulong>(Vector256<ulong> x), hex://vfuncs/generic?v32i#v32i_g[64u](v256x64u)
; v32i_g[64u](v256x64u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<int> v32i<long>(Vector256<long> x), hex://vfuncs/generic?v32i#v32i_g[64i](v256x64i)
; v32i_g[64i](v256x64i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<int> v32i<float>(Vector256<float> x), hex://vfuncs/generic?v32i#v32i_g[32f](v256x32f)
; v32i_g[32f](v256x32f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<int> v32i<double>(Vector256<double> x), hex://vfuncs/generic?v32i#v32i_g[64f](v256x64f)
; v32i_g[64f](v256x64f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<uint> v32u<byte>(Vector256<byte> x), hex://vfuncs/generic?v32u#v32u_g[8u](v256x8u)
; v32u_g[8u](v256x8u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<uint> v32u<sbyte>(Vector256<sbyte> x), hex://vfuncs/generic?v32u#v32u_g[8i](v256x8i)
; v32u_g[8i](v256x8i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<uint> v32u<ushort>(Vector256<ushort> x), hex://vfuncs/generic?v32u#v32u_g[16u](v256x16u)
; v32u_g[16u](v256x16u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<uint> v32u<short>(Vector256<short> x), hex://vfuncs/generic?v32u#v32u_g[16i](v256x16i)
; v32u_g[16i](v256x16i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<uint> v32u<uint>(Vector256<uint> x), hex://vfuncs/generic?v32u#v32u_g[32u](v256x32u)
; v32u_g[32u](v256x32u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<uint> v32u<int>(Vector256<int> x), hex://vfuncs/generic?v32u#v32u_g[32i](v256x32i)
; v32u_g[32i](v256x32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<uint> v32u<ulong>(Vector256<ulong> x), hex://vfuncs/generic?v32u#v32u_g[64u](v256x64u)
; v32u_g[64u](v256x64u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<uint> v32u<long>(Vector256<long> x), hex://vfuncs/generic?v32u#v32u_g[64i](v256x64i)
; v32u_g[64i](v256x64i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<uint> v32u<float>(Vector256<float> x), hex://vfuncs/generic?v32u#v32u_g[32f](v256x32f)
; v32u_g[32f](v256x32f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<uint> v32u<double>(Vector256<double> x), hex://vfuncs/generic?v32u#v32u_g[64f](v256x64f)
; v32u_g[64f](v256x64f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<long> v64i<byte>(Vector256<byte> x), hex://vfuncs/generic?v64i#v64i_g[8u](v256x8u)
; v64i_g[8u](v256x8u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<long> v64i<sbyte>(Vector256<sbyte> x), hex://vfuncs/generic?v64i#v64i_g[8i](v256x8i)
; v64i_g[8i](v256x8i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<long> v64i<ushort>(Vector256<ushort> x), hex://vfuncs/generic?v64i#v64i_g[16u](v256x16u)
; v64i_g[16u](v256x16u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<long> v64i<short>(Vector256<short> x), hex://vfuncs/generic?v64i#v64i_g[16i](v256x16i)
; v64i_g[16i](v256x16i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<long> v64i<uint>(Vector256<uint> x), hex://vfuncs/generic?v64i#v64i_g[32u](v256x32u)
; v64i_g[32u](v256x32u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<long> v64i<int>(Vector256<int> x), hex://vfuncs/generic?v64i#v64i_g[32i](v256x32i)
; v64i_g[32i](v256x32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<long> v64i<ulong>(Vector256<ulong> x), hex://vfuncs/generic?v64i#v64i_g[64u](v256x64u)
; v64i_g[64u](v256x64u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<long> v64i<long>(Vector256<long> x), hex://vfuncs/generic?v64i#v64i_g[64i](v256x64i)
; v64i_g[64i](v256x64i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<long> v64i<float>(Vector256<float> x), hex://vfuncs/generic?v64i#v64i_g[32f](v256x32f)
; v64i_g[32f](v256x32f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<long> v64i<double>(Vector256<double> x), hex://vfuncs/generic?v64i#v64i_g[64f](v256x64f)
; v64i_g[64f](v256x64f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ulong> v64u<byte>(Vector256<byte> x), hex://vfuncs/generic?v64u#v64u_g[8u](v256x8u)
; v64u_g[8u](v256x8u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ulong> v64u<sbyte>(Vector256<sbyte> x), hex://vfuncs/generic?v64u#v64u_g[8i](v256x8i)
; v64u_g[8i](v256x8i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ulong> v64u<ushort>(Vector256<ushort> x), hex://vfuncs/generic?v64u#v64u_g[16u](v256x16u)
; v64u_g[16u](v256x16u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ulong> v64u<short>(Vector256<short> x), hex://vfuncs/generic?v64u#v64u_g[16i](v256x16i)
; v64u_g[16i](v256x16i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ulong> v64u<uint>(Vector256<uint> x), hex://vfuncs/generic?v64u#v64u_g[32u](v256x32u)
; v64u_g[32u](v256x32u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ulong> v64u<int>(Vector256<int> x), hex://vfuncs/generic?v64u#v64u_g[32i](v256x32i)
; v64u_g[32i](v256x32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ulong> v64u<ulong>(Vector256<ulong> x), hex://vfuncs/generic?v64u#v64u_g[64u](v256x64u)
; v64u_g[64u](v256x64u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ulong> v64u<long>(Vector256<long> x), hex://vfuncs/generic?v64u#v64u_g[64i](v256x64i)
; v64u_g[64i](v256x64i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ulong> v64u<float>(Vector256<float> x), hex://vfuncs/generic?v64u#v64u_g[32f](v256x32f)
; v64u_g[32f](v256x32f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ulong> v64u<double>(Vector256<double> x), hex://vfuncs/generic?v64u#v64u_g[64f](v256x64f)
; v64u_g[64f](v256x64f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<float> v32f<byte>(Vector256<byte> x), hex://vfuncs/generic?v32f#v32f_g[8u](v256x8u)
; v32f_g[8u](v256x8u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<float> v32f<sbyte>(Vector256<sbyte> x), hex://vfuncs/generic?v32f#v32f_g[8i](v256x8i)
; v32f_g[8i](v256x8i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<float> v32f<ushort>(Vector256<ushort> x), hex://vfuncs/generic?v32f#v32f_g[16u](v256x16u)
; v32f_g[16u](v256x16u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<float> v32f<short>(Vector256<short> x), hex://vfuncs/generic?v32f#v32f_g[16i](v256x16i)
; v32f_g[16i](v256x16i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<float> v32f<uint>(Vector256<uint> x), hex://vfuncs/generic?v32f#v32f_g[32u](v256x32u)
; v32f_g[32u](v256x32u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<float> v32f<int>(Vector256<int> x), hex://vfuncs/generic?v32f#v32f_g[32i](v256x32i)
; v32f_g[32i](v256x32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<float> v32f<ulong>(Vector256<ulong> x), hex://vfuncs/generic?v32f#v32f_g[64u](v256x64u)
; v32f_g[64u](v256x64u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<float> v32f<long>(Vector256<long> x), hex://vfuncs/generic?v32f#v32f_g[64i](v256x64i)
; v32f_g[64i](v256x64i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<float> v32f<float>(Vector256<float> x), hex://vfuncs/generic?v32f#v32f_g[32f](v256x32f)
; v32f_g[32f](v256x32f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<float> v32f<double>(Vector256<double> x), hex://vfuncs/generic?v32f#v32f_g[64f](v256x64f)
; v32f_g[64f](v256x64f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<double> v64f<byte>(Vector256<byte> x), hex://vfuncs/generic?v64f#v64f_g[8u](v256x8u)
; v64f_g[8u](v256x8u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<double> v64f<sbyte>(Vector256<sbyte> x), hex://vfuncs/generic?v64f#v64f_g[8i](v256x8i)
; v64f_g[8i](v256x8i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<double> v64f<ushort>(Vector256<ushort> x), hex://vfuncs/generic?v64f#v64f_g[16u](v256x16u)
; v64f_g[16u](v256x16u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<double> v64f<short>(Vector256<short> x), hex://vfuncs/generic?v64f#v64f_g[16i](v256x16i)
; v64f_g[16i](v256x16i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<double> v64f<uint>(Vector256<uint> x), hex://vfuncs/generic?v64f#v64f_g[32u](v256x32u)
; v64f_g[32u](v256x32u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<double> v64f<int>(Vector256<int> x), hex://vfuncs/generic?v64f#v64f_g[32i](v256x32i)
; v64f_g[32i](v256x32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<double> v64f<ulong>(Vector256<ulong> x), hex://vfuncs/generic?v64f#v64f_g[64u](v256x64u)
; v64f_g[64u](v256x64u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<double> v64f<long>(Vector256<long> x), hex://vfuncs/generic?v64f#v64f_g[64i](v256x64i)
; v64f_g[64i](v256x64i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<double> v64f<float>(Vector256<float> x), hex://vfuncs/generic?v64f#v64f_g[32f](v256x32f)
; v64f_g[32f](v256x32f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<double> v64f<double>(Vector256<double> x), hex://vfuncs/generic?v64f#v64f_g[64f](v256x64f)
; v64f_g[64f](v256x64f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<byte>(N128 w, byte t), hex://vfuncs/generic?vcount#vcount_g[8u](n128,8u)
; vcount_g[8u](n128,8u)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x10,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,10h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 10 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<sbyte>(N128 w, sbyte t), hex://vfuncs/generic?vcount#vcount_g[8i](n128,8i)
; vcount_g[8i](n128,8i)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x10,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,10h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 10 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<ushort>(N128 w, ushort t), hex://vfuncs/generic?vcount#vcount_g[16u](n128,16u)
; vcount_g[16u](n128,16u)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x08,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,8                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 08 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<short>(N128 w, short t), hex://vfuncs/generic?vcount#vcount_g[16i](n128,16i)
; vcount_g[16i](n128,16i)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x08,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,8                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 08 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<uint>(N128 w, uint t), hex://vfuncs/generic?vcount#vcount_g[32u](n128,32u)
; vcount_g[32u](n128,32u)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x04,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,4                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 04 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<int>(N128 w, int t), hex://vfuncs/generic?vcount#vcount_g[32i](n128,32i)
; vcount_g[32i](n128,32i)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x04,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,4                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 04 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<ulong>(N128 w, ulong t), hex://vfuncs/generic?vcount#vcount_g[64u](n128,64u)
; vcount_g[64u](n128,64u)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x02,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,2                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 02 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<long>(N128 w, long t), hex://vfuncs/generic?vcount#vcount_g[64i](n128,64i)
; vcount_g[64i](n128,64i)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x02,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,2                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 02 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<float>(N128 w, float t), hex://vfuncs/generic?vcount#vcount_g[32f](n128,32f)
; vcount_g[32f](n128,32f)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x04,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,4                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 04 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<double>(N128 w, double t), hex://vfuncs/generic?vcount#vcount_g[64f](n128,64f)
; vcount_g[64f](n128,64f)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x02,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,2                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 02 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<byte>(N256 w, byte t), hex://vfuncs/generic?vcount#vcount_g[8u](n256,8u)
; vcount_g[8u](n256,8u)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x20,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,20h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 20 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<sbyte>(N256 w, sbyte t), hex://vfuncs/generic?vcount#vcount_g[8i](n256,8i)
; vcount_g[8i](n256,8i)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x20,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,20h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 20 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<ushort>(N256 w, ushort t), hex://vfuncs/generic?vcount#vcount_g[16u](n256,16u)
; vcount_g[16u](n256,16u)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x10,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,10h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 10 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<short>(N256 w, short t), hex://vfuncs/generic?vcount#vcount_g[16i](n256,16i)
; vcount_g[16i](n256,16i)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x10,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,10h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 10 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<uint>(N256 w, uint t), hex://vfuncs/generic?vcount#vcount_g[32u](n256,32u)
; vcount_g[32u](n256,32u)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x08,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,8                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 08 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<int>(N256 w, int t), hex://vfuncs/generic?vcount#vcount_g[32i](n256,32i)
; vcount_g[32i](n256,32i)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x08,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,8                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 08 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<ulong>(N256 w, ulong t), hex://vfuncs/generic?vcount#vcount_g[64u](n256,64u)
; vcount_g[64u](n256,64u)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x04,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,4                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 04 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<long>(N256 w, long t), hex://vfuncs/generic?vcount#vcount_g[64i](n256,64i)
; vcount_g[64i](n256,64i)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x04,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,4                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 04 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<float>(N256 w, float t), hex://vfuncs/generic?vcount#vcount_g[32f](n256,32f)
; vcount_g[32f](n256,32f)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x08,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,8                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 08 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<double>(N256 w, double t), hex://vfuncs/generic?vcount#vcount_g[64f](n256,64f)
; vcount_g[64f](n256,64f)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x04,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,4                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 04 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<byte>(N512 w, byte t), hex://vfuncs/generic?vcount#vcount_g[8u](n512,8u)
; vcount_g[8u](n512,8u)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x40,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,40h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 40 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<sbyte>(N512 w, sbyte t), hex://vfuncs/generic?vcount#vcount_g[8i](n512,8i)
; vcount_g[8i](n512,8i)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x40,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,40h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 40 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<ushort>(N512 w, ushort t), hex://vfuncs/generic?vcount#vcount_g[16u](n512,16u)
; vcount_g[16u](n512,16u)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x20,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,20h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 20 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<short>(N512 w, short t), hex://vfuncs/generic?vcount#vcount_g[16i](n512,16i)
; vcount_g[16i](n512,16i)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x20,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,20h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 20 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<uint>(N512 w, uint t), hex://vfuncs/generic?vcount#vcount_g[32u](n512,32u)
; vcount_g[32u](n512,32u)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x10,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,10h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 10 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<int>(N512 w, int t), hex://vfuncs/generic?vcount#vcount_g[32i](n512,32i)
; vcount_g[32i](n512,32i)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x10,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,10h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 10 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<ulong>(N512 w, ulong t), hex://vfuncs/generic?vcount#vcount_g[64u](n512,64u)
; vcount_g[64u](n512,64u)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x08,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,8                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 08 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<long>(N512 w, long t), hex://vfuncs/generic?vcount#vcount_g[64i](n512,64i)
; vcount_g[64i](n512,64i)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x08,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,8                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 08 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<float>(N512 w, float t), hex://vfuncs/generic?vcount#vcount_g[32f](n512,32f)
; vcount_g[32f](n512,32f)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x10,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,10h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 10 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<double>(N512 w, double t), hex://vfuncs/generic?vcount#vcount_g[64f](n512,64f)
; vcount_g[64f](n512,64f)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x08,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,8                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 08 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> vzero<byte>(N128 w, byte t), hex://vfuncs/generic?vzero#vzero_g[8u](n128,8u)
; vzero_g[8u](n128,8u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf8,0x57,0xc0,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps xmm0,xmm0,xmm0                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 f8 57 c0}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> vzero<sbyte>(N128 w, sbyte t), hex://vfuncs/generic?vzero#vzero_g[8i](n128,8i)
; vzero_g[8i](n128,8i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf8,0x57,0xc0,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps xmm0,xmm0,xmm0                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 f8 57 c0}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> vzero<ushort>(N128 w, ushort t), hex://vfuncs/generic?vzero#vzero_g[16u](n128,16u)
; vzero_g[16u](n128,16u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf8,0x57,0xc0,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps xmm0,xmm0,xmm0                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 f8 57 c0}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> vzero<short>(N128 w, short t), hex://vfuncs/generic?vzero#vzero_g[16i](n128,16i)
; vzero_g[16i](n128,16i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf8,0x57,0xc0,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps xmm0,xmm0,xmm0                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 f8 57 c0}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> vzero<uint>(N128 w, uint t), hex://vfuncs/generic?vzero#vzero_g[32u](n128,32u)
; vzero_g[32u](n128,32u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf8,0x57,0xc0,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps xmm0,xmm0,xmm0                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 f8 57 c0}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> vzero<int>(N128 w, int t), hex://vfuncs/generic?vzero#vzero_g[32i](n128,32i)
; vzero_g[32i](n128,32i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf8,0x57,0xc0,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps xmm0,xmm0,xmm0                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 f8 57 c0}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> vzero<ulong>(N128 w, ulong t), hex://vfuncs/generic?vzero#vzero_g[64u](n128,64u)
; vzero_g[64u](n128,64u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf8,0x57,0xc0,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps xmm0,xmm0,xmm0                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 f8 57 c0}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> vzero<long>(N128 w, long t), hex://vfuncs/generic?vzero#vzero_g[64i](n128,64i)
; vzero_g[64i](n128,64i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf8,0x57,0xc0,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps xmm0,xmm0,xmm0                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 f8 57 c0}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> vzero<float>(N128 w, float t), hex://vfuncs/generic?vzero#vzero_g[32f](n128,32f)
; vzero_g[32f](n128,32f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf8,0x57,0xc0,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps xmm0,xmm0,xmm0                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 f8 57 c0}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> vzero<double>(N128 w, double t), hex://vfuncs/generic?vzero#vzero_g[64f](n128,64f)
; vzero_g[64f](n128,64f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf8,0x57,0xc0,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps xmm0,xmm0,xmm0                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 f8 57 c0}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<byte> vzero<byte>(N256 w, byte t), hex://vfuncs/generic?vzero#vzero_g[8u](n256,8u)
; vzero_g[8u](n256,8u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfc,0x57,0xc0,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps ymm0,ymm0,ymm0                   ; VXORPS ymm1, ymm2, ymm3/m256 || VEX.256.0F.WIG 57 /r || encoded[4]{c5 fc 57 c0}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<sbyte> vzero<sbyte>(N256 w, sbyte t), hex://vfuncs/generic?vzero#vzero_g[8i](n256,8i)
; vzero_g[8i](n256,8i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfc,0x57,0xc0,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps ymm0,ymm0,ymm0                   ; VXORPS ymm1, ymm2, ymm3/m256 || VEX.256.0F.WIG 57 /r || encoded[4]{c5 fc 57 c0}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ushort> vzero<ushort>(N256 w, ushort t), hex://vfuncs/generic?vzero#vzero_g[16u](n256,16u)
; vzero_g[16u](n256,16u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfc,0x57,0xc0,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps ymm0,ymm0,ymm0                   ; VXORPS ymm1, ymm2, ymm3/m256 || VEX.256.0F.WIG 57 /r || encoded[4]{c5 fc 57 c0}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<short> vzero<short>(N256 w, short t), hex://vfuncs/generic?vzero#vzero_g[16i](n256,16i)
; vzero_g[16i](n256,16i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfc,0x57,0xc0,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps ymm0,ymm0,ymm0                   ; VXORPS ymm1, ymm2, ymm3/m256 || VEX.256.0F.WIG 57 /r || encoded[4]{c5 fc 57 c0}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<uint> vzero<uint>(N256 w, uint t), hex://vfuncs/generic?vzero#vzero_g[32u](n256,32u)
; vzero_g[32u](n256,32u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfc,0x57,0xc0,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps ymm0,ymm0,ymm0                   ; VXORPS ymm1, ymm2, ymm3/m256 || VEX.256.0F.WIG 57 /r || encoded[4]{c5 fc 57 c0}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<int> vzero<int>(N256 w, int t), hex://vfuncs/generic?vzero#vzero_g[32i](n256,32i)
; vzero_g[32i](n256,32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfc,0x57,0xc0,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps ymm0,ymm0,ymm0                   ; VXORPS ymm1, ymm2, ymm3/m256 || VEX.256.0F.WIG 57 /r || encoded[4]{c5 fc 57 c0}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ulong> vzero<ulong>(N256 w, ulong t), hex://vfuncs/generic?vzero#vzero_g[64u](n256,64u)
; vzero_g[64u](n256,64u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfc,0x57,0xc0,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps ymm0,ymm0,ymm0                   ; VXORPS ymm1, ymm2, ymm3/m256 || VEX.256.0F.WIG 57 /r || encoded[4]{c5 fc 57 c0}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<long> vzero<long>(N256 w, long t), hex://vfuncs/generic?vzero#vzero_g[64i](n256,64i)
; vzero_g[64i](n256,64i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfc,0x57,0xc0,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps ymm0,ymm0,ymm0                   ; VXORPS ymm1, ymm2, ymm3/m256 || VEX.256.0F.WIG 57 /r || encoded[4]{c5 fc 57 c0}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<float> vzero<float>(N256 w, float t), hex://vfuncs/generic?vzero#vzero_g[32f](n256,32f)
; vzero_g[32f](n256,32f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfc,0x57,0xc0,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps ymm0,ymm0,ymm0                   ; VXORPS ymm1, ymm2, ymm3/m256 || VEX.256.0F.WIG 57 /r || encoded[4]{c5 fc 57 c0}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<double> vzero<double>(N256 w, double t), hex://vfuncs/generic?vzero#vzero_g[64f](n256,64f)
; vzero_g[64f](n256,64f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfc,0x57,0xc0,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps ymm0,ymm0,ymm0                   ; VXORPS ymm1, ymm2, ymm3/m256 || VEX.256.0F.WIG 57 /r || encoded[4]{c5 fc 57 c0}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<byte> span<byte>(Vector128<byte> src), hex://vfuncs/generic?span#span_g[8u](v128x8u)
; span_g[8u](v128x8u)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x5d,0x42,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x00,0x87,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c83c19d0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 5d 42 d3 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 00 87 bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<sbyte> span<sbyte>(Vector128<sbyte> src), hex://vfuncs/generic?span#span_g[8i](v128x8i)
; span_g[8i](v128x8i)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x2d,0x3e,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x60,0x82,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c83c1a40h                      ; CALL rel32 || E8 cd || encoded[5]{e8 2d 3e d3 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 60 82 bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<ushort> span<ushort>(Vector128<ushort> src), hex://vfuncs/generic?span#span_g[16u](v128x16u)
; span_g[16u](v128x16u)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xfd,0x3d,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0xc0,0x81,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c83c1ab0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 fd 3d d3 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c0 81 bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<short> span<short>(Vector128<short> src), hex://vfuncs/generic?span#span_g[16i](v128x16i)
; span_g[16i](v128x16i)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xcd,0x3d,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x20,0x81,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c83c1b20h                      ; CALL rel32 || E8 cd || encoded[5]{e8 cd 3d d3 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 20 81 bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<uint> span<uint>(Vector128<uint> src), hex://vfuncs/generic?span#span_g[32u](v128x32u)
; span_g[32u](v128x32u)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x9d,0x39,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x80,0x7c,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c83c1b90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 9d 39 d3 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 80 7c bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<int> span<int>(Vector128<int> src), hex://vfuncs/generic?span#span_g[32i](v128x32i)
; span_g[32i](v128x32i)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x6d,0x39,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0xe0,0x7b,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c83c1c00h                      ; CALL rel32 || E8 cd || encoded[5]{e8 6d 39 d3 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e0 7b bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<ulong> span<ulong>(Vector128<ulong> src), hex://vfuncs/generic?span#span_g[64u](v128x64u)
; span_g[64u](v128x64u)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x3d,0x39,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x40,0x7b,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c83c1c70h                      ; CALL rel32 || E8 cd || encoded[5]{e8 3d 39 d3 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 40 7b bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<long> span<long>(Vector128<long> src), hex://vfuncs/generic?span#span_g[64i](v128x64i)
; span_g[64i](v128x64i)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x0d,0x39,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0xa0,0x7a,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c83c1ce0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 0d 39 d3 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a0 7a bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<float> span<float>(Vector128<float> src), hex://vfuncs/generic?span#span_g[32f](v128x32f)
; span_g[32f](v128x32f)[126] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0xc5,0xe0,0x57,0xdb,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xdc,0x34,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xf8,0x11,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0xff,0x75,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h vxorps xmm3,xmm3,xmm3                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 e0 57 db}
0049h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004fh call 7ff7c83c1d50h                      ; CALL rel32 || E8 cd || encoded[5]{e8 dc 34 d3 ff}
0054h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0059h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005ch vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
0060h vmovups [rax],xmm0                      ; VMOVUPS xmm2/m128, xmm1 || VEX.128.0F.WIG 11 /r || encoded[4]{c5 f8 11 00}
0064h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0069h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006ch call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ff 75 bd 5e}
0071h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0073h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0076h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ah pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007bh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007ch pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<double> span<double>(Vector128<double> src), hex://vfuncs/generic?span#span_g[64f](v128x64f)
; span_g[64f](v128x64f)[126] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0xc5,0xe0,0x57,0xdb,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xac,0x34,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xf9,0x11,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x5f,0x75,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h vxorps xmm3,xmm3,xmm3                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 e0 57 db}
0049h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004fh call 7ff7c83c1dc0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ac 34 d3 ff}
0054h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0059h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005ch vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
0060h vmovupd [rax],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 00}
0064h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0069h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006ch call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 5f 75 bd 5e}
0071h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0073h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0076h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ah pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007bh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007ch pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<byte> span<byte>(Vector256<byte> src), hex://vfuncs/generic?span#span_g[8u](v256x8u)
; span_g[8u](v256x8u)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x7d,0x34,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0xb0,0x70,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c83c2240h                      ; CALL rel32 || E8 cd || encoded[5]{e8 7d 34 d3 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b0 70 bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<sbyte> span<sbyte>(Vector256<sbyte> src), hex://vfuncs/generic?span#span_g[8i](v256x8i)
; span_g[8i](v256x8i)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x4d,0x34,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x10,0x70,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c83c22b0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 4d 34 d3 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 10 70 bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<ushort> span<ushort>(Vector256<ushort> src), hex://vfuncs/generic?span#span_g[16u](v256x16u)
; span_g[16u](v256x16u)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x1d,0x34,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x70,0x6f,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c83c2320h                      ; CALL rel32 || E8 cd || encoded[5]{e8 1d 34 d3 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 70 6f bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<short> span<short>(Vector256<short> src), hex://vfuncs/generic?span#span_g[16i](v256x16i)
; span_g[16i](v256x16i)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xdd,0x2f,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0xc0,0x6a,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c83c2390h                      ; CALL rel32 || E8 cd || encoded[5]{e8 dd 2f d3 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c0 6a bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<uint> span<uint>(Vector256<uint> src), hex://vfuncs/generic?span#span_g[32u](v256x32u)
; span_g[32u](v256x32u)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0xad,0x2f,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x20,0x6a,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c83c2400h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ad 2f d3 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 20 6a bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<int> span<int>(Vector256<int> src), hex://vfuncs/generic?span#span_g[32i](v256x32i)
; span_g[32i](v256x32i)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x7d,0x2f,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x80,0x69,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c83c2470h                      ; CALL rel32 || E8 cd || encoded[5]{e8 7d 2f d3 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 80 69 bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<ulong> span<ulong>(Vector256<ulong> src), hex://vfuncs/generic?span#span_g[64u](v256x64u)
; span_g[64u](v256x64u)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x4d,0x2f,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0xe0,0x68,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c83c24e0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 4d 2f d3 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e0 68 bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<long> span<long>(Vector256<long> src), hex://vfuncs/generic?span#span_g[64i](v256x64i)
; span_g[64i](v256x64i)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x1d,0x2f,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x40,0x68,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c83c2550h                      ; CALL rel32 || E8 cd || encoded[5]{e8 1d 2f d3 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 40 68 bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<float> span<float>(Vector256<float> src), hex://vfuncs/generic?span#span_g[32f](v256x32f)
; span_g[32f](v256x32f)[129] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0xc5,0xe0,0x57,0xdb,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xec,0x2e,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfc,0x11,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x9f,0x67,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h vxorps xmm3,xmm3,xmm3                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 e0 57 db}
0049h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004fh call 7ff7c83c25c0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ec 2e d3 ff}
0054h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0059h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005ch vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
0060h vmovups [rax],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 00}
0064h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0069h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006ch call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 9f 67 bd 5e}
0071h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0073h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0076h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0079h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007dh pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007eh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007fh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
0080h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<double> span<double>(Vector256<double> src), hex://vfuncs/generic?span#span_g[64f](v256x64f)
; span_g[64f](v256x64f)[129] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0xc5,0xe0,0x57,0xdb,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xac,0x2a,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x11,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0xef,0x62,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h vxorps xmm3,xmm3,xmm3                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 e0 57 db}
0049h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004fh call 7ff7c83c2630h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ac 2a d3 ff}
0054h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0059h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005ch vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
0060h vmovupd [rax],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 00}
0064h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0069h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006ch call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ef 62 bd 5e}
0071h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0073h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0076h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0079h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007dh pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007eh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007fh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
0080h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<byte> span<byte>(Vector512<byte> src), hex://vfuncs/generic?span#span_g[8u](v512x8u)
; span_g[8u](v512x8u)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x6d,0x26,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x30,0x5e,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c83c26a0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 6d 26 d3 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0078h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 30 5e bd 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<sbyte> span<sbyte>(Vector512<sbyte> src), hex://vfuncs/generic?span#span_g[8i](v512x8i)
; span_g[8i](v512x8i)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x2d,0x26,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x80,0x5d,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c83c2710h                      ; CALL rel32 || E8 cd || encoded[5]{e8 2d 26 d3 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0078h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 80 5d bd 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<ushort> span<ushort>(Vector512<ushort> src), hex://vfuncs/generic?span#span_g[16u](v512x16u)
; span_g[16u](v512x16u)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xed,0x25,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0xd0,0x5c,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c83c2780h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ed 25 d3 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0078h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d0 5c bd 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<short> span<short>(Vector512<short> src), hex://vfuncs/generic?span#span_g[16i](v512x16i)
; span_g[16i](v512x16i)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xad,0x25,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x20,0x5c,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c83c27f0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ad 25 d3 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0078h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 20 5c bd 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<uint> span<uint>(Vector512<uint> src), hex://vfuncs/generic?span#span_g[32u](v512x32u)
; span_g[32u](v512x32u)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x5d,0x21,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x60,0x57,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c83c2860h                      ; CALL rel32 || E8 cd || encoded[5]{e8 5d 21 d3 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0078h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 60 57 bd 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<int> span<int>(Vector512<int> src), hex://vfuncs/generic?span#span_g[32i](v512x32i)
; span_g[32i](v512x32i)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x1d,0x21,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0xb0,0x56,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c83c28d0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 1d 21 d3 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0078h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b0 56 bd 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<ulong> span<ulong>(Vector512<ulong> src), hex://vfuncs/generic?span#span_g[64u](v512x64u)
; span_g[64u](v512x64u)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0xdd,0x20,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x00,0x56,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c83c2940h                      ; CALL rel32 || E8 cd || encoded[5]{e8 dd 20 d3 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0078h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 00 56 bd 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<long> span<long>(Vector512<long> src), hex://vfuncs/generic?span#span_g[64i](v512x64i)
; span_g[64i](v512x64i)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x9d,0x20,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x50,0x55,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c83c29b0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 9d 20 d3 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0078h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 50 55 bd 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<float> span<float>(Vector512<float> src), hex://vfuncs/generic?span#span_g[32f](v512x32f)
; span_g[32f](v512x32f)[145] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0xc5,0xe0,0x57,0xdb,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x5c,0x20,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfc,0x11,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfc,0x11,0x08,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x9f,0x54,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h vxorps xmm3,xmm3,xmm3                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 e0 57 db}
0049h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004fh call 7ff7c83c2a20h                      ; CALL rel32 || E8 cd || encoded[5]{e8 5c 20 d3 ff}
0054h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0059h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005ch vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
0060h vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0065h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0068h vmovups [rdx],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 02}
006ch add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0070h vmovups [rax],ymm1                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 08}
0074h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0079h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
007ch call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 9f 54 bd 5e}
0081h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0083h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0086h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0089h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008dh pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008eh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008fh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
0090h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<double> span<double>(Vector512<double> src), hex://vfuncs/generic?span#span_g[64f](v512x64f)
; span_g[64f](v512x64f)[145] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0xc5,0xe0,0x57,0xdb,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x1c,0x20,0xd3,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfd,0x11,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfd,0x11,0x08,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0xef,0x53,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h vxorps xmm3,xmm3,xmm3                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 e0 57 db}
0049h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004fh call 7ff7c83c2a90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 1c 20 d3 ff}
0054h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0059h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005ch vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
0060h vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0065h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0068h vmovupd [rdx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 02}
006ch add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0070h vmovupd [rax],ymm1                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 08}
0074h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0079h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
007ch call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ef 53 bd 5e}
0081h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0083h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0086h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0089h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008dh pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008eh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008fh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
0090h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector128<byte> src, ref Fixed128 dst), hex://vfuncs/generic?vstore#vstore_g[8u](v128x8u)
; vstore_g[8u](v128x8u)[14] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x02,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovdqu xmmword ptr [rdx],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 02}
000dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector128<sbyte> src, ref Fixed128 dst), hex://vfuncs/generic?vstore#vstore_g[8i](v128x8i)
; vstore_g[8i](v128x8i)[14] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x02,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovdqu xmmword ptr [rdx],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 02}
000dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector128<ushort> src, ref Fixed128 dst), hex://vfuncs/generic?vstore#vstore_g[16u](v128x16u)
; vstore_g[16u](v128x16u)[14] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x02,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovdqu xmmword ptr [rdx],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 02}
000dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector128<short> src, ref Fixed128 dst), hex://vfuncs/generic?vstore#vstore_g[16i](v128x16i)
; vstore_g[16i](v128x16i)[14] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x02,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovdqu xmmword ptr [rdx],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 02}
000dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector128<uint> src, ref Fixed128 dst), hex://vfuncs/generic?vstore#vstore_g[32u](v128x32u)
; vstore_g[32u](v128x32u)[14] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x02,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovdqu xmmword ptr [rdx],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 02}
000dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector128<int> src, ref Fixed128 dst), hex://vfuncs/generic?vstore#vstore_g[32i](v128x32i)
; vstore_g[32i](v128x32i)[14] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x02,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovdqu xmmword ptr [rdx],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 02}
000dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector128<ulong> src, ref Fixed128 dst), hex://vfuncs/generic?vstore#vstore_g[64u](v128x64u)
; vstore_g[64u](v128x64u)[14] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x02,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovdqu xmmword ptr [rdx],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 02}
000dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector128<long> src, ref Fixed128 dst), hex://vfuncs/generic?vstore#vstore_g[64i](v128x64i)
; vstore_g[64i](v128x64i)[14] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x02,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovdqu xmmword ptr [rdx],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 02}
000dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector128<float> src, ref Fixed128 dst), hex://vfuncs/generic?vstore#vstore_g[32f](v128x32f)
; vstore_g[32f](v128x32f)[14] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xf8,0x11,0x02,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovups [rdx],xmm0                      ; VMOVUPS xmm2/m128, xmm1 || VEX.128.0F.WIG 11 /r || encoded[4]{c5 f8 11 02}
000dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector128<double> src, ref Fixed128 dst), hex://vfuncs/generic?vstore#vstore_g[64f](v128x64f)
; vstore_g[64f](v128x64f)[14] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x11,0x02,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovupd [rdx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 02}
000dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector256<byte> src, ref Fixed256 dst), hex://vfuncs/generic?vstore#vstore_g[8u](v256x8u)
; vstore_g[8u](v256x8u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x02,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
000dh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector256<sbyte> src, ref Fixed256 dst), hex://vfuncs/generic?vstore#vstore_g[8i](v256x8i)
; vstore_g[8i](v256x8i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x02,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
000dh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector256<ushort> src, ref Fixed256 dst), hex://vfuncs/generic?vstore#vstore_g[16u](v256x16u)
; vstore_g[16u](v256x16u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x02,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
000dh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector256<short> src, ref Fixed256 dst), hex://vfuncs/generic?vstore#vstore_g[16i](v256x16i)
; vstore_g[16i](v256x16i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x02,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
000dh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector256<uint> src, ref Fixed256 dst), hex://vfuncs/generic?vstore#vstore_g[32u](v256x32u)
; vstore_g[32u](v256x32u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x02,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
000dh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector256<int> src, ref Fixed256 dst), hex://vfuncs/generic?vstore#vstore_g[32i](v256x32i)
; vstore_g[32i](v256x32i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x02,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
000dh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector256<ulong> src, ref Fixed256 dst), hex://vfuncs/generic?vstore#vstore_g[64u](v256x64u)
; vstore_g[64u](v256x64u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x02,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
000dh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector256<long> src, ref Fixed256 dst), hex://vfuncs/generic?vstore#vstore_g[64i](v256x64i)
; vstore_g[64i](v256x64i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x02,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
000dh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector256<float> src, ref Fixed256 dst), hex://vfuncs/generic?vstore#vstore_g[32f](v256x32f)
; vstore_g[32f](v256x32f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0xc5,0xfc,0x11,0x02,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h vmovups [rdx],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 02}
000dh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector256<double> src, ref Fixed256 dst), hex://vfuncs/generic?vstore#vstore_g[64f](v256x64f)
; vstore_g[64f](v256x64f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x02,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h vmovupd [rdx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 02}
000dh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector128<byte> src, Span<byte> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[8u](v128x8u,span8u,32i)
; vstore_g[8u](v128x8u,span8u,32i)[23] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x03,0xc2,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
0012h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0016h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector128<sbyte> src, Span<sbyte> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[8i](v128x8i,span8i,32i)
; vstore_g[8i](v128x8i,span8i,32i)[23] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x03,0xc2,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
0012h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0016h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector128<ushort> src, Span<ushort> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[16u](v128x16u,span16u,32i)
; vstore_g[16u](v128x16u,span16u,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x50,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 50}
0013h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector128<short> src, Span<short> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[16i](v128x16i,span16i,32i)
; vstore_g[16i](v128x16i,span16i,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x50,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 50}
0013h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector128<uint> src, Span<uint> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32u](v128x32u,span32u,32i)
; vstore_g[32u](v128x32u,span32u,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0013h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector128<int> src, Span<int> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32i](v128x32i,span32i,32i)
; vstore_g[32i](v128x32i,span32i,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0013h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector128<ulong> src, Span<ulong> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64u](v128x64u,span64u,32i)
; vstore_g[64u](v128x64u,span64u,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0013h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector128<long> src, Span<long> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64i](v128x64i,span64i,32i)
; vstore_g[64i](v128x64i,span64i,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0013h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector128<float> src, Span<float> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32f](v128x32f,span32f,32i)
; vstore_g[32f](v128x32f,span32f,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xf8,0x11,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0013h vmovups [rax],xmm0                      ; VMOVUPS xmm2/m128, xmm1 || VEX.128.0F.WIG 11 /r || encoded[4]{c5 f8 11 00}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector128<double> src, Span<double> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64f](v128x64f,span64f,32i)
; vstore_g[64f](v128x64f,span64f,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xf9,0x11,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0013h vmovupd [rax],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 00}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector256<byte> src, Span<byte> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[8u](v256x8u,span8u,32i)
; vstore_g[8u](v256x8u,span8u,32i)[26] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x03,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
0012h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0016h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0019h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector256<sbyte> src, Span<sbyte> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[8i](v256x8i,span8i,32i)
; vstore_g[8i](v256x8i,span8i,32i)[26] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x03,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
0012h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0016h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0019h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector256<ushort> src, Span<ushort> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[16u](v256x16u,span16u,32i)
; vstore_g[16u](v256x16u,span16u,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x50,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 50}
0013h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0017h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector256<short> src, Span<short> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[16i](v256x16i,span16i,32i)
; vstore_g[16i](v256x16i,span16i,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x50,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 50}
0013h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0017h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector256<uint> src, Span<uint> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32u](v256x32u,span32u,32i)
; vstore_g[32u](v256x32u,span32u,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0013h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0017h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector256<int> src, Span<int> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32i](v256x32i,span32i,32i)
; vstore_g[32i](v256x32i,span32i,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0013h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0017h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector256<ulong> src, Span<ulong> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64u](v256x64u,span64u,32i)
; vstore_g[64u](v256x64u,span64u,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0013h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0017h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector256<long> src, Span<long> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64i](v256x64i,span64i,32i)
; vstore_g[64i](v256x64i,span64i,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0013h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0017h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector256<float> src, Span<float> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32f](v256x32f,span32f,32i)
; vstore_g[32f](v256x32f,span32f,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfc,0x11,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0013h vmovups [rax],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 00}
0017h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector256<double> src, Span<double> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64f](v256x64f,span64f,32i)
; vstore_g[64f](v256x64f,span64f,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfd,0x11,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0013h vmovupd [rax],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 00}
0017h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector512<byte> src, Span<byte> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[8u](v512x8u,span8u,32i)
; vstore_g[8u](v512x8u,span8u,32i)[45] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x03,0xd0,0xc5,0xfe,0x7f,0x02,0x41,0x83,0xc0,0x20,0x49,0x63,0xd0,0x48,0x03,0xc2,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0014h add rdx,rax                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 d0}
0017h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
001bh add r8d,20h                             ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 20}
001fh movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0022h add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
0025h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0029h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector512<sbyte> src, Span<sbyte> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[8i](v512x8i,span8i,32i)
; vstore_g[8i](v512x8i,span8i,32i)[45] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x03,0xd0,0xc5,0xfe,0x7f,0x02,0x41,0x83,0xc0,0x20,0x49,0x63,0xd0,0x48,0x03,0xc2,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0014h add rdx,rax                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 d0}
0017h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
001bh add r8d,20h                             ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 20}
001fh movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0022h add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
0025h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0029h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector512<ushort> src, Span<ushort> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[16u](v512x16u,span16u,32i)
; vstore_g[16u](v512x16u,span16u,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x14,0x50,0xc5,0xfe,0x7f,0x02,0x41,0x83,0xc0,0x10,0x49,0x63,0xd0,0x48,0x8d,0x04,0x50,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0014h lea rdx,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 14 50}
0018h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
001ch add r8d,10h                             ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 10}
0020h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0023h lea rax,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 50}
0027h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector512<short> src, Span<short> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[16i](v512x16i,span16i,32i)
; vstore_g[16i](v512x16i,span16i,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x14,0x50,0xc5,0xfe,0x7f,0x02,0x41,0x83,0xc0,0x10,0x49,0x63,0xd0,0x48,0x8d,0x04,0x50,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0014h lea rdx,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 14 50}
0018h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
001ch add r8d,10h                             ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 10}
0020h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0023h lea rax,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 50}
0027h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector512<uint> src, Span<uint> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32u](v512x32u,span32u,32i)
; vstore_g[32u](v512x32u,span32u,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x14,0x90,0xc5,0xfe,0x7f,0x02,0x41,0x83,0xc0,0x08,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0014h lea rdx,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 14 90}
0018h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
001ch add r8d,8                               ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 08}
0020h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0023h lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0027h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector512<int> src, Span<int> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32i](v512x32i,span32i,32i)
; vstore_g[32i](v512x32i,span32i,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x14,0x90,0xc5,0xfe,0x7f,0x02,0x41,0x83,0xc0,0x08,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0014h lea rdx,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 14 90}
0018h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
001ch add r8d,8                               ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 08}
0020h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0023h lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0027h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector512<ulong> src, Span<ulong> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64u](v512x64u,span64u,32i)
; vstore_g[64u](v512x64u,span64u,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x14,0xd0,0xc5,0xfe,0x7f,0x02,0x41,0x83,0xc0,0x04,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0014h lea rdx,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 14 d0}
0018h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
001ch add r8d,4                               ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 04}
0020h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0023h lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0027h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector512<long> src, Span<long> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64i](v512x64i,span64i,32i)
; vstore_g[64i](v512x64i,span64i,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x14,0xd0,0xc5,0xfe,0x7f,0x02,0x41,0x83,0xc0,0x04,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0014h lea rdx,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 14 d0}
0018h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
001ch add r8d,4                               ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 04}
0020h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0023h lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0027h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector512<float> src, Span<float> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32f](v512x32f,span32f,32i)
; vstore_g[32f](v512x32f,span32f,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x14,0x90,0xc5,0xfc,0x11,0x02,0x41,0x83,0xc0,0x08,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfc,0x11,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0014h lea rdx,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 14 90}
0018h vmovups [rdx],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 02}
001ch add r8d,8                               ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 08}
0020h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0023h lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0027h vmovups [rax],ymm1                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector512<double> src, Span<double> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64f](v512x64f,span64f,32i)
; vstore_g[64f](v512x64f,span64f,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x14,0xd0,0xc5,0xfd,0x11,0x02,0x41,0x83,0xc0,0x04,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfd,0x11,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0014h lea rdx,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 14 d0}
0018h vmovupd [rdx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 02}
001ch add r8d,4                               ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 04}
0020h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0023h lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0027h vmovupd [rax],ymm1                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector512<byte> src, ref byte dst, int offset), hex://vfuncs/generic?vstore#vstore_g[8u](v512x8u,8u~ref,32i)
; vstore_g[8u](v512x8u,8u~ref,32i)[42] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x03,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xfd,0x10,0x41,0x20,0x41,0x83,0xc0,0x20,0x49,0x63,0xc0,0x48,0x03,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
000fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0013h vmovupd ymm0,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 41 20}
0018h add r8d,20h                             ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 20}
001ch movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
001fh add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
0022h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0026h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector512<sbyte> src, ref sbyte dst, int offset), hex://vfuncs/generic?vstore#vstore_g[8i](v512x8i,8i~ref,32i)
; vstore_g[8i](v512x8i,8i~ref,32i)[42] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x03,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xfd,0x10,0x41,0x20,0x41,0x83,0xc0,0x20,0x49,0x63,0xc0,0x48,0x03,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
000fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0013h vmovupd ymm0,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 41 20}
0018h add r8d,20h                             ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 20}
001ch movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
001fh add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
0022h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0026h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector512<ushort> src, ref ushort dst, int offset), hex://vfuncs/generic?vstore#vstore_g[16u](v512x16u,16u~ref,32i)
; vstore_g[16u](v512x16u,16u~ref,32i)[44] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x42,0xc5,0xfe,0x7f,0x00,0xc5,0xfd,0x10,0x41,0x20,0x41,0x83,0xc0,0x10,0x49,0x63,0xc0,0x48,0x8d,0x04,0x42,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 42}
0010h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0014h vmovupd ymm0,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 41 20}
0019h add r8d,10h                             ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 10}
001dh movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
0020h lea rax,[rdx+rax*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 42}
0024h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0028h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector512<short> src, ref short dst, int offset), hex://vfuncs/generic?vstore#vstore_g[16i](v512x16i,16i~ref,32i)
; vstore_g[16i](v512x16i,16i~ref,32i)[44] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x42,0xc5,0xfe,0x7f,0x00,0xc5,0xfd,0x10,0x41,0x20,0x41,0x83,0xc0,0x10,0x49,0x63,0xc0,0x48,0x8d,0x04,0x42,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 42}
0010h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0014h vmovupd ymm0,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 41 20}
0019h add r8d,10h                             ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 10}
001dh movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
0020h lea rax,[rdx+rax*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 42}
0024h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0028h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector512<uint> src, ref uint dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32u](v512x32u,32u~ref,32i)
; vstore_g[32u](v512x32u,32u~ref,32i)[44] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x82,0xc5,0xfe,0x7f,0x00,0xc5,0xfd,0x10,0x41,0x20,0x41,0x83,0xc0,0x08,0x49,0x63,0xc0,0x48,0x8d,0x04,0x82,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 82}
0010h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0014h vmovupd ymm0,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 41 20}
0019h add r8d,8                               ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 08}
001dh movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
0020h lea rax,[rdx+rax*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 82}
0024h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0028h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector512<int> src, ref int dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32i](v512x32i,32i~ref,32i)
; vstore_g[32i](v512x32i,32i~ref,32i)[44] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x82,0xc5,0xfe,0x7f,0x00,0xc5,0xfd,0x10,0x41,0x20,0x41,0x83,0xc0,0x08,0x49,0x63,0xc0,0x48,0x8d,0x04,0x82,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 82}
0010h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0014h vmovupd ymm0,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 41 20}
0019h add r8d,8                               ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 08}
001dh movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
0020h lea rax,[rdx+rax*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 82}
0024h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0028h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector512<ulong> src, ref ulong dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64u](v512x64u,64u~ref,32i)
; vstore_g[64u](v512x64u,64u~ref,32i)[44] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xfd,0x10,0x41,0x20,0x41,0x83,0xc0,0x04,0x49,0x63,0xc0,0x48,0x8d,0x04,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 c2}
0010h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0014h vmovupd ymm0,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 41 20}
0019h add r8d,4                               ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 04}
001dh movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
0020h lea rax,[rdx+rax*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 c2}
0024h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0028h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector512<long> src, ref long dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64i](v512x64i,64i~ref,32i)
; vstore_g[64i](v512x64i,64i~ref,32i)[44] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xfd,0x10,0x41,0x20,0x41,0x83,0xc0,0x04,0x49,0x63,0xc0,0x48,0x8d,0x04,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 c2}
0010h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0014h vmovupd ymm0,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 41 20}
0019h add r8d,4                               ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 04}
001dh movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
0020h lea rax,[rdx+rax*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 c2}
0024h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0028h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector512<float> src, ref float dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32f](v512x32f,32f~ref,32i)
; vstore_g[32f](v512x32f,32f~ref,32i)[44] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x82,0xc5,0xfc,0x11,0x00,0xc5,0xfd,0x10,0x41,0x20,0x41,0x83,0xc0,0x08,0x49,0x63,0xc0,0x48,0x8d,0x04,0x82,0xc5,0xfc,0x11,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 82}
0010h vmovups [rax],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 00}
0014h vmovupd ymm0,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 41 20}
0019h add r8d,8                               ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 08}
001dh movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
0020h lea rax,[rdx+rax*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 82}
0024h vmovups [rax],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 00}
0028h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector512<double> src, ref double dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64f](v512x64f,64f~ref,32i)
; vstore_g[64f](v512x64f,64f~ref,32i)[44] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0xc2,0xc5,0xfd,0x11,0x00,0xc5,0xfd,0x10,0x41,0x20,0x41,0x83,0xc0,0x04,0x49,0x63,0xc0,0x48,0x8d,0x04,0xc2,0xc5,0xfd,0x11,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 c2}
0010h vmovupd [rax],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 00}
0014h vmovupd ymm0,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 41 20}
0019h add r8d,4                               ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 04}
001dh movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
0020h lea rax,[rdx+rax*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 c2}
0024h vmovupd [rax],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 00}
0028h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector128<byte> src, in Block128<byte> dst), hex://vfuncs/generic?vstore#vstore_g[8u](v128x8u,b128x8u~in)
; vstore_g[8u](v128x8u,b128x8u~in)[17] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector128<sbyte> src, in Block128<sbyte> dst), hex://vfuncs/generic?vstore#vstore_g[8i](v128x8i,b128x8i~in)
; vstore_g[8i](v128x8i,b128x8i~in)[17] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector128<ushort> src, in Block128<ushort> dst), hex://vfuncs/generic?vstore#vstore_g[16u](v128x16u,b128x16u~in)
; vstore_g[16u](v128x16u,b128x16u~in)[17] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector128<short> src, in Block128<short> dst), hex://vfuncs/generic?vstore#vstore_g[16i](v128x16i,b128x16i~in)
; vstore_g[16i](v128x16i,b128x16i~in)[17] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector128<uint> src, in Block128<uint> dst), hex://vfuncs/generic?vstore#vstore_g[32u](v128x32u,b128x32u~in)
; vstore_g[32u](v128x32u,b128x32u~in)[17] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector128<int> src, in Block128<int> dst), hex://vfuncs/generic?vstore#vstore_g[32i](v128x32i,b128x32i~in)
; vstore_g[32i](v128x32i,b128x32i~in)[17] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector128<ulong> src, in Block128<ulong> dst), hex://vfuncs/generic?vstore#vstore_g[64u](v128x64u,b128x64u~in)
; vstore_g[64u](v128x64u,b128x64u~in)[17] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector128<long> src, in Block128<long> dst), hex://vfuncs/generic?vstore#vstore_g[64i](v128x64i,b128x64i~in)
; vstore_g[64i](v128x64i,b128x64i~in)[17] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector128<float> src, in Block128<float> dst), hex://vfuncs/generic?vstore#vstore_g[32f](v128x32f,b128x32f~in)
; vstore_g[32f](v128x32f,b128x32f~in)[17] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0xc5,0xf8,0x11,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch vmovups [rax],xmm0                      ; VMOVUPS xmm2/m128, xmm1 || VEX.128.0F.WIG 11 /r || encoded[4]{c5 f8 11 00}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector128<double> src, in Block128<double> dst), hex://vfuncs/generic?vstore#vstore_g[64f](v128x64f,b128x64f~in)
; vstore_g[64f](v128x64f,b128x64f~in)[17] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x11,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch vmovupd [rax],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 00}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector128<byte> src, in Block128<byte> dst, int block), hex://vfuncs/generic?vstore#vstore_g[8u](v128x8u,b128x8u~in,32i)
; vstore_g[8u](v128x8u,b128x8u~in,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x04,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x03,0xc2,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,4                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 04}
000ch vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
0016h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector128<sbyte> src, in Block128<sbyte> dst, int block), hex://vfuncs/generic?vstore#vstore_g[8i](v128x8i,b128x8i~in,32i)
; vstore_g[8i](v128x8i,b128x8i~in,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x04,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x03,0xc2,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,4                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 04}
000ch vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
0016h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector128<ushort> src, in Block128<ushort> dst, int block), hex://vfuncs/generic?vstore#vstore_g[16u](v128x16u,b128x16u~in,32i)
; vstore_g[16u](v128x16u,b128x16u~in,32i)[28] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x03,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x50,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,3                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 03}
000ch vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 50}
0017h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
001bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector128<short> src, in Block128<short> dst, int block), hex://vfuncs/generic?vstore#vstore_g[16i](v128x16i,b128x16i~in,32i)
; vstore_g[16i](v128x16i,b128x16i~in,32i)[28] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x03,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x50,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,3                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 03}
000ch vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 50}
0017h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
001bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector128<uint> src, in Block128<uint> dst, int block), hex://vfuncs/generic?vstore#vstore_g[32u](v128x32u,b128x32u~in,32i)
; vstore_g[32u](v128x32u,b128x32u~in,32i)[28] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,2                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 02}
000ch vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0017h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
001bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector128<int> src, in Block128<int> dst, int block), hex://vfuncs/generic?vstore#vstore_g[32i](v128x32i,b128x32i~in,32i)
; vstore_g[32i](v128x32i,b128x32i~in,32i)[28] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,2                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 02}
000ch vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0017h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
001bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector128<ulong> src, in Block128<ulong> dst, int block), hex://vfuncs/generic?vstore#vstore_g[64u](v128x64u,b128x64u~in,32i)
; vstore_g[64u](v128x64u,b128x64u~in,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xd1,0xe0,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,1                               ; SHL r/m32, 1 || o32 D1 /4 || encoded[3]{41 d1 e0}
000bh vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000fh movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0012h lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0016h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector128<long> src, in Block128<long> dst, int block), hex://vfuncs/generic?vstore#vstore_g[64i](v128x64i,b128x64i~in,32i)
; vstore_g[64i](v128x64i,b128x64i~in,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xd1,0xe0,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,1                               ; SHL r/m32, 1 || o32 D1 /4 || encoded[3]{41 d1 e0}
000bh vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000fh movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0012h lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0016h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector128<float> src, in Block128<float> dst, int block), hex://vfuncs/generic?vstore#vstore_g[32f](v128x32f,b128x32f~in,32i)
; vstore_g[32f](v128x32f,b128x32f~in,32i)[28] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xf8,0x11,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,2                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 02}
000ch vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0017h vmovups [rax],xmm0                      ; VMOVUPS xmm2/m128, xmm1 || VEX.128.0F.WIG 11 /r || encoded[4]{c5 f8 11 00}
001bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector128<double> src, in Block128<double> dst, int block), hex://vfuncs/generic?vstore#vstore_g[64f](v128x64f,b128x64f~in,32i)
; vstore_g[64f](v128x64f,b128x64f~in,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xd1,0xe0,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xf9,0x11,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,1                               ; SHL r/m32, 1 || o32 D1 /4 || encoded[3]{41 d1 e0}
000bh vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000fh movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0012h lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0016h vmovupd [rax],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 00}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector256<byte> src, in Block256<byte> dst), hex://vfuncs/generic?vstore#vstore_g[8u](v256x8u,b256x8u~in)
; vstore_g[8u](v256x8u,b256x8u~in)[20] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector256<sbyte> src, in Block256<sbyte> dst), hex://vfuncs/generic?vstore#vstore_g[8i](v256x8i,b256x8i~in)
; vstore_g[8i](v256x8i,b256x8i~in)[20] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector256<ushort> src, in Block256<ushort> dst), hex://vfuncs/generic?vstore#vstore_g[16u](v256x16u,b256x16u~in)
; vstore_g[16u](v256x16u,b256x16u~in)[20] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector256<short> src, in Block256<short> dst), hex://vfuncs/generic?vstore#vstore_g[16i](v256x16i,b256x16i~in)
; vstore_g[16i](v256x16i,b256x16i~in)[20] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector256<uint> src, in Block256<uint> dst), hex://vfuncs/generic?vstore#vstore_g[32u](v256x32u,b256x32u~in)
; vstore_g[32u](v256x32u,b256x32u~in)[20] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector256<int> src, in Block256<int> dst), hex://vfuncs/generic?vstore#vstore_g[32i](v256x32i,b256x32i~in)
; vstore_g[32i](v256x32i,b256x32i~in)[20] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector256<ulong> src, in Block256<ulong> dst), hex://vfuncs/generic?vstore#vstore_g[64u](v256x64u,b256x64u~in)
; vstore_g[64u](v256x64u,b256x64u~in)[20] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector256<long> src, in Block256<long> dst), hex://vfuncs/generic?vstore#vstore_g[64i](v256x64i,b256x64i~in)
; vstore_g[64i](v256x64i,b256x64i~in)[20] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector256<float> src, in Block256<float> dst), hex://vfuncs/generic?vstore#vstore_g[32f](v256x32f,b256x32f~in)
; vstore_g[32f](v256x32f,b256x32f~in)[20] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfc,0x11,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovups [rax],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 00}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector256<double> src, in Block256<double> dst), hex://vfuncs/generic?vstore#vstore_g[64f](v256x64f,b256x64f~in)
; vstore_g[64f](v256x64f,b256x64f~in)[20] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd [rax],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 00}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector512<byte> src, in Block512<byte> dst), hex://vfuncs/generic?vstore#vstore_g[8u](v512x8u,b512x8u~in)
; vstore_g[8u](v512x8u,b512x8u~in)[36] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0014h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0018h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
001ch vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0020h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0023h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector512<sbyte> src, in Block512<sbyte> dst), hex://vfuncs/generic?vstore#vstore_g[8i](v512x8i,b512x8i~in)
; vstore_g[8i](v512x8i,b512x8i~in)[36] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0014h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0018h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
001ch vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0020h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0023h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector512<ushort> src, in Block512<ushort> dst), hex://vfuncs/generic?vstore#vstore_g[16u](v512x16u,b512x16u~in)
; vstore_g[16u](v512x16u,b512x16u~in)[36] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0014h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0018h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
001ch vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0020h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0023h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector512<short> src, in Block512<short> dst), hex://vfuncs/generic?vstore#vstore_g[16i](v512x16i,b512x16i~in)
; vstore_g[16i](v512x16i,b512x16i~in)[36] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0014h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0018h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
001ch vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0020h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0023h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector512<uint> src, in Block512<uint> dst), hex://vfuncs/generic?vstore#vstore_g[32u](v512x32u,b512x32u~in)
; vstore_g[32u](v512x32u,b512x32u~in)[36] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0014h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0018h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
001ch vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0020h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0023h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector512<int> src, in Block512<int> dst), hex://vfuncs/generic?vstore#vstore_g[32i](v512x32i,b512x32i~in)
; vstore_g[32i](v512x32i,b512x32i~in)[36] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0014h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0018h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
001ch vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0020h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0023h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector512<ulong> src, in Block512<ulong> dst), hex://vfuncs/generic?vstore#vstore_g[64u](v512x64u,b512x64u~in)
; vstore_g[64u](v512x64u,b512x64u~in)[36] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0014h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0018h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
001ch vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0020h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0023h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector512<long> src, in Block512<long> dst), hex://vfuncs/generic?vstore#vstore_g[64i](v512x64i,b512x64i~in)
; vstore_g[64i](v512x64i,b512x64i~in)[36] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0014h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0018h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
001ch vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0020h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0023h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector512<float> src, in Block512<float> dst), hex://vfuncs/generic?vstore#vstore_g[32f](v512x32f,b512x32f~in)
; vstore_g[32f](v512x32f,b512x32f~in)[36] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x48,0x8b,0xd0,0xc5,0xfc,0x11,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfc,0x11,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0014h vmovups [rdx],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 02}
0018h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
001ch vmovups [rax],ymm1                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 08}
0020h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0023h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector512<double> src, in Block512<double> dst), hex://vfuncs/generic?vstore#vstore_g[64f](v512x64f,b512x64f~in)
; vstore_g[64f](v512x64f,b512x64f~in)[36] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x48,0x8b,0xd0,0xc5,0xfd,0x11,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfd,0x11,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0014h vmovupd [rdx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 02}
0018h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
001ch vmovupd [rax],ymm1                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 08}
0020h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0023h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector256<byte> src, in Block256<byte> dst, int block), hex://vfuncs/generic?vstore#vstore_g[8u](v256x8u,b256x8u~in,32i)
; vstore_g[8u](v256x8u,b256x8u~in,32i)[30] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x05,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x03,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,5                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 05}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
0016h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
001ah vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector256<sbyte> src, in Block256<sbyte> dst, int block), hex://vfuncs/generic?vstore#vstore_g[8i](v256x8i,b256x8i~in,32i)
; vstore_g[8i](v256x8i,b256x8i~in,32i)[30] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x05,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x03,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,5                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 05}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
0016h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
001ah vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector256<ushort> src, in Block256<ushort> dst, int block), hex://vfuncs/generic?vstore#vstore_g[16u](v256x16u,b256x16u~in,32i)
; vstore_g[16u](v256x16u,b256x16u~in,32i)[31] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x04,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x50,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,4                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 04}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 50}
0017h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
001bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector256<short> src, in Block256<short> dst, int block), hex://vfuncs/generic?vstore#vstore_g[16i](v256x16i,b256x16i~in,32i)
; vstore_g[16i](v256x16i,b256x16i~in,32i)[31] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x04,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x50,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,4                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 04}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 50}
0017h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
001bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector256<uint> src, in Block256<uint> dst, int block), hex://vfuncs/generic?vstore#vstore_g[32u](v256x32u,b256x32u~in,32i)
; vstore_g[32u](v256x32u,b256x32u~in,32i)[31] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x03,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,3                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 03}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0017h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
001bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector256<int> src, in Block256<int> dst, int block), hex://vfuncs/generic?vstore#vstore_g[32i](v256x32i,b256x32i~in,32i)
; vstore_g[32i](v256x32i,b256x32i~in,32i)[31] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x03,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,3                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 03}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0017h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
001bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector256<ulong> src, in Block256<ulong> dst, int block), hex://vfuncs/generic?vstore#vstore_g[64u](v256x64u,b256x64u~in,32i)
; vstore_g[64u](v256x64u,b256x64u~in,32i)[31] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,2                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 02}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0017h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
001bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector256<long> src, in Block256<long> dst, int block), hex://vfuncs/generic?vstore#vstore_g[64i](v256x64i,b256x64i~in,32i)
; vstore_g[64i](v256x64i,b256x64i~in,32i)[31] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,2                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 02}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0017h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
001bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector256<float> src, in Block256<float> dst, int block), hex://vfuncs/generic?vstore#vstore_g[32f](v256x32f,b256x32f~in,32i)
; vstore_g[32f](v256x32f,b256x32f~in,32i)[31] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x03,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfc,0x11,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,3                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 03}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0017h vmovups [rax],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 00}
001bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector256<double> src, in Block256<double> dst, int block), hex://vfuncs/generic?vstore#vstore_g[64f](v256x64f,b256x64f~in,32i)
; vstore_g[64f](v256x64f,b256x64f~in,32i)[31] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfd,0x11,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,2                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 02}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0017h vmovupd [rax],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 00}
001bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector512<byte> src, in Block512<byte> dst, int block), hex://vfuncs/generic?vstore#vstore_g[8u](v512x8u,b512x8u~in,32i)
; vstore_g[8u](v512x8u,b512x8u~in,32i)[46] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x06,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x03,0xc2,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,6                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 06}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0015h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0018h add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
001bh mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
001eh vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0022h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0026h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002ah vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector512<sbyte> src, in Block512<sbyte> dst, int block), hex://vfuncs/generic?vstore#vstore_g[8i](v512x8i,b512x8i~in,32i)
; vstore_g[8i](v512x8i,b512x8i~in,32i)[46] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x06,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x03,0xc2,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,6                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 06}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0015h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0018h add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
001bh mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
001eh vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0022h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0026h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002ah vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector512<ushort> src, in Block512<ushort> dst, int block), hex://vfuncs/generic?vstore#vstore_g[16u](v512x16u,b512x16u~in,32i)
; vstore_g[16u](v512x16u,b512x16u~in,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x05,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x04,0x50,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,5                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 05}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0015h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0018h lea rax,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 50}
001ch mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
001fh vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0023h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0027h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector512<short> src, in Block512<short> dst, int block), hex://vfuncs/generic?vstore#vstore_g[16i](v512x16i,b512x16i~in,32i)
; vstore_g[16i](v512x16i,b512x16i~in,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x05,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x04,0x50,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,5                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 05}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0015h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0018h lea rax,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 50}
001ch mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
001fh vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0023h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0027h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector512<uint> src, in Block512<uint> dst, int block), hex://vfuncs/generic?vstore#vstore_g[32u](v512x32u,b512x32u~in,32i)
; vstore_g[32u](v512x32u,b512x32u~in,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x04,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,4                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 04}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0015h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0018h lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
001ch mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
001fh vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0023h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0027h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector512<int> src, in Block512<int> dst, int block), hex://vfuncs/generic?vstore#vstore_g[32i](v512x32i,b512x32i~in,32i)
; vstore_g[32i](v512x32i,b512x32i~in,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x04,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,4                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 04}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0015h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0018h lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
001ch mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
001fh vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0023h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0027h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector512<ulong> src, in Block512<ulong> dst, int block), hex://vfuncs/generic?vstore#vstore_g[64u](v512x64u,b512x64u~in,32i)
; vstore_g[64u](v512x64u,b512x64u~in,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x03,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,3                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 03}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0015h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0018h lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
001ch mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
001fh vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0023h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0027h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector512<long> src, in Block512<long> dst, int block), hex://vfuncs/generic?vstore#vstore_g[64i](v512x64i,b512x64i~in,32i)
; vstore_g[64i](v512x64i,b512x64i~in,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x03,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,3                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 03}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0015h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0018h lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
001ch mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
001fh vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0023h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0027h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector512<float> src, in Block512<float> dst, int block), hex://vfuncs/generic?vstore#vstore_g[32f](v512x32f,b512x32f~in,32i)
; vstore_g[32f](v512x32f,b512x32f~in,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x04,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0x48,0x8b,0xd0,0xc5,0xfc,0x11,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfc,0x11,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,4                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 04}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0015h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0018h lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
001ch mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
001fh vmovups [rdx],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 02}
0023h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0027h vmovups [rax],ymm1                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector512<double> src, in Block512<double> dst, int block), hex://vfuncs/generic?vstore#vstore_g[64f](v512x64f,b512x64f~in,32i)
; vstore_g[64f](v512x64f,b512x64f~in,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x03,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0x48,0x8b,0xd0,0xc5,0xfd,0x11,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfd,0x11,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,3                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 03}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0015h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0018h lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
001ch mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
001fh vmovupd [rdx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 02}
0023h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0027h vmovupd [rax],ymm1                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector128<byte> src, ref byte dst, int offset), hex://vfuncs/generic?vstore#vstore_g[8u](v128x8u,8u~ref,32i)
; vstore_g[8u](v128x8u,8u~ref,32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0x49,0x63,0xc0,0x48,0x03,0xc2,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
000fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector128<sbyte> src, ref sbyte dst, int offset), hex://vfuncs/generic?vstore#vstore_g[8i](v128x8i,8i~ref,32i)
; vstore_g[8i](v128x8i,8i~ref,32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0x49,0x63,0xc0,0x48,0x03,0xc2,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
000fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector128<ushort> src, ref ushort dst, int offset), hex://vfuncs/generic?vstore#vstore_g[16u](v128x16u,16u~ref,32i)
; vstore_g[16u](v128x16u,16u~ref,32i)[21] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x42,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 42}
0010h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0014h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector128<short> src, ref short dst, int offset), hex://vfuncs/generic?vstore#vstore_g[16i](v128x16i,16i~ref,32i)
; vstore_g[16i](v128x16i,16i~ref,32i)[21] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x42,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 42}
0010h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0014h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector128<uint> src, ref uint dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32u](v128x32u,32u~ref,32i)
; vstore_g[32u](v128x32u,32u~ref,32i)[21] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x82,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 82}
0010h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0014h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector128<int> src, ref int dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32i](v128x32i,32i~ref,32i)
; vstore_g[32i](v128x32i,32i~ref,32i)[21] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x82,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 82}
0010h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0014h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector128<ulong> src, ref ulong dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64u](v128x64u,64u~ref,32i)
; vstore_g[64u](v128x64u,64u~ref,32i)[21] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0xc2,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 c2}
0010h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0014h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector128<long> src, ref long dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64i](v128x64i,64i~ref,32i)
; vstore_g[64i](v128x64i,64i~ref,32i)[21] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0xc2,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 c2}
0010h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0014h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector128<float> src, ref float dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32f](v128x32f,32f~ref,32i)
; vstore_g[32f](v128x32f,32f~ref,32i)[21] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x82,0xc5,0xf8,0x11,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 82}
0010h vmovups [rax],xmm0                      ; VMOVUPS xmm2/m128, xmm1 || VEX.128.0F.WIG 11 /r || encoded[4]{c5 f8 11 00}
0014h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector128<double> src, ref double dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64f](v128x64f,64f~ref,32i)
; vstore_g[64f](v128x64f,64f~ref,32i)[21] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0xc2,0xc5,0xf9,0x11,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 c2}
0010h vmovupd [rax],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 00}
0014h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector256<byte> src, ref byte dst, int offset), hex://vfuncs/generic?vstore#vstore_g[8u](v256x8u,8u~ref,32i)
; vstore_g[8u](v256x8u,8u~ref,32i)[23] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x03,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
000fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0013h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0016h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector256<sbyte> src, ref sbyte dst, int offset), hex://vfuncs/generic?vstore#vstore_g[8i](v256x8i,8i~ref,32i)
; vstore_g[8i](v256x8i,8i~ref,32i)[23] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x03,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
000fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0013h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0016h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector256<ushort> src, ref ushort dst, int offset), hex://vfuncs/generic?vstore#vstore_g[16u](v256x16u,16u~ref,32i)
; vstore_g[16u](v256x16u,16u~ref,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x42,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 42}
0010h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0014h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector256<short> src, ref short dst, int offset), hex://vfuncs/generic?vstore#vstore_g[16i](v256x16i,16i~ref,32i)
; vstore_g[16i](v256x16i,16i~ref,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x42,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 42}
0010h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0014h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector256<uint> src, ref uint dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32u](v256x32u,32u~ref,32i)
; vstore_g[32u](v256x32u,32u~ref,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x82,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 82}
0010h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0014h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector256<int> src, ref int dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32i](v256x32i,32i~ref,32i)
; vstore_g[32i](v256x32i,32i~ref,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x82,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 82}
0010h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0014h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector256<ulong> src, ref ulong dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64u](v256x64u,64u~ref,32i)
; vstore_g[64u](v256x64u,64u~ref,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 c2}
0010h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0014h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector256<long> src, ref long dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64i](v256x64i,64i~ref,32i)
; vstore_g[64i](v256x64i,64i~ref,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 c2}
0010h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0014h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector256<float> src, ref float dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32f](v256x32f,32f~ref,32i)
; vstore_g[32f](v256x32f,32f~ref,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x82,0xc5,0xfc,0x11,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 82}
0010h vmovups [rax],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 00}
0014h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector256<double> src, ref double dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64f](v256x64f,64f~ref,32i)
; vstore_g[64f](v256x64f,64f~ref,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0xc2,0xc5,0xfd,0x11,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 c2}
0010h vmovupd [rax],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 00}
0014h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block128<byte> block<byte>(Vector128<byte> src), hex://vfuncs/generic?block#block_g[8u](v128x8u)
; block_g[8u](v128x8u)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x7d,0xcc,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x20,0x11,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c83c19d0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 7d cc d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 20 11 bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block128<sbyte> block<sbyte>(Vector128<sbyte> src), hex://vfuncs/generic?block#block_g[8i](v128x8i)
; block_g[8i](v128x8i)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x4d,0xcc,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x80,0x10,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c83c1a40h                      ; CALL rel32 || E8 cd || encoded[5]{e8 4d cc d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 80 10 bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block128<ushort> block<ushort>(Vector128<ushort> src), hex://vfuncs/generic?block#block_g[16u](v128x16u)
; block_g[16u](v128x16u)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x1d,0xcc,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0xe0,0x0f,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c83c1ab0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 1d cc d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e0 0f bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block128<short> block<short>(Vector128<short> src), hex://vfuncs/generic?block#block_g[16i](v128x16i)
; block_g[16i](v128x16i)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xed,0xcb,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x40,0x0f,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c83c1b20h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ed cb d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 40 0f bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block128<uint> block<uint>(Vector128<uint> src), hex://vfuncs/generic?block#block_g[32u](v128x32u)
; block_g[32u](v128x32u)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0xbd,0xcb,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0xa0,0x0e,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c83c1b90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 bd cb d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a0 0e bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block128<int> block<int>(Vector128<int> src), hex://vfuncs/generic?block#block_g[32i](v128x32i)
; block_g[32i](v128x32i)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x8d,0xcb,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x00,0x0e,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c83c1c00h                      ; CALL rel32 || E8 cd || encoded[5]{e8 8d cb d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 00 0e bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block128<ulong> block<ulong>(Vector128<ulong> src), hex://vfuncs/generic?block#block_g[64u](v128x64u)
; block_g[64u](v128x64u)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x5d,0xcb,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x60,0x0d,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c83c1c70h                      ; CALL rel32 || E8 cd || encoded[5]{e8 5d cb d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 60 0d bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block128<long> block<long>(Vector128<long> src), hex://vfuncs/generic?block#block_g[64i](v128x64i)
; block_g[64i](v128x64i)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x2d,0xcb,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0xc0,0x0c,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c83c1ce0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 2d cb d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c0 0c bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block128<float> block<float>(Vector128<float> src), hex://vfuncs/generic?block#block_g[32f](v128x32f)
; block_g[32f](v128x32f)[126] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0xc5,0xe0,0x57,0xdb,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xfc,0xca,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xf8,0x11,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x1f,0x0c,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h vxorps xmm3,xmm3,xmm3                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 e0 57 db}
0049h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004fh call 7ff7c83c1d50h                      ; CALL rel32 || E8 cd || encoded[5]{e8 fc ca d2 ff}
0054h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0059h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005ch vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
0060h vmovups [rax],xmm0                      ; VMOVUPS xmm2/m128, xmm1 || VEX.128.0F.WIG 11 /r || encoded[4]{c5 f8 11 00}
0064h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0067h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006ch call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 1f 0c bd 5e}
0071h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0073h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0076h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ah pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007bh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007ch pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block128<double> block<double>(Vector128<double> src), hex://vfuncs/generic?block#block_g[64f](v128x64f)
; block_g[64f](v128x64f)[126] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0xc5,0xe0,0x57,0xdb,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xcc,0xca,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xf9,0x11,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x7f,0x0b,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h vxorps xmm3,xmm3,xmm3                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 e0 57 db}
0049h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004fh call 7ff7c83c1dc0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 cc ca d2 ff}
0054h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0059h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005ch vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
0060h vmovupd [rax],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 00}
0064h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0067h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006ch call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 7f 0b bd 5e}
0071h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0073h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0076h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ah pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007bh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007ch pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block256<byte> block<byte>(Vector256<byte> src), hex://vfuncs/generic?block#block_g[8u](v256x8u)
; block_g[8u](v256x8u)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x9d,0xca,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0xd0,0x06,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c83c2240h                      ; CALL rel32 || E8 cd || encoded[5]{e8 9d ca d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d0 06 bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block256<sbyte> block<sbyte>(Vector256<sbyte> src), hex://vfuncs/generic?block#block_g[8i](v256x8i)
; block_g[8i](v256x8i)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x6d,0xca,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x30,0x06,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c83c22b0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 6d ca d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 30 06 bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block256<ushort> block<ushort>(Vector256<ushort> src), hex://vfuncs/generic?block#block_g[16u](v256x16u)
; block_g[16u](v256x16u)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x3d,0xca,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x90,0x05,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c83c2320h                      ; CALL rel32 || E8 cd || encoded[5]{e8 3d ca d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 90 05 bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block256<short> block<short>(Vector256<short> src), hex://vfuncs/generic?block#block_g[16i](v256x16i)
; block_g[16i](v256x16i)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x0d,0xca,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0xf0,0x04,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c83c2390h                      ; CALL rel32 || E8 cd || encoded[5]{e8 0d ca d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f0 04 bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block256<uint> block<uint>(Vector256<uint> src), hex://vfuncs/generic?block#block_g[32u](v256x32u)
; block_g[32u](v256x32u)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0xdd,0xc9,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x50,0x04,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c83c2400h                      ; CALL rel32 || E8 cd || encoded[5]{e8 dd c9 d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 50 04 bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block256<int> block<int>(Vector256<int> src), hex://vfuncs/generic?block#block_g[32i](v256x32i)
; block_g[32i](v256x32i)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0xad,0xc9,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0xb0,0x03,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c83c2470h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ad c9 d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b0 03 bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block256<ulong> block<ulong>(Vector256<ulong> src), hex://vfuncs/generic?block#block_g[64u](v256x64u)
; block_g[64u](v256x64u)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x7d,0xc9,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x10,0x03,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c83c24e0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 7d c9 d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 10 03 bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block256<long> block<long>(Vector256<long> src), hex://vfuncs/generic?block#block_g[64i](v256x64i)
; block_g[64i](v256x64i)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x4d,0xc9,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x70,0x02,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c83c2550h                      ; CALL rel32 || E8 cd || encoded[5]{e8 4d c9 d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 70 02 bd 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block256<float> block<float>(Vector256<float> src), hex://vfuncs/generic?block#block_g[32f](v256x32f)
; block_g[32f](v256x32f)[129] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0xc5,0xe0,0x57,0xdb,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x1c,0xc9,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfc,0x11,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0xcf,0x01,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h vxorps xmm3,xmm3,xmm3                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 e0 57 db}
0049h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004fh call 7ff7c83c25c0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 1c c9 d2 ff}
0054h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0059h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005ch vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
0060h vmovups [rax],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 00}
0064h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0067h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006ch call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 cf 01 bd 5e}
0071h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0073h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0076h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0079h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007dh pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007eh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007fh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
0080h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block256<double> block<double>(Vector256<double> src), hex://vfuncs/generic?block#block_g[64f](v256x64f)
; block_g[64f](v256x64f)[129] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0xc5,0xe0,0x57,0xdb,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xec,0xc8,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x11,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x2f,0x01,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h vxorps xmm3,xmm3,xmm3                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 e0 57 db}
0049h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004fh call 7ff7c83c2630h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ec c8 d2 ff}
0054h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0059h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005ch vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
0060h vmovupd [rax],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 00}
0064h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0067h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006ch call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 2f 01 bd 5e}
0071h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0073h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0076h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0079h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007dh pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007eh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007fh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
0080h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block512<byte> block<byte>(Vector512<byte> src), hex://vfuncs/generic?block#block_g[8u](v512x8u)
; block_g[8u](v512x8u)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xbd,0xc8,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x80,0x00,0xbd,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c83c26a0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 bd c8 d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0076h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 80 00 bd 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block512<sbyte> block<sbyte>(Vector512<sbyte> src), hex://vfuncs/generic?block#block_g[8i](v512x8i)
; block_g[8i](v512x8i)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x7d,0xc8,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0xd0,0xff,0xbc,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c83c2710h                      ; CALL rel32 || E8 cd || encoded[5]{e8 7d c8 d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0076h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d0 ff bc 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block512<ushort> block<ushort>(Vector512<ushort> src), hex://vfuncs/generic?block#block_g[16u](v512x16u)
; block_g[16u](v512x16u)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x3d,0xc8,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x20,0xff,0xbc,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c83c2780h                      ; CALL rel32 || E8 cd || encoded[5]{e8 3d c8 d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0076h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 20 ff bc 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block512<short> block<short>(Vector512<short> src), hex://vfuncs/generic?block#block_g[16i](v512x16i)
; block_g[16i](v512x16i)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xfd,0xc7,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x70,0xfe,0xbc,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c83c27f0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 fd c7 d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0076h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 70 fe bc 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block512<uint> block<uint>(Vector512<uint> src), hex://vfuncs/generic?block#block_g[32u](v512x32u)
; block_g[32u](v512x32u)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0xbd,0xc7,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0xc0,0xfd,0xbc,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c83c2860h                      ; CALL rel32 || E8 cd || encoded[5]{e8 bd c7 d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0076h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c0 fd bc 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block512<int> block<int>(Vector512<int> src), hex://vfuncs/generic?block#block_g[32i](v512x32i)
; block_g[32i](v512x32i)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x7d,0xc7,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x10,0xfd,0xbc,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c83c28d0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 7d c7 d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0076h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 10 fd bc 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block512<ulong> block<ulong>(Vector512<ulong> src), hex://vfuncs/generic?block#block_g[64u](v512x64u)
; block_g[64u](v512x64u)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x3d,0xc7,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x60,0xfc,0xbc,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c83c2940h                      ; CALL rel32 || E8 cd || encoded[5]{e8 3d c7 d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0076h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 60 fc bc 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block512<long> block<long>(Vector512<long> src), hex://vfuncs/generic?block#block_g[64i](v512x64i)
; block_g[64i](v512x64i)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0xed,0xc2,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0xa0,0xf7,0xbc,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c83c29b0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ed c2 d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0076h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a0 f7 bc 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block512<float> block<float>(Vector512<float> src), hex://vfuncs/generic?block#block_g[32f](v512x32f)
; block_g[32f](v512x32f)[145] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0xc5,0xe0,0x57,0xdb,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xac,0xc2,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfc,0x11,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfc,0x11,0x08,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0xef,0xf6,0xbc,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h vxorps xmm3,xmm3,xmm3                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 e0 57 db}
0049h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004fh call 7ff7c83c2a20h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ac c2 d2 ff}
0054h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0059h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005ch vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
0060h vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0065h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0068h vmovups [rdx],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 02}
006ch add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0070h vmovups [rax],ymm1                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 08}
0074h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0077h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
007ch call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ef f6 bc 5e}
0081h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0083h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0086h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0089h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008dh pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008eh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008fh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
0090h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block512<double> block<double>(Vector512<double> src), hex://vfuncs/generic?block#block_g[64f](v512x64f)
; block_g[64f](v512x64f)[145] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0xc5,0xe0,0x57,0xdb,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x6c,0xc2,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfd,0x11,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfd,0x11,0x08,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x3f,0xf6,0xbc,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h vxorps xmm3,xmm3,xmm3                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 e0 57 db}
0049h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004fh call 7ff7c83c2a90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 6c c2 d2 ff}
0054h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0059h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005ch vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
0060h vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0065h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0068h vmovupd [rdx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 02}
006ch add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0070h vmovupd [rax],ymm1                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 08}
0074h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0077h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
007ch call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 3f f6 bc 5e}
0081h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0083h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0086h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0089h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008dh pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008eh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008fh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
0090h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<sbyte> vcast8i<byte>(in Vector128<byte> src), hex://vfuncs/generic?vcast8i#vcast8i_g[8u](v128x8u~in)
; vcast8i_g[8u](v128x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<sbyte> vcast8i<sbyte>(in Vector128<sbyte> src), hex://vfuncs/generic?vcast8i#vcast8i_g[8i](v128x8i~in)
; vcast8i_g[8i](v128x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<sbyte> vcast8i<ushort>(in Vector128<ushort> src), hex://vfuncs/generic?vcast8i#vcast8i_g[16u](v128x16u~in)
; vcast8i_g[16u](v128x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<sbyte> vcast8i<short>(in Vector128<short> src), hex://vfuncs/generic?vcast8i#vcast8i_g[16i](v128x16i~in)
; vcast8i_g[16i](v128x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<sbyte> vcast8i<uint>(in Vector128<uint> src), hex://vfuncs/generic?vcast8i#vcast8i_g[32u](v128x32u~in)
; vcast8i_g[32u](v128x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<sbyte> vcast8i<int>(in Vector128<int> src), hex://vfuncs/generic?vcast8i#vcast8i_g[32i](v128x32i~in)
; vcast8i_g[32i](v128x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<sbyte> vcast8i<ulong>(in Vector128<ulong> src), hex://vfuncs/generic?vcast8i#vcast8i_g[64u](v128x64u~in)
; vcast8i_g[64u](v128x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<sbyte> vcast8i<long>(in Vector128<long> src), hex://vfuncs/generic?vcast8i#vcast8i_g[64i](v128x64i~in)
; vcast8i_g[64i](v128x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<sbyte> vcast8i<float>(in Vector128<float> src), hex://vfuncs/generic?vcast8i#vcast8i_g[32f](v128x32f~in)
; vcast8i_g[32f](v128x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<sbyte> vcast8i<double>(in Vector128<double> src), hex://vfuncs/generic?vcast8i#vcast8i_g[64f](v128x64f~in)
; vcast8i_g[64f](v128x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<byte> vcast8u<byte>(in Vector128<byte> src), hex://vfuncs/generic?vcast8u#vcast8u_g[8u](v128x8u~in)
; vcast8u_g[8u](v128x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<byte> vcast8u<sbyte>(in Vector128<sbyte> src), hex://vfuncs/generic?vcast8u#vcast8u_g[8i](v128x8i~in)
; vcast8u_g[8i](v128x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<byte> vcast8u<ushort>(in Vector128<ushort> src), hex://vfuncs/generic?vcast8u#vcast8u_g[16u](v128x16u~in)
; vcast8u_g[16u](v128x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<byte> vcast8u<short>(in Vector128<short> src), hex://vfuncs/generic?vcast8u#vcast8u_g[16i](v128x16i~in)
; vcast8u_g[16i](v128x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<byte> vcast8u<uint>(in Vector128<uint> src), hex://vfuncs/generic?vcast8u#vcast8u_g[32u](v128x32u~in)
; vcast8u_g[32u](v128x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<byte> vcast8u<int>(in Vector128<int> src), hex://vfuncs/generic?vcast8u#vcast8u_g[32i](v128x32i~in)
; vcast8u_g[32i](v128x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<byte> vcast8u<ulong>(in Vector128<ulong> src), hex://vfuncs/generic?vcast8u#vcast8u_g[64u](v128x64u~in)
; vcast8u_g[64u](v128x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<byte> vcast8u<long>(in Vector128<long> src), hex://vfuncs/generic?vcast8u#vcast8u_g[64i](v128x64i~in)
; vcast8u_g[64i](v128x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<byte> vcast8u<float>(in Vector128<float> src), hex://vfuncs/generic?vcast8u#vcast8u_g[32f](v128x32f~in)
; vcast8u_g[32f](v128x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<byte> vcast8u<double>(in Vector128<double> src), hex://vfuncs/generic?vcast8u#vcast8u_g[64f](v128x64f~in)
; vcast8u_g[64f](v128x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<short> vcast16i<byte>(in Vector128<byte> src), hex://vfuncs/generic?vcast16i#vcast16i_g[8u](v128x8u~in)
; vcast16i_g[8u](v128x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<short> vcast16i<sbyte>(in Vector128<sbyte> src), hex://vfuncs/generic?vcast16i#vcast16i_g[8i](v128x8i~in)
; vcast16i_g[8i](v128x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<short> vcast16i<ushort>(in Vector128<ushort> src), hex://vfuncs/generic?vcast16i#vcast16i_g[16u](v128x16u~in)
; vcast16i_g[16u](v128x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<short> vcast16i<short>(in Vector128<short> src), hex://vfuncs/generic?vcast16i#vcast16i_g[16i](v128x16i~in)
; vcast16i_g[16i](v128x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<short> vcast16i<uint>(in Vector128<uint> src), hex://vfuncs/generic?vcast16i#vcast16i_g[32u](v128x32u~in)
; vcast16i_g[32u](v128x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<short> vcast16i<int>(in Vector128<int> src), hex://vfuncs/generic?vcast16i#vcast16i_g[32i](v128x32i~in)
; vcast16i_g[32i](v128x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<short> vcast16i<ulong>(in Vector128<ulong> src), hex://vfuncs/generic?vcast16i#vcast16i_g[64u](v128x64u~in)
; vcast16i_g[64u](v128x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<short> vcast16i<long>(in Vector128<long> src), hex://vfuncs/generic?vcast16i#vcast16i_g[64i](v128x64i~in)
; vcast16i_g[64i](v128x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<short> vcast16i<float>(in Vector128<float> src), hex://vfuncs/generic?vcast16i#vcast16i_g[32f](v128x32f~in)
; vcast16i_g[32f](v128x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<short> vcast16i<double>(in Vector128<double> src), hex://vfuncs/generic?vcast16i#vcast16i_g[64f](v128x64f~in)
; vcast16i_g[64f](v128x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ushort> vcast16u<byte>(in Vector128<byte> src), hex://vfuncs/generic?vcast16u#vcast16u_g[8u](v128x8u~in)
; vcast16u_g[8u](v128x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ushort> vcast16u<sbyte>(in Vector128<sbyte> src), hex://vfuncs/generic?vcast16u#vcast16u_g[8i](v128x8i~in)
; vcast16u_g[8i](v128x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ushort> vcast16u<ushort>(in Vector128<ushort> src), hex://vfuncs/generic?vcast16u#vcast16u_g[16u](v128x16u~in)
; vcast16u_g[16u](v128x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ushort> vcast16u<short>(in Vector128<short> src), hex://vfuncs/generic?vcast16u#vcast16u_g[16i](v128x16i~in)
; vcast16u_g[16i](v128x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ushort> vcast16u<uint>(in Vector128<uint> src), hex://vfuncs/generic?vcast16u#vcast16u_g[32u](v128x32u~in)
; vcast16u_g[32u](v128x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ushort> vcast16u<int>(in Vector128<int> src), hex://vfuncs/generic?vcast16u#vcast16u_g[32i](v128x32i~in)
; vcast16u_g[32i](v128x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ushort> vcast16u<ulong>(in Vector128<ulong> src), hex://vfuncs/generic?vcast16u#vcast16u_g[64u](v128x64u~in)
; vcast16u_g[64u](v128x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ushort> vcast16u<long>(in Vector128<long> src), hex://vfuncs/generic?vcast16u#vcast16u_g[64i](v128x64i~in)
; vcast16u_g[64i](v128x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ushort> vcast16u<float>(in Vector128<float> src), hex://vfuncs/generic?vcast16u#vcast16u_g[32f](v128x32f~in)
; vcast16u_g[32f](v128x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ushort> vcast16u<double>(in Vector128<double> src), hex://vfuncs/generic?vcast16u#vcast16u_g[64f](v128x64f~in)
; vcast16u_g[64f](v128x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<int> vcast32i<byte>(in Vector128<byte> src), hex://vfuncs/generic?vcast32i#vcast32i_g[8u](v128x8u~in)
; vcast32i_g[8u](v128x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<int> vcast32i<sbyte>(in Vector128<sbyte> src), hex://vfuncs/generic?vcast32i#vcast32i_g[8i](v128x8i~in)
; vcast32i_g[8i](v128x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<int> vcast32i<ushort>(in Vector128<ushort> src), hex://vfuncs/generic?vcast32i#vcast32i_g[16u](v128x16u~in)
; vcast32i_g[16u](v128x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<int> vcast32i<short>(in Vector128<short> src), hex://vfuncs/generic?vcast32i#vcast32i_g[16i](v128x16i~in)
; vcast32i_g[16i](v128x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<int> vcast32i<uint>(in Vector128<uint> src), hex://vfuncs/generic?vcast32i#vcast32i_g[32u](v128x32u~in)
; vcast32i_g[32u](v128x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<int> vcast32i<int>(in Vector128<int> src), hex://vfuncs/generic?vcast32i#vcast32i_g[32i](v128x32i~in)
; vcast32i_g[32i](v128x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<int> vcast32i<ulong>(in Vector128<ulong> src), hex://vfuncs/generic?vcast32i#vcast32i_g[64u](v128x64u~in)
; vcast32i_g[64u](v128x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<int> vcast32i<long>(in Vector128<long> src), hex://vfuncs/generic?vcast32i#vcast32i_g[64i](v128x64i~in)
; vcast32i_g[64i](v128x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<int> vcast32i<float>(in Vector128<float> src), hex://vfuncs/generic?vcast32i#vcast32i_g[32f](v128x32f~in)
; vcast32i_g[32f](v128x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<int> vcast32i<double>(in Vector128<double> src), hex://vfuncs/generic?vcast32i#vcast32i_g[64f](v128x64f~in)
; vcast32i_g[64f](v128x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<uint> vcast32u<byte>(in Vector128<byte> src), hex://vfuncs/generic?vcast32u#vcast32u_g[8u](v128x8u~in)
; vcast32u_g[8u](v128x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<uint> vcast32u<sbyte>(in Vector128<sbyte> src), hex://vfuncs/generic?vcast32u#vcast32u_g[8i](v128x8i~in)
; vcast32u_g[8i](v128x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<uint> vcast32u<ushort>(in Vector128<ushort> src), hex://vfuncs/generic?vcast32u#vcast32u_g[16u](v128x16u~in)
; vcast32u_g[16u](v128x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<uint> vcast32u<short>(in Vector128<short> src), hex://vfuncs/generic?vcast32u#vcast32u_g[16i](v128x16i~in)
; vcast32u_g[16i](v128x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<uint> vcast32u<uint>(in Vector128<uint> src), hex://vfuncs/generic?vcast32u#vcast32u_g[32u](v128x32u~in)
; vcast32u_g[32u](v128x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<uint> vcast32u<int>(in Vector128<int> src), hex://vfuncs/generic?vcast32u#vcast32u_g[32i](v128x32i~in)
; vcast32u_g[32i](v128x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<uint> vcast32u<ulong>(in Vector128<ulong> src), hex://vfuncs/generic?vcast32u#vcast32u_g[64u](v128x64u~in)
; vcast32u_g[64u](v128x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<uint> vcast32u<long>(in Vector128<long> src), hex://vfuncs/generic?vcast32u#vcast32u_g[64i](v128x64i~in)
; vcast32u_g[64i](v128x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<uint> vcast32u<float>(in Vector128<float> src), hex://vfuncs/generic?vcast32u#vcast32u_g[32f](v128x32f~in)
; vcast32u_g[32f](v128x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<uint> vcast32u<double>(in Vector128<double> src), hex://vfuncs/generic?vcast32u#vcast32u_g[64f](v128x64f~in)
; vcast32u_g[64f](v128x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<long> vcast64i<byte>(in Vector128<byte> src), hex://vfuncs/generic?vcast64i#vcast64i_g[8u](v128x8u~in)
; vcast64i_g[8u](v128x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<long> vcast64i<sbyte>(in Vector128<sbyte> src), hex://vfuncs/generic?vcast64i#vcast64i_g[8i](v128x8i~in)
; vcast64i_g[8i](v128x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<long> vcast64i<ushort>(in Vector128<ushort> src), hex://vfuncs/generic?vcast64i#vcast64i_g[16u](v128x16u~in)
; vcast64i_g[16u](v128x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<long> vcast64i<short>(in Vector128<short> src), hex://vfuncs/generic?vcast64i#vcast64i_g[16i](v128x16i~in)
; vcast64i_g[16i](v128x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<long> vcast64i<uint>(in Vector128<uint> src), hex://vfuncs/generic?vcast64i#vcast64i_g[32u](v128x32u~in)
; vcast64i_g[32u](v128x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<long> vcast64i<int>(in Vector128<int> src), hex://vfuncs/generic?vcast64i#vcast64i_g[32i](v128x32i~in)
; vcast64i_g[32i](v128x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<long> vcast64i<ulong>(in Vector128<ulong> src), hex://vfuncs/generic?vcast64i#vcast64i_g[64u](v128x64u~in)
; vcast64i_g[64u](v128x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<long> vcast64i<long>(in Vector128<long> src), hex://vfuncs/generic?vcast64i#vcast64i_g[64i](v128x64i~in)
; vcast64i_g[64i](v128x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<long> vcast64i<float>(in Vector128<float> src), hex://vfuncs/generic?vcast64i#vcast64i_g[32f](v128x32f~in)
; vcast64i_g[32f](v128x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<long> vcast64i<double>(in Vector128<double> src), hex://vfuncs/generic?vcast64i#vcast64i_g[64f](v128x64f~in)
; vcast64i_g[64f](v128x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ulong> vcast64u<byte>(in Vector128<byte> src), hex://vfuncs/generic?vcast64u#vcast64u_g[8u](v128x8u~in)
; vcast64u_g[8u](v128x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ulong> vcast64u<sbyte>(in Vector128<sbyte> src), hex://vfuncs/generic?vcast64u#vcast64u_g[8i](v128x8i~in)
; vcast64u_g[8i](v128x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ulong> vcast64u<ushort>(in Vector128<ushort> src), hex://vfuncs/generic?vcast64u#vcast64u_g[16u](v128x16u~in)
; vcast64u_g[16u](v128x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ulong> vcast64u<short>(in Vector128<short> src), hex://vfuncs/generic?vcast64u#vcast64u_g[16i](v128x16i~in)
; vcast64u_g[16i](v128x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ulong> vcast64u<uint>(in Vector128<uint> src), hex://vfuncs/generic?vcast64u#vcast64u_g[32u](v128x32u~in)
; vcast64u_g[32u](v128x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ulong> vcast64u<int>(in Vector128<int> src), hex://vfuncs/generic?vcast64u#vcast64u_g[32i](v128x32i~in)
; vcast64u_g[32i](v128x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ulong> vcast64u<ulong>(in Vector128<ulong> src), hex://vfuncs/generic?vcast64u#vcast64u_g[64u](v128x64u~in)
; vcast64u_g[64u](v128x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ulong> vcast64u<long>(in Vector128<long> src), hex://vfuncs/generic?vcast64u#vcast64u_g[64i](v128x64i~in)
; vcast64u_g[64i](v128x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ulong> vcast64u<float>(in Vector128<float> src), hex://vfuncs/generic?vcast64u#vcast64u_g[32f](v128x32f~in)
; vcast64u_g[32f](v128x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ulong> vcast64u<double>(in Vector128<double> src), hex://vfuncs/generic?vcast64u#vcast64u_g[64f](v128x64f~in)
; vcast64u_g[64f](v128x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<double> vcast64f<byte>(in Vector128<byte> src), hex://vfuncs/generic?vcast64f#vcast64f_g[8u](v128x8u~in)
; vcast64f_g[8u](v128x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<double> vcast64f<sbyte>(in Vector128<sbyte> src), hex://vfuncs/generic?vcast64f#vcast64f_g[8i](v128x8i~in)
; vcast64f_g[8i](v128x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<double> vcast64f<ushort>(in Vector128<ushort> src), hex://vfuncs/generic?vcast64f#vcast64f_g[16u](v128x16u~in)
; vcast64f_g[16u](v128x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<double> vcast64f<short>(in Vector128<short> src), hex://vfuncs/generic?vcast64f#vcast64f_g[16i](v128x16i~in)
; vcast64f_g[16i](v128x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<double> vcast64f<uint>(in Vector128<uint> src), hex://vfuncs/generic?vcast64f#vcast64f_g[32u](v128x32u~in)
; vcast64f_g[32u](v128x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<double> vcast64f<int>(in Vector128<int> src), hex://vfuncs/generic?vcast64f#vcast64f_g[32i](v128x32i~in)
; vcast64f_g[32i](v128x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<double> vcast64f<ulong>(in Vector128<ulong> src), hex://vfuncs/generic?vcast64f#vcast64f_g[64u](v128x64u~in)
; vcast64f_g[64u](v128x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<double> vcast64f<long>(in Vector128<long> src), hex://vfuncs/generic?vcast64f#vcast64f_g[64i](v128x64i~in)
; vcast64f_g[64i](v128x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<double> vcast64f<float>(in Vector128<float> src), hex://vfuncs/generic?vcast64f#vcast64f_g[32f](v128x32f~in)
; vcast64f_g[32f](v128x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<double> vcast64f<double>(in Vector128<double> src), hex://vfuncs/generic?vcast64f#vcast64f_g[64f](v128x64f~in)
; vcast64f_g[64f](v128x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<float> vcast32f<byte>(in Vector128<byte> src), hex://vfuncs/generic?vcast32f#vcast32f_g[8u](v128x8u~in)
; vcast32f_g[8u](v128x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<float> vcast32f<sbyte>(in Vector128<sbyte> src), hex://vfuncs/generic?vcast32f#vcast32f_g[8i](v128x8i~in)
; vcast32f_g[8i](v128x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<float> vcast32f<ushort>(in Vector128<ushort> src), hex://vfuncs/generic?vcast32f#vcast32f_g[16u](v128x16u~in)
; vcast32f_g[16u](v128x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<float> vcast32f<short>(in Vector128<short> src), hex://vfuncs/generic?vcast32f#vcast32f_g[16i](v128x16i~in)
; vcast32f_g[16i](v128x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<float> vcast32f<uint>(in Vector128<uint> src), hex://vfuncs/generic?vcast32f#vcast32f_g[32u](v128x32u~in)
; vcast32f_g[32u](v128x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<float> vcast32f<int>(in Vector128<int> src), hex://vfuncs/generic?vcast32f#vcast32f_g[32i](v128x32i~in)
; vcast32f_g[32i](v128x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<float> vcast32f<ulong>(in Vector128<ulong> src), hex://vfuncs/generic?vcast32f#vcast32f_g[64u](v128x64u~in)
; vcast32f_g[64u](v128x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<float> vcast32f<long>(in Vector128<long> src), hex://vfuncs/generic?vcast32f#vcast32f_g[64i](v128x64i~in)
; vcast32f_g[64i](v128x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<float> vcast32f<float>(in Vector128<float> src), hex://vfuncs/generic?vcast32f#vcast32f_g[32f](v128x32f~in)
; vcast32f_g[32f](v128x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<float> vcast32f<double>(in Vector128<double> src), hex://vfuncs/generic?vcast32f#vcast32f_g[64f](v128x64f~in)
; vcast32f_g[64f](v128x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<sbyte> vcast8i<byte>(in Vector256<byte> src), hex://vfuncs/generic?vcast8i#vcast8i_g[8u](v256x8u~in)
; vcast8i_g[8u](v256x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<sbyte> vcast8i<sbyte>(in Vector256<sbyte> src), hex://vfuncs/generic?vcast8i#vcast8i_g[8i](v256x8i~in)
; vcast8i_g[8i](v256x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<sbyte> vcast8i<ushort>(in Vector256<ushort> src), hex://vfuncs/generic?vcast8i#vcast8i_g[16u](v256x16u~in)
; vcast8i_g[16u](v256x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<sbyte> vcast8i<short>(in Vector256<short> src), hex://vfuncs/generic?vcast8i#vcast8i_g[16i](v256x16i~in)
; vcast8i_g[16i](v256x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<sbyte> vcast8i<uint>(in Vector256<uint> src), hex://vfuncs/generic?vcast8i#vcast8i_g[32u](v256x32u~in)
; vcast8i_g[32u](v256x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<sbyte> vcast8i<int>(in Vector256<int> src), hex://vfuncs/generic?vcast8i#vcast8i_g[32i](v256x32i~in)
; vcast8i_g[32i](v256x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<sbyte> vcast8i<ulong>(in Vector256<ulong> src), hex://vfuncs/generic?vcast8i#vcast8i_g[64u](v256x64u~in)
; vcast8i_g[64u](v256x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<sbyte> vcast8i<long>(in Vector256<long> src), hex://vfuncs/generic?vcast8i#vcast8i_g[64i](v256x64i~in)
; vcast8i_g[64i](v256x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<sbyte> vcast8i<float>(in Vector256<float> src), hex://vfuncs/generic?vcast8i#vcast8i_g[32f](v256x32f~in)
; vcast8i_g[32f](v256x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<sbyte> vcast8i<double>(in Vector256<double> src), hex://vfuncs/generic?vcast8i#vcast8i_g[64f](v256x64f~in)
; vcast8i_g[64f](v256x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<byte> vcast8u<byte>(in Vector256<byte> src), hex://vfuncs/generic?vcast8u#vcast8u_g[8u](v256x8u~in)
; vcast8u_g[8u](v256x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<byte> vcast8u<sbyte>(in Vector256<sbyte> src), hex://vfuncs/generic?vcast8u#vcast8u_g[8i](v256x8i~in)
; vcast8u_g[8i](v256x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<byte> vcast8u<ushort>(in Vector256<ushort> src), hex://vfuncs/generic?vcast8u#vcast8u_g[16u](v256x16u~in)
; vcast8u_g[16u](v256x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<byte> vcast8u<short>(in Vector256<short> src), hex://vfuncs/generic?vcast8u#vcast8u_g[16i](v256x16i~in)
; vcast8u_g[16i](v256x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<byte> vcast8u<uint>(in Vector256<uint> src), hex://vfuncs/generic?vcast8u#vcast8u_g[32u](v256x32u~in)
; vcast8u_g[32u](v256x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<byte> vcast8u<int>(in Vector256<int> src), hex://vfuncs/generic?vcast8u#vcast8u_g[32i](v256x32i~in)
; vcast8u_g[32i](v256x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<byte> vcast8u<ulong>(in Vector256<ulong> src), hex://vfuncs/generic?vcast8u#vcast8u_g[64u](v256x64u~in)
; vcast8u_g[64u](v256x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<byte> vcast8u<long>(in Vector256<long> src), hex://vfuncs/generic?vcast8u#vcast8u_g[64i](v256x64i~in)
; vcast8u_g[64i](v256x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<byte> vcast8u<float>(in Vector256<float> src), hex://vfuncs/generic?vcast8u#vcast8u_g[32f](v256x32f~in)
; vcast8u_g[32f](v256x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<byte> vcast8u<double>(in Vector256<double> src), hex://vfuncs/generic?vcast8u#vcast8u_g[64f](v256x64f~in)
; vcast8u_g[64f](v256x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<short> vcast16i<byte>(in Vector256<byte> src), hex://vfuncs/generic?vcast16i#vcast16i_g[8u](v256x8u~in)
; vcast16i_g[8u](v256x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<short> vcast16i<sbyte>(in Vector256<sbyte> src), hex://vfuncs/generic?vcast16i#vcast16i_g[8i](v256x8i~in)
; vcast16i_g[8i](v256x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<short> vcast16i<ushort>(in Vector256<ushort> src), hex://vfuncs/generic?vcast16i#vcast16i_g[16u](v256x16u~in)
; vcast16i_g[16u](v256x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<short> vcast16i<short>(in Vector256<short> src), hex://vfuncs/generic?vcast16i#vcast16i_g[16i](v256x16i~in)
; vcast16i_g[16i](v256x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<short> vcast16i<uint>(in Vector256<uint> src), hex://vfuncs/generic?vcast16i#vcast16i_g[32u](v256x32u~in)
; vcast16i_g[32u](v256x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<short> vcast16i<int>(in Vector256<int> src), hex://vfuncs/generic?vcast16i#vcast16i_g[32i](v256x32i~in)
; vcast16i_g[32i](v256x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<short> vcast16i<ulong>(in Vector256<ulong> src), hex://vfuncs/generic?vcast16i#vcast16i_g[64u](v256x64u~in)
; vcast16i_g[64u](v256x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<short> vcast16i<long>(in Vector256<long> src), hex://vfuncs/generic?vcast16i#vcast16i_g[64i](v256x64i~in)
; vcast16i_g[64i](v256x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<short> vcast16i<float>(in Vector256<float> src), hex://vfuncs/generic?vcast16i#vcast16i_g[32f](v256x32f~in)
; vcast16i_g[32f](v256x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<short> vcast16i<double>(in Vector256<double> src), hex://vfuncs/generic?vcast16i#vcast16i_g[64f](v256x64f~in)
; vcast16i_g[64f](v256x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ushort> vcast16u<byte>(in Vector256<byte> src), hex://vfuncs/generic?vcast16u#vcast16u_g[8u](v256x8u~in)
; vcast16u_g[8u](v256x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ushort> vcast16u<sbyte>(in Vector256<sbyte> src), hex://vfuncs/generic?vcast16u#vcast16u_g[8i](v256x8i~in)
; vcast16u_g[8i](v256x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ushort> vcast16u<ushort>(in Vector256<ushort> src), hex://vfuncs/generic?vcast16u#vcast16u_g[16u](v256x16u~in)
; vcast16u_g[16u](v256x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ushort> vcast16u<short>(in Vector256<short> src), hex://vfuncs/generic?vcast16u#vcast16u_g[16i](v256x16i~in)
; vcast16u_g[16i](v256x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ushort> vcast16u<uint>(in Vector256<uint> src), hex://vfuncs/generic?vcast16u#vcast16u_g[32u](v256x32u~in)
; vcast16u_g[32u](v256x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ushort> vcast16u<int>(in Vector256<int> src), hex://vfuncs/generic?vcast16u#vcast16u_g[32i](v256x32i~in)
; vcast16u_g[32i](v256x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ushort> vcast16u<ulong>(in Vector256<ulong> src), hex://vfuncs/generic?vcast16u#vcast16u_g[64u](v256x64u~in)
; vcast16u_g[64u](v256x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ushort> vcast16u<long>(in Vector256<long> src), hex://vfuncs/generic?vcast16u#vcast16u_g[64i](v256x64i~in)
; vcast16u_g[64i](v256x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ushort> vcast16u<float>(in Vector256<float> src), hex://vfuncs/generic?vcast16u#vcast16u_g[32f](v256x32f~in)
; vcast16u_g[32f](v256x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ushort> vcast16u<double>(in Vector256<double> src), hex://vfuncs/generic?vcast16u#vcast16u_g[64f](v256x64f~in)
; vcast16u_g[64f](v256x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<int> vcast32i<byte>(in Vector256<byte> src), hex://vfuncs/generic?vcast32i#vcast32i_g[8u](v256x8u~in)
; vcast32i_g[8u](v256x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<int> vcast32i<sbyte>(in Vector256<sbyte> src), hex://vfuncs/generic?vcast32i#vcast32i_g[8i](v256x8i~in)
; vcast32i_g[8i](v256x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<int> vcast32i<ushort>(in Vector256<ushort> src), hex://vfuncs/generic?vcast32i#vcast32i_g[16u](v256x16u~in)
; vcast32i_g[16u](v256x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<int> vcast32i<short>(in Vector256<short> src), hex://vfuncs/generic?vcast32i#vcast32i_g[16i](v256x16i~in)
; vcast32i_g[16i](v256x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<int> vcast32i<uint>(in Vector256<uint> src), hex://vfuncs/generic?vcast32i#vcast32i_g[32u](v256x32u~in)
; vcast32i_g[32u](v256x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<int> vcast32i<int>(in Vector256<int> src), hex://vfuncs/generic?vcast32i#vcast32i_g[32i](v256x32i~in)
; vcast32i_g[32i](v256x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<int> vcast32i<ulong>(in Vector256<ulong> src), hex://vfuncs/generic?vcast32i#vcast32i_g[64u](v256x64u~in)
; vcast32i_g[64u](v256x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<int> vcast32i<long>(in Vector256<long> src), hex://vfuncs/generic?vcast32i#vcast32i_g[64i](v256x64i~in)
; vcast32i_g[64i](v256x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<int> vcast32i<float>(in Vector256<float> src), hex://vfuncs/generic?vcast32i#vcast32i_g[32f](v256x32f~in)
; vcast32i_g[32f](v256x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<int> vcast32i<double>(in Vector256<double> src), hex://vfuncs/generic?vcast32i#vcast32i_g[64f](v256x64f~in)
; vcast32i_g[64f](v256x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<uint> vcast32u<byte>(in Vector256<byte> src), hex://vfuncs/generic?vcast32u#vcast32u_g[8u](v256x8u~in)
; vcast32u_g[8u](v256x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<uint> vcast32u<sbyte>(in Vector256<sbyte> src), hex://vfuncs/generic?vcast32u#vcast32u_g[8i](v256x8i~in)
; vcast32u_g[8i](v256x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<uint> vcast32u<ushort>(in Vector256<ushort> src), hex://vfuncs/generic?vcast32u#vcast32u_g[16u](v256x16u~in)
; vcast32u_g[16u](v256x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<uint> vcast32u<short>(in Vector256<short> src), hex://vfuncs/generic?vcast32u#vcast32u_g[16i](v256x16i~in)
; vcast32u_g[16i](v256x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<uint> vcast32u<uint>(in Vector256<uint> src), hex://vfuncs/generic?vcast32u#vcast32u_g[32u](v256x32u~in)
; vcast32u_g[32u](v256x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<uint> vcast32u<int>(in Vector256<int> src), hex://vfuncs/generic?vcast32u#vcast32u_g[32i](v256x32i~in)
; vcast32u_g[32i](v256x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<uint> vcast32u<ulong>(in Vector256<ulong> src), hex://vfuncs/generic?vcast32u#vcast32u_g[64u](v256x64u~in)
; vcast32u_g[64u](v256x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<uint> vcast32u<long>(in Vector256<long> src), hex://vfuncs/generic?vcast32u#vcast32u_g[64i](v256x64i~in)
; vcast32u_g[64i](v256x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<uint> vcast32u<float>(in Vector256<float> src), hex://vfuncs/generic?vcast32u#vcast32u_g[32f](v256x32f~in)
; vcast32u_g[32f](v256x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<uint> vcast32u<double>(in Vector256<double> src), hex://vfuncs/generic?vcast32u#vcast32u_g[64f](v256x64f~in)
; vcast32u_g[64f](v256x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<long> vcast64i<byte>(in Vector256<byte> src), hex://vfuncs/generic?vcast64i#vcast64i_g[8u](v256x8u~in)
; vcast64i_g[8u](v256x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<long> vcast64i<sbyte>(in Vector256<sbyte> src), hex://vfuncs/generic?vcast64i#vcast64i_g[8i](v256x8i~in)
; vcast64i_g[8i](v256x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<long> vcast64i<ushort>(in Vector256<ushort> src), hex://vfuncs/generic?vcast64i#vcast64i_g[16u](v256x16u~in)
; vcast64i_g[16u](v256x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<long> vcast64i<short>(in Vector256<short> src), hex://vfuncs/generic?vcast64i#vcast64i_g[16i](v256x16i~in)
; vcast64i_g[16i](v256x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<long> vcast64i<uint>(in Vector256<uint> src), hex://vfuncs/generic?vcast64i#vcast64i_g[32u](v256x32u~in)
; vcast64i_g[32u](v256x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<long> vcast64i<int>(in Vector256<int> src), hex://vfuncs/generic?vcast64i#vcast64i_g[32i](v256x32i~in)
; vcast64i_g[32i](v256x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<long> vcast64i<ulong>(in Vector256<ulong> src), hex://vfuncs/generic?vcast64i#vcast64i_g[64u](v256x64u~in)
; vcast64i_g[64u](v256x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<long> vcast64i<long>(in Vector256<long> src), hex://vfuncs/generic?vcast64i#vcast64i_g[64i](v256x64i~in)
; vcast64i_g[64i](v256x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<long> vcast64i<float>(in Vector256<float> src), hex://vfuncs/generic?vcast64i#vcast64i_g[32f](v256x32f~in)
; vcast64i_g[32f](v256x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<long> vcast64i<double>(in Vector256<double> src), hex://vfuncs/generic?vcast64i#vcast64i_g[64f](v256x64f~in)
; vcast64i_g[64f](v256x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ulong> vcast64u<byte>(in Vector256<byte> src), hex://vfuncs/generic?vcast64u#vcast64u_g[8u](v256x8u~in)
; vcast64u_g[8u](v256x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ulong> vcast64u<sbyte>(in Vector256<sbyte> src), hex://vfuncs/generic?vcast64u#vcast64u_g[8i](v256x8i~in)
; vcast64u_g[8i](v256x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ulong> vcast64u<ushort>(in Vector256<ushort> src), hex://vfuncs/generic?vcast64u#vcast64u_g[16u](v256x16u~in)
; vcast64u_g[16u](v256x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ulong> vcast64u<short>(in Vector256<short> src), hex://vfuncs/generic?vcast64u#vcast64u_g[16i](v256x16i~in)
; vcast64u_g[16i](v256x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ulong> vcast64u<uint>(in Vector256<uint> src), hex://vfuncs/generic?vcast64u#vcast64u_g[32u](v256x32u~in)
; vcast64u_g[32u](v256x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ulong> vcast64u<int>(in Vector256<int> src), hex://vfuncs/generic?vcast64u#vcast64u_g[32i](v256x32i~in)
; vcast64u_g[32i](v256x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ulong> vcast64u<ulong>(in Vector256<ulong> src), hex://vfuncs/generic?vcast64u#vcast64u_g[64u](v256x64u~in)
; vcast64u_g[64u](v256x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ulong> vcast64u<long>(in Vector256<long> src), hex://vfuncs/generic?vcast64u#vcast64u_g[64i](v256x64i~in)
; vcast64u_g[64i](v256x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ulong> vcast64u<float>(in Vector256<float> src), hex://vfuncs/generic?vcast64u#vcast64u_g[32f](v256x32f~in)
; vcast64u_g[32f](v256x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ulong> vcast64u<double>(in Vector256<double> src), hex://vfuncs/generic?vcast64u#vcast64u_g[64f](v256x64f~in)
; vcast64u_g[64f](v256x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<float> vcast32f<byte>(in Vector256<byte> src), hex://vfuncs/generic?vcast32f#vcast32f_g[8u](v256x8u~in)
; vcast32f_g[8u](v256x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<float> vcast32f<sbyte>(in Vector256<sbyte> src), hex://vfuncs/generic?vcast32f#vcast32f_g[8i](v256x8i~in)
; vcast32f_g[8i](v256x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<float> vcast32f<ushort>(in Vector256<ushort> src), hex://vfuncs/generic?vcast32f#vcast32f_g[16u](v256x16u~in)
; vcast32f_g[16u](v256x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<float> vcast32f<short>(in Vector256<short> src), hex://vfuncs/generic?vcast32f#vcast32f_g[16i](v256x16i~in)
; vcast32f_g[16i](v256x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<float> vcast32f<uint>(in Vector256<uint> src), hex://vfuncs/generic?vcast32f#vcast32f_g[32u](v256x32u~in)
; vcast32f_g[32u](v256x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<float> vcast32f<int>(in Vector256<int> src), hex://vfuncs/generic?vcast32f#vcast32f_g[32i](v256x32i~in)
; vcast32f_g[32i](v256x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<float> vcast32f<ulong>(in Vector256<ulong> src), hex://vfuncs/generic?vcast32f#vcast32f_g[64u](v256x64u~in)
; vcast32f_g[64u](v256x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<float> vcast32f<long>(in Vector256<long> src), hex://vfuncs/generic?vcast32f#vcast32f_g[64i](v256x64i~in)
; vcast32f_g[64i](v256x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<float> vcast32f<float>(in Vector256<float> src), hex://vfuncs/generic?vcast32f#vcast32f_g[32f](v256x32f~in)
; vcast32f_g[32f](v256x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<float> vcast32f<double>(in Vector256<double> src), hex://vfuncs/generic?vcast32f#vcast32f_g[64f](v256x64f~in)
; vcast32f_g[64f](v256x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<double> vcast64f<byte>(in Vector256<byte> src), hex://vfuncs/generic?vcast64f#vcast64f_g[8u](v256x8u~in)
; vcast64f_g[8u](v256x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<double> vcast64f<sbyte>(in Vector256<sbyte> src), hex://vfuncs/generic?vcast64f#vcast64f_g[8i](v256x8i~in)
; vcast64f_g[8i](v256x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<double> vcast64f<ushort>(in Vector256<ushort> src), hex://vfuncs/generic?vcast64f#vcast64f_g[16u](v256x16u~in)
; vcast64f_g[16u](v256x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<double> vcast64f<short>(in Vector256<short> src), hex://vfuncs/generic?vcast64f#vcast64f_g[16i](v256x16i~in)
; vcast64f_g[16i](v256x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<double> vcast64f<uint>(in Vector256<uint> src), hex://vfuncs/generic?vcast64f#vcast64f_g[32u](v256x32u~in)
; vcast64f_g[32u](v256x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<double> vcast64f<int>(in Vector256<int> src), hex://vfuncs/generic?vcast64f#vcast64f_g[32i](v256x32i~in)
; vcast64f_g[32i](v256x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<double> vcast64f<ulong>(in Vector256<ulong> src), hex://vfuncs/generic?vcast64f#vcast64f_g[64u](v256x64u~in)
; vcast64f_g[64u](v256x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<double> vcast64f<long>(in Vector256<long> src), hex://vfuncs/generic?vcast64f#vcast64f_g[64i](v256x64i~in)
; vcast64f_g[64i](v256x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<double> vcast64f<float>(in Vector256<float> src), hex://vfuncs/generic?vcast64f#vcast64f_g[32f](v256x32f~in)
; vcast64f_g[32f](v256x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<double> vcast64f<double>(in Vector256<double> src), hex://vfuncs/generic?vcast64f#vcast64f_g[64f](v256x64f~in)
; vcast64f_g[64f](v256x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<sbyte> vcast8i<byte>(in Vector512<byte> src), hex://vfuncs/generic?vcast8i#vcast8i_g[8u](v512x8u~in)
; vcast8i_g[8u](v512x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<sbyte> vcast8i<sbyte>(in Vector512<sbyte> src), hex://vfuncs/generic?vcast8i#vcast8i_g[8i](v512x8i~in)
; vcast8i_g[8i](v512x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<sbyte> vcast8i<ushort>(in Vector512<ushort> src), hex://vfuncs/generic?vcast8i#vcast8i_g[16u](v512x16u~in)
; vcast8i_g[16u](v512x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<sbyte> vcast8i<short>(in Vector512<short> src), hex://vfuncs/generic?vcast8i#vcast8i_g[16i](v512x16i~in)
; vcast8i_g[16i](v512x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<sbyte> vcast8i<uint>(in Vector512<uint> src), hex://vfuncs/generic?vcast8i#vcast8i_g[32u](v512x32u~in)
; vcast8i_g[32u](v512x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<sbyte> vcast8i<int>(in Vector512<int> src), hex://vfuncs/generic?vcast8i#vcast8i_g[32i](v512x32i~in)
; vcast8i_g[32i](v512x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<sbyte> vcast8i<ulong>(in Vector512<ulong> src), hex://vfuncs/generic?vcast8i#vcast8i_g[64u](v512x64u~in)
; vcast8i_g[64u](v512x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<sbyte> vcast8i<long>(in Vector512<long> src), hex://vfuncs/generic?vcast8i#vcast8i_g[64i](v512x64i~in)
; vcast8i_g[64i](v512x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<sbyte> vcast8i<float>(in Vector512<float> src), hex://vfuncs/generic?vcast8i#vcast8i_g[32f](v512x32f~in)
; vcast8i_g[32f](v512x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<sbyte> vcast8i<double>(in Vector512<double> src), hex://vfuncs/generic?vcast8i#vcast8i_g[64f](v512x64f~in)
; vcast8i_g[64f](v512x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<byte> vcast8u<byte>(in Vector512<byte> src), hex://vfuncs/generic?vcast8u#vcast8u_g[8u](v512x8u~in)
; vcast8u_g[8u](v512x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<byte> vcast8u<sbyte>(in Vector512<sbyte> src), hex://vfuncs/generic?vcast8u#vcast8u_g[8i](v512x8i~in)
; vcast8u_g[8i](v512x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<byte> vcast8u<ushort>(in Vector512<ushort> src), hex://vfuncs/generic?vcast8u#vcast8u_g[16u](v512x16u~in)
; vcast8u_g[16u](v512x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<byte> vcast8u<short>(in Vector512<short> src), hex://vfuncs/generic?vcast8u#vcast8u_g[16i](v512x16i~in)
; vcast8u_g[16i](v512x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<byte> vcast8u<uint>(in Vector512<uint> src), hex://vfuncs/generic?vcast8u#vcast8u_g[32u](v512x32u~in)
; vcast8u_g[32u](v512x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<byte> vcast8u<int>(in Vector512<int> src), hex://vfuncs/generic?vcast8u#vcast8u_g[32i](v512x32i~in)
; vcast8u_g[32i](v512x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<byte> vcast8u<ulong>(in Vector512<ulong> src), hex://vfuncs/generic?vcast8u#vcast8u_g[64u](v512x64u~in)
; vcast8u_g[64u](v512x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<byte> vcast8u<long>(in Vector512<long> src), hex://vfuncs/generic?vcast8u#vcast8u_g[64i](v512x64i~in)
; vcast8u_g[64i](v512x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<byte> vcast8u<float>(in Vector512<float> src), hex://vfuncs/generic?vcast8u#vcast8u_g[32f](v512x32f~in)
; vcast8u_g[32f](v512x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<byte> vcast8u<double>(in Vector512<double> src), hex://vfuncs/generic?vcast8u#vcast8u_g[64f](v512x64f~in)
; vcast8u_g[64f](v512x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<short> vcast16i<byte>(in Vector512<byte> src), hex://vfuncs/generic?vcast16i#vcast16i_g[8u](v512x8u~in)
; vcast16i_g[8u](v512x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<short> vcast16i<sbyte>(in Vector512<sbyte> src), hex://vfuncs/generic?vcast16i#vcast16i_g[8i](v512x8i~in)
; vcast16i_g[8i](v512x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<short> vcast16i<ushort>(in Vector512<ushort> src), hex://vfuncs/generic?vcast16i#vcast16i_g[16u](v512x16u~in)
; vcast16i_g[16u](v512x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<short> vcast16i<short>(in Vector512<short> src), hex://vfuncs/generic?vcast16i#vcast16i_g[16i](v512x16i~in)
; vcast16i_g[16i](v512x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<short> vcast16i<uint>(in Vector512<uint> src), hex://vfuncs/generic?vcast16i#vcast16i_g[32u](v512x32u~in)
; vcast16i_g[32u](v512x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<short> vcast16i<int>(in Vector512<int> src), hex://vfuncs/generic?vcast16i#vcast16i_g[32i](v512x32i~in)
; vcast16i_g[32i](v512x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<short> vcast16i<ulong>(in Vector512<ulong> src), hex://vfuncs/generic?vcast16i#vcast16i_g[64u](v512x64u~in)
; vcast16i_g[64u](v512x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<short> vcast16i<long>(in Vector512<long> src), hex://vfuncs/generic?vcast16i#vcast16i_g[64i](v512x64i~in)
; vcast16i_g[64i](v512x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<short> vcast16i<float>(in Vector512<float> src), hex://vfuncs/generic?vcast16i#vcast16i_g[32f](v512x32f~in)
; vcast16i_g[32f](v512x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<short> vcast16i<double>(in Vector512<double> src), hex://vfuncs/generic?vcast16i#vcast16i_g[64f](v512x64f~in)
; vcast16i_g[64f](v512x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ushort> vcast16u<byte>(in Vector512<byte> src), hex://vfuncs/generic?vcast16u#vcast16u_g[8u](v512x8u~in)
; vcast16u_g[8u](v512x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ushort> vcast16u<sbyte>(in Vector512<sbyte> src), hex://vfuncs/generic?vcast16u#vcast16u_g[8i](v512x8i~in)
; vcast16u_g[8i](v512x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ushort> vcast16u<ushort>(in Vector512<ushort> src), hex://vfuncs/generic?vcast16u#vcast16u_g[16u](v512x16u~in)
; vcast16u_g[16u](v512x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ushort> vcast16u<short>(in Vector512<short> src), hex://vfuncs/generic?vcast16u#vcast16u_g[16i](v512x16i~in)
; vcast16u_g[16i](v512x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ushort> vcast16u<uint>(in Vector512<uint> src), hex://vfuncs/generic?vcast16u#vcast16u_g[32u](v512x32u~in)
; vcast16u_g[32u](v512x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ushort> vcast16u<int>(in Vector512<int> src), hex://vfuncs/generic?vcast16u#vcast16u_g[32i](v512x32i~in)
; vcast16u_g[32i](v512x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ushort> vcast16u<ulong>(in Vector512<ulong> src), hex://vfuncs/generic?vcast16u#vcast16u_g[64u](v512x64u~in)
; vcast16u_g[64u](v512x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ushort> vcast16u<long>(in Vector512<long> src), hex://vfuncs/generic?vcast16u#vcast16u_g[64i](v512x64i~in)
; vcast16u_g[64i](v512x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ushort> vcast16u<float>(in Vector512<float> src), hex://vfuncs/generic?vcast16u#vcast16u_g[32f](v512x32f~in)
; vcast16u_g[32f](v512x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ushort> vcast16u<double>(in Vector512<double> src), hex://vfuncs/generic?vcast16u#vcast16u_g[64f](v512x64f~in)
; vcast16u_g[64f](v512x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<int> vcast32i<byte>(in Vector512<byte> src), hex://vfuncs/generic?vcast32i#vcast32i_g[8u](v512x8u~in)
; vcast32i_g[8u](v512x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<int> vcast32i<sbyte>(in Vector512<sbyte> src), hex://vfuncs/generic?vcast32i#vcast32i_g[8i](v512x8i~in)
; vcast32i_g[8i](v512x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<int> vcast32i<ushort>(in Vector512<ushort> src), hex://vfuncs/generic?vcast32i#vcast32i_g[16u](v512x16u~in)
; vcast32i_g[16u](v512x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<int> vcast32i<short>(in Vector512<short> src), hex://vfuncs/generic?vcast32i#vcast32i_g[16i](v512x16i~in)
; vcast32i_g[16i](v512x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<int> vcast32i<uint>(in Vector512<uint> src), hex://vfuncs/generic?vcast32i#vcast32i_g[32u](v512x32u~in)
; vcast32i_g[32u](v512x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<int> vcast32i<int>(in Vector512<int> src), hex://vfuncs/generic?vcast32i#vcast32i_g[32i](v512x32i~in)
; vcast32i_g[32i](v512x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<int> vcast32i<ulong>(in Vector512<ulong> src), hex://vfuncs/generic?vcast32i#vcast32i_g[64u](v512x64u~in)
; vcast32i_g[64u](v512x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<int> vcast32i<long>(in Vector512<long> src), hex://vfuncs/generic?vcast32i#vcast32i_g[64i](v512x64i~in)
; vcast32i_g[64i](v512x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<int> vcast32i<float>(in Vector512<float> src), hex://vfuncs/generic?vcast32i#vcast32i_g[32f](v512x32f~in)
; vcast32i_g[32f](v512x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<int> vcast32i<double>(in Vector512<double> src), hex://vfuncs/generic?vcast32i#vcast32i_g[64f](v512x64f~in)
; vcast32i_g[64f](v512x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<uint> vcast32u<byte>(in Vector512<byte> src), hex://vfuncs/generic?vcast32u#vcast32u_g[8u](v512x8u~in)
; vcast32u_g[8u](v512x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<uint> vcast32u<sbyte>(in Vector512<sbyte> src), hex://vfuncs/generic?vcast32u#vcast32u_g[8i](v512x8i~in)
; vcast32u_g[8i](v512x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<uint> vcast32u<ushort>(in Vector512<ushort> src), hex://vfuncs/generic?vcast32u#vcast32u_g[16u](v512x16u~in)
; vcast32u_g[16u](v512x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<uint> vcast32u<short>(in Vector512<short> src), hex://vfuncs/generic?vcast32u#vcast32u_g[16i](v512x16i~in)
; vcast32u_g[16i](v512x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<uint> vcast32u<uint>(in Vector512<uint> src), hex://vfuncs/generic?vcast32u#vcast32u_g[32u](v512x32u~in)
; vcast32u_g[32u](v512x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<uint> vcast32u<int>(in Vector512<int> src), hex://vfuncs/generic?vcast32u#vcast32u_g[32i](v512x32i~in)
; vcast32u_g[32i](v512x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<uint> vcast32u<ulong>(in Vector512<ulong> src), hex://vfuncs/generic?vcast32u#vcast32u_g[64u](v512x64u~in)
; vcast32u_g[64u](v512x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<uint> vcast32u<long>(in Vector512<long> src), hex://vfuncs/generic?vcast32u#vcast32u_g[64i](v512x64i~in)
; vcast32u_g[64i](v512x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<uint> vcast32u<float>(in Vector512<float> src), hex://vfuncs/generic?vcast32u#vcast32u_g[32f](v512x32f~in)
; vcast32u_g[32f](v512x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<uint> vcast32u<double>(in Vector512<double> src), hex://vfuncs/generic?vcast32u#vcast32u_g[64f](v512x64f~in)
; vcast32u_g[64f](v512x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<long> vcast64i<byte>(in Vector512<byte> src), hex://vfuncs/generic?vcast64i#vcast64i_g[8u](v512x8u~in)
; vcast64i_g[8u](v512x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<long> vcast64i<sbyte>(in Vector512<sbyte> src), hex://vfuncs/generic?vcast64i#vcast64i_g[8i](v512x8i~in)
; vcast64i_g[8i](v512x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<long> vcast64i<ushort>(in Vector512<ushort> src), hex://vfuncs/generic?vcast64i#vcast64i_g[16u](v512x16u~in)
; vcast64i_g[16u](v512x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<long> vcast64i<short>(in Vector512<short> src), hex://vfuncs/generic?vcast64i#vcast64i_g[16i](v512x16i~in)
; vcast64i_g[16i](v512x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<long> vcast64i<uint>(in Vector512<uint> src), hex://vfuncs/generic?vcast64i#vcast64i_g[32u](v512x32u~in)
; vcast64i_g[32u](v512x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<long> vcast64i<int>(in Vector512<int> src), hex://vfuncs/generic?vcast64i#vcast64i_g[32i](v512x32i~in)
; vcast64i_g[32i](v512x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<long> vcast64i<ulong>(in Vector512<ulong> src), hex://vfuncs/generic?vcast64i#vcast64i_g[64u](v512x64u~in)
; vcast64i_g[64u](v512x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<long> vcast64i<long>(in Vector512<long> src), hex://vfuncs/generic?vcast64i#vcast64i_g[64i](v512x64i~in)
; vcast64i_g[64i](v512x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<long> vcast64i<float>(in Vector512<float> src), hex://vfuncs/generic?vcast64i#vcast64i_g[32f](v512x32f~in)
; vcast64i_g[32f](v512x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<long> vcast64i<double>(in Vector512<double> src), hex://vfuncs/generic?vcast64i#vcast64i_g[64f](v512x64f~in)
; vcast64i_g[64f](v512x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ulong> vcast64u<byte>(in Vector512<byte> src), hex://vfuncs/generic?vcast64u#vcast64u_g[8u](v512x8u~in)
; vcast64u_g[8u](v512x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ulong> vcast64u<sbyte>(in Vector512<sbyte> src), hex://vfuncs/generic?vcast64u#vcast64u_g[8i](v512x8i~in)
; vcast64u_g[8i](v512x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ulong> vcast64u<ushort>(in Vector512<ushort> src), hex://vfuncs/generic?vcast64u#vcast64u_g[16u](v512x16u~in)
; vcast64u_g[16u](v512x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ulong> vcast64u<short>(in Vector512<short> src), hex://vfuncs/generic?vcast64u#vcast64u_g[16i](v512x16i~in)
; vcast64u_g[16i](v512x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ulong> vcast64u<uint>(in Vector512<uint> src), hex://vfuncs/generic?vcast64u#vcast64u_g[32u](v512x32u~in)
; vcast64u_g[32u](v512x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ulong> vcast64u<int>(in Vector512<int> src), hex://vfuncs/generic?vcast64u#vcast64u_g[32i](v512x32i~in)
; vcast64u_g[32i](v512x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ulong> vcast64u<ulong>(in Vector512<ulong> src), hex://vfuncs/generic?vcast64u#vcast64u_g[64u](v512x64u~in)
; vcast64u_g[64u](v512x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ulong> vcast64u<long>(in Vector512<long> src), hex://vfuncs/generic?vcast64u#vcast64u_g[64i](v512x64i~in)
; vcast64u_g[64i](v512x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ulong> vcast64u<float>(in Vector512<float> src), hex://vfuncs/generic?vcast64u#vcast64u_g[32f](v512x32f~in)
; vcast64u_g[32f](v512x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ulong> vcast64u<double>(in Vector512<double> src), hex://vfuncs/generic?vcast64u#vcast64u_g[64f](v512x64f~in)
; vcast64u_g[64f](v512x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<float> vcast32f<byte>(in Vector512<byte> src), hex://vfuncs/generic?vcast32f#vcast32f_g[8u](v512x8u~in)
; vcast32f_g[8u](v512x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<float> vcast32f<sbyte>(in Vector512<sbyte> src), hex://vfuncs/generic?vcast32f#vcast32f_g[8i](v512x8i~in)
; vcast32f_g[8i](v512x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<float> vcast32f<ushort>(in Vector512<ushort> src), hex://vfuncs/generic?vcast32f#vcast32f_g[16u](v512x16u~in)
; vcast32f_g[16u](v512x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<float> vcast32f<short>(in Vector512<short> src), hex://vfuncs/generic?vcast32f#vcast32f_g[16i](v512x16i~in)
; vcast32f_g[16i](v512x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<float> vcast32f<uint>(in Vector512<uint> src), hex://vfuncs/generic?vcast32f#vcast32f_g[32u](v512x32u~in)
; vcast32f_g[32u](v512x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<float> vcast32f<int>(in Vector512<int> src), hex://vfuncs/generic?vcast32f#vcast32f_g[32i](v512x32i~in)
; vcast32f_g[32i](v512x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<float> vcast32f<ulong>(in Vector512<ulong> src), hex://vfuncs/generic?vcast32f#vcast32f_g[64u](v512x64u~in)
; vcast32f_g[64u](v512x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<float> vcast32f<long>(in Vector512<long> src), hex://vfuncs/generic?vcast32f#vcast32f_g[64i](v512x64i~in)
; vcast32f_g[64i](v512x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<float> vcast32f<float>(in Vector512<float> src), hex://vfuncs/generic?vcast32f#vcast32f_g[32f](v512x32f~in)
; vcast32f_g[32f](v512x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<float> vcast32f<double>(in Vector512<double> src), hex://vfuncs/generic?vcast32f#vcast32f_g[64f](v512x64f~in)
; vcast32f_g[64f](v512x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<double> vcast64f<byte>(in Vector512<byte> src), hex://vfuncs/generic?vcast64f#vcast64f_g[8u](v512x8u~in)
; vcast64f_g[8u](v512x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<double> vcast64f<sbyte>(in Vector512<sbyte> src), hex://vfuncs/generic?vcast64f#vcast64f_g[8i](v512x8i~in)
; vcast64f_g[8i](v512x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<double> vcast64f<ushort>(in Vector512<ushort> src), hex://vfuncs/generic?vcast64f#vcast64f_g[16u](v512x16u~in)
; vcast64f_g[16u](v512x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<double> vcast64f<short>(in Vector512<short> src), hex://vfuncs/generic?vcast64f#vcast64f_g[16i](v512x16i~in)
; vcast64f_g[16i](v512x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<double> vcast64f<uint>(in Vector512<uint> src), hex://vfuncs/generic?vcast64f#vcast64f_g[32u](v512x32u~in)
; vcast64f_g[32u](v512x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<double> vcast64f<int>(in Vector512<int> src), hex://vfuncs/generic?vcast64f#vcast64f_g[32i](v512x32i~in)
; vcast64f_g[32i](v512x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<double> vcast64f<ulong>(in Vector512<ulong> src), hex://vfuncs/generic?vcast64f#vcast64f_g[64u](v512x64u~in)
; vcast64f_g[64u](v512x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<double> vcast64f<long>(in Vector512<long> src), hex://vfuncs/generic?vcast64f#vcast64f_g[64i](v512x64i~in)
; vcast64f_g[64i](v512x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<double> vcast64f<float>(in Vector512<float> src), hex://vfuncs/generic?vcast64f#vcast64f_g[32f](v512x32f~in)
; vcast64f_g[32f](v512x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<double> vcast64f<double>(in Vector512<double> src), hex://vfuncs/generic?vcast64f#vcast64f_g[64f](v512x64f~in)
; vcast64f_g[64f](v512x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; byte vcell<byte>(Vector128<byte> src, int index), hex://vfuncs/generic?vcell#vcell_g[8u](v128x8u,32i)
; vcell_g[8u](v128x8u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x37,0xa0,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 37 a0 0b ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell<sbyte>(Vector128<sbyte> src, int index), hex://vfuncs/generic?vcell#vcell_g[8i](v128x8i,32i)
; vcell_g[8i](v128x8i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe6,0x9f,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e6 9f 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell<ushort>(Vector128<ushort> src, int index), hex://vfuncs/generic?vcell#vcell_g[16u](v128x16u,32i)
; vcell_g[16u](v128x16u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x97,0x9f,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 97 9f 0b ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell<short>(Vector128<short> src, int index), hex://vfuncs/generic?vcell#vcell_g[16i](v128x16i,32i)
; vcell_g[16i](v128x16i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x46,0x9f,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 46 9f 0b ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell<uint>(Vector128<uint> src, int index), hex://vfuncs/generic?vcell#vcell_g[32u](v128x32u,32i)
; vcell_g[32u](v128x32u,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf8,0x9e,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f8 9e 0b ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell<int>(Vector128<int> src, int index), hex://vfuncs/generic?vcell#vcell_g[32i](v128x32i,32i)
; vcell_g[32i](v128x32i,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa8,0x9e,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a8 9e 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell<ulong>(Vector128<ulong> src, int index), hex://vfuncs/generic?vcell#vcell_g[64u](v128x64u,32i)
; vcell_g[64u](v128x64u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x57,0x9e,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 57 9e 0b ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell<long>(Vector128<long> src, int index), hex://vfuncs/generic?vcell#vcell_g[64i](v128x64i,32i)
; vcell_g[64i](v128x64i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x07,0x9e,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 07 9e 0b ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell<float>(Vector128<float> src, int index), hex://vfuncs/generic?vcell#vcell_g[32f](v128x32f,32i)
; vcell_g[32f](v128x32f,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb6,0x99,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b6 99 0b ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell<double>(Vector128<double> src, int index), hex://vfuncs/generic?vcell#vcell_g[64f](v128x64f,32i)
; vcell_g[64f](v128x64f,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x66,0x99,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 66 99 0b ff}
------------------------------------------------------------------------------------------------------------------------
; byte vhead<byte>(Vector128<byte> src), hex://vfuncs/generic?vhead#vhead_g[8u](v128x8u)
; vhead_g[8u](v128x8u)[16] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc4,0xe3,0x79,0x14,0xc0,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vpextrb eax,xmm0,0                      ; VPEXTRB r32/m8, xmm2, imm8 || VEX.128.66.0F3A.W0 14 /r ib || encoded[6]{c4 e3 79 14 c0 00}
000fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; sbyte vhead<sbyte>(Vector128<sbyte> src), hex://vfuncs/generic?vhead#vhead_g[8i](v128x8i)
; vhead_g[8i](v128x8i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc4,0xe3,0x79,0x14,0xc0,0x00,0x48,0x0f,0xbe,0xc0,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vpextrb eax,xmm0,0                      ; VPEXTRB r32/m8, xmm2, imm8 || VEX.128.66.0F3A.W0 14 /r ib || encoded[6]{c4 e3 79 14 c0 00}
000fh movsx rax,al                            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[4]{48 0f be c0}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ushort vhead<ushort>(Vector128<ushort> src), hex://vfuncs/generic?vhead#vhead_g[16u](v128x16u)
; vhead_g[16u](v128x16u)[15] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0xc5,0xc0,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vpextrw eax,xmm0,0                      ; VPEXTRW r32, xmm1, imm8 || VEX.128.66.0F.W0 C5 /r ib || encoded[5]{c5 f9 c5 c0 00}
000eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; short vhead<short>(Vector128<short> src), hex://vfuncs/generic?vhead#vhead_g[16i](v128x16i)
; vhead_g[16i](v128x16i)[19] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0xc5,0xc0,0x00,0x48,0x0f,0xbf,0xc0,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vpextrw eax,xmm0,0                      ; VPEXTRW r32, xmm1, imm8 || VEX.128.66.0F.W0 C5 /r ib || encoded[5]{c5 f9 c5 c0 00}
000eh movsx rax,ax                            ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[4]{48 0f bf c0}
0012h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; uint vhead<uint>(Vector128<uint> src), hex://vfuncs/generic?vhead#vhead_g[32u](v128x32u)
; vhead_g[32u](v128x32u)[14] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x7e,0xc0,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovd eax,xmm0                          ; VMOVD r/m32, xmm1 || VEX.128.66.0F.W0 7E /r || encoded[4]{c5 f9 7e c0}
000dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vhead<int>(Vector128<int> src), hex://vfuncs/generic?vhead#vhead_g[32i](v128x32i)
; vhead_g[32i](v128x32i)[14] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x7e,0xc0,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovd eax,xmm0                          ; VMOVD r/m32, xmm1 || VEX.128.66.0F.W0 7E /r || encoded[4]{c5 f9 7e c0}
000dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ulong vhead<ulong>(Vector128<ulong> src), hex://vfuncs/generic?vhead#vhead_g[64u](v128x64u)
; vhead_g[64u](v128x64u)[15] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc4,0xe1,0xf9,0x7e,0xc0,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovq rax,xmm0                          ; VMOVQ r/m64, xmm1 || VEX.128.66.0F.W1 7E /r || encoded[5]{c4 e1 f9 7e c0}
000eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; long vhead<long>(Vector128<long> src), hex://vfuncs/generic?vhead#vhead_g[64i](v128x64i)
; vhead_g[64i](v128x64i)[15] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc4,0xe1,0xf9,0x7e,0xc0,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovq rax,xmm0                          ; VMOVQ r/m64, xmm1 || VEX.128.66.0F.W1 7E /r || encoded[5]{c4 e1 f9 7e c0}
000eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; float vhead<float>(Vector128<float> src), hex://vfuncs/generic?vhead#vhead_g[32f](v128x32f)
; vhead_g[32f](v128x32f)[10] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; double vhead<double>(Vector128<double> src), hex://vfuncs/generic?vhead#vhead_g[64f](v128x64f)
; vhead_g[64f](v128x64f)[10] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> vcell<byte>(Vector128<byte> src, int index, byte value), hex://vfuncs/generic?vcell#vcell_g[8u](v128x8u,32i,8u)
; vcell_g[8u](v128x8u,32i,8u)[63] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x02,0x41,0x83,0xf8,0x10,0x73,0x24,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0x44,0x88,0x0c,0x10,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x89,0x97,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
000bh cmp r8d,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 10}
000fh jae short 0035h                         ; JAE rel8 || 73 cb || encoded[2]{73 24}
0011h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0017h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
001fh mov [rax+rdx],r9b                       ; MOV r/m8, r8 || 88 /r || encoded[4]{44 88 0c 10}
0023h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
0029h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0030h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0034h ret                                     ; RET || C3 || encoded[1]{c3}
0035h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003ah call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 89 97 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> vcell<sbyte>(Vector128<sbyte> src, int index, sbyte value), hex://vfuncs/generic?vcell#vcell_g[8i](v128x8i,32i,8i)
; vcell_g[8i](v128x8i,32i,8i)[63] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x02,0x41,0x83,0xf8,0x10,0x73,0x24,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0x44,0x88,0x0c,0x10,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x29,0x97,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
000bh cmp r8d,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 10}
000fh jae short 0035h                         ; JAE rel8 || 73 cb || encoded[2]{73 24}
0011h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0017h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
001fh mov [rax+rdx],r9b                       ; MOV r/m8, r8 || 88 /r || encoded[4]{44 88 0c 10}
0023h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
0029h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0030h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0034h ret                                     ; RET || C3 || encoded[1]{c3}
0035h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003ah call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 29 97 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> vcell<ushort>(Vector128<ushort> src, int index, ushort value), hex://vfuncs/generic?vcell#vcell_g[16u](v128x16u,32i,16u)
; vcell_g[16u](v128x16u,32i,16u)[64] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x02,0x41,0x83,0xf8,0x08,0x73,0x25,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0x66,0x44,0x89,0x0c,0x50,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc8,0x96,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
000bh cmp r8d,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 08}
000fh jae short 0036h                         ; JAE rel8 || 73 cb || encoded[2]{73 25}
0011h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0017h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
001fh mov [rax+rdx*2],r9w                     ; MOV r/m16, r16 || o16 89 /r || encoded[5]{66 44 89 0c 50}
0024h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002ah vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0035h ret                                     ; RET || C3 || encoded[1]{c3}
0036h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c8 96 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> vcell<short>(Vector128<short> src, int index, short value), hex://vfuncs/generic?vcell#vcell_g[16i](v128x16i,32i,16i)
; vcell_g[16i](v128x16i,32i,16i)[64] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x02,0x41,0x83,0xf8,0x08,0x73,0x25,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0x66,0x44,0x89,0x0c,0x50,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x68,0x96,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
000bh cmp r8d,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 08}
000fh jae short 0036h                         ; JAE rel8 || 73 cb || encoded[2]{73 25}
0011h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0017h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
001fh mov [rax+rdx*2],r9w                     ; MOV r/m16, r16 || o16 89 /r || encoded[5]{66 44 89 0c 50}
0024h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002ah vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0035h ret                                     ; RET || C3 || encoded[1]{c3}
0036h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 68 96 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> vcell<uint>(Vector128<uint> src, int index, uint value), hex://vfuncs/generic?vcell#vcell_g[32u](v128x32u,32i,32u)
; vcell_g[32u](v128x32u,32i,32u)[63] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x02,0x41,0x83,0xf8,0x04,0x73,0x24,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0x44,0x89,0x0c,0x90,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x09,0x96,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
000bh cmp r8d,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 04}
000fh jae short 0035h                         ; JAE rel8 || 73 cb || encoded[2]{73 24}
0011h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0017h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
001fh mov [rax+rdx*4],r9d                     ; MOV r/m32, r32 || o32 89 /r || encoded[4]{44 89 0c 90}
0023h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
0029h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0030h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0034h ret                                     ; RET || C3 || encoded[1]{c3}
0035h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003ah call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 09 96 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> vcell<int>(Vector128<int> src, int index, int value), hex://vfuncs/generic?vcell#vcell_g[32i](v128x32i,32i,32i)
; vcell_g[32i](v128x32i,32i,32i)[63] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x02,0x41,0x83,0xf8,0x04,0x73,0x24,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0x44,0x89,0x0c,0x90,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa9,0x95,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
000bh cmp r8d,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 04}
000fh jae short 0035h                         ; JAE rel8 || 73 cb || encoded[2]{73 24}
0011h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0017h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
001fh mov [rax+rdx*4],r9d                     ; MOV r/m32, r32 || o32 89 /r || encoded[4]{44 89 0c 90}
0023h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
0029h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0030h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0034h ret                                     ; RET || C3 || encoded[1]{c3}
0035h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003ah call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a9 95 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> vcell<ulong>(Vector128<ulong> src, int index, ulong value), hex://vfuncs/generic?vcell#vcell_g[64u](v128x64u,32i,64u)
; vcell_g[64u](v128x64u,32i,64u)[63] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x02,0x41,0x83,0xf8,0x02,0x73,0x24,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0x4c,0x89,0x0c,0xd0,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x49,0x95,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
000bh cmp r8d,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 02}
000fh jae short 0035h                         ; JAE rel8 || 73 cb || encoded[2]{73 24}
0011h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0017h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
001fh mov [rax+rdx*8],r9                      ; MOV r/m64, r64 || REX.W 89 /r || encoded[4]{4c 89 0c d0}
0023h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
0029h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0030h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0034h ret                                     ; RET || C3 || encoded[1]{c3}
0035h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003ah call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 49 95 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> vcell<long>(Vector128<long> src, int index, long value), hex://vfuncs/generic?vcell#vcell_g[64i](v128x64i,32i,64i)
; vcell_g[64i](v128x64i,32i,64i)[63] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x02,0x41,0x83,0xf8,0x02,0x73,0x24,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0x4c,0x89,0x0c,0xd0,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe9,0x94,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
000bh cmp r8d,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 02}
000fh jae short 0035h                         ; JAE rel8 || 73 cb || encoded[2]{73 24}
0011h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0017h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
001fh mov [rax+rdx*8],r9                      ; MOV r/m64, r64 || REX.W 89 /r || encoded[4]{4c 89 0c d0}
0023h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
0029h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0030h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0034h ret                                     ; RET || C3 || encoded[1]{c3}
0035h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003ah call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e9 94 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> vcell<float>(Vector128<float> src, int index, float value), hex://vfuncs/generic?vcell#vcell_g[32f](v128x32f,32i,32f)
; vcell_g[32f](v128x32f,32i,32f)[64] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x02,0x41,0x83,0xf8,0x04,0x73,0x25,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0xc5,0xfa,0x11,0x1c,0x90,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x88,0x94,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
000bh cmp r8d,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 04}
000fh jae short 0036h                         ; JAE rel8 || 73 cb || encoded[2]{73 25}
0011h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0017h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
001fh vmovss dword ptr [rax+rdx*4],xmm3       ; VMOVSS m32, xmm1 || VEX.LIG.F3.0F.WIG 11 /r || encoded[5]{c5 fa 11 1c 90}
0024h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002ah vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0035h ret                                     ; RET || C3 || encoded[1]{c3}
0036h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 88 94 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> vcell<double>(Vector128<double> src, int index, double value), hex://vfuncs/generic?vcell#vcell_g[64f](v128x64f,32i,64f)
; vcell_g[64f](v128x64f,32i,64f)[64] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x02,0x41,0x83,0xf8,0x02,0x73,0x25,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0xc5,0xfb,0x11,0x1c,0xd0,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x28,0x94,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
000bh cmp r8d,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 02}
000fh jae short 0036h                         ; JAE rel8 || 73 cb || encoded[2]{73 25}
0011h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0017h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
001fh vmovsd qword ptr [rax+rdx*8],xmm3       ; VMOVSD m64, xmm1 || VEX.LIG.F2.0F.WIG 11 /r || encoded[5]{c5 fb 11 1c d0}
0024h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002ah vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0035h ret                                     ; RET || C3 || encoded[1]{c3}
0036h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 28 94 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> vcell<byte>(byte src, int index, Vector128<byte> dst), hex://vfuncs/generic?vcell#vcell_g[8u](8u,32i,v128x8u)
; vcell_g[8u](8u,32i,v128x8u)[64] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc4,0xc1,0x79,0x10,0x01,0x41,0x83,0xf8,0x10,0x73,0x24,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x42,0x88,0x14,0x00,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc8,0x93,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[r9]                       ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[5]{c4 c1 79 10 01}
000ch cmp r8d,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 10}
0010h jae short 0036h                         ; JAE rel8 || 73 cb || encoded[2]{73 24}
0012h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8],dl                         ; MOV r/m8, r8 || 88 /r || encoded[4]{42 88 14 00}
0024h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002ah vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0035h ret                                     ; RET || C3 || encoded[1]{c3}
0036h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c8 93 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> vcell<sbyte>(sbyte src, int index, Vector128<sbyte> dst), hex://vfuncs/generic?vcell#vcell_g[8i](8i,32i,v128x8i)
; vcell_g[8i](8i,32i,v128x8i)[64] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc4,0xc1,0x79,0x10,0x01,0x41,0x83,0xf8,0x10,0x73,0x24,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x42,0x88,0x14,0x00,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x68,0x93,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[r9]                       ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[5]{c4 c1 79 10 01}
000ch cmp r8d,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 10}
0010h jae short 0036h                         ; JAE rel8 || 73 cb || encoded[2]{73 24}
0012h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8],dl                         ; MOV r/m8, r8 || 88 /r || encoded[4]{42 88 14 00}
0024h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002ah vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0035h ret                                     ; RET || C3 || encoded[1]{c3}
0036h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 68 93 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> vcell<ushort>(ushort src, int index, Vector128<ushort> dst), hex://vfuncs/generic?vcell#vcell_g[16u](16u,32i,v128x16u)
; vcell_g[16u](16u,32i,v128x16u)[65] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc4,0xc1,0x79,0x10,0x01,0x41,0x83,0xf8,0x08,0x73,0x25,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x66,0x42,0x89,0x14,0x40,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x07,0x93,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[r9]                       ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[5]{c4 c1 79 10 01}
000ch cmp r8d,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 08}
0010h jae short 0037h                         ; JAE rel8 || 73 cb || encoded[2]{73 25}
0012h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8*2],dx                       ; MOV r/m16, r16 || o16 89 /r || encoded[5]{66 42 89 14 40}
0025h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002bh vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002fh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0032h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0036h ret                                     ; RET || C3 || encoded[1]{c3}
0037h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 07 93 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> vcell<short>(short src, int index, Vector128<short> dst), hex://vfuncs/generic?vcell#vcell_g[16i](16i,32i,v128x16i)
; vcell_g[16i](16i,32i,v128x16i)[65] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc4,0xc1,0x79,0x10,0x01,0x41,0x83,0xf8,0x08,0x73,0x25,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x66,0x42,0x89,0x14,0x40,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa7,0x92,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[r9]                       ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[5]{c4 c1 79 10 01}
000ch cmp r8d,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 08}
0010h jae short 0037h                         ; JAE rel8 || 73 cb || encoded[2]{73 25}
0012h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8*2],dx                       ; MOV r/m16, r16 || o16 89 /r || encoded[5]{66 42 89 14 40}
0025h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002bh vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002fh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0032h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0036h ret                                     ; RET || C3 || encoded[1]{c3}
0037h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a7 92 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> vcell<uint>(uint src, int index, Vector128<uint> dst), hex://vfuncs/generic?vcell#vcell_g[32u](32u,32i,v128x32u)
; vcell_g[32u](32u,32i,v128x32u)[64] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc4,0xc1,0x79,0x10,0x01,0x41,0x83,0xf8,0x04,0x73,0x24,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x42,0x89,0x14,0x80,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x48,0x92,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[r9]                       ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[5]{c4 c1 79 10 01}
000ch cmp r8d,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 04}
0010h jae short 0036h                         ; JAE rel8 || 73 cb || encoded[2]{73 24}
0012h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8*4],edx                      ; MOV r/m32, r32 || o32 89 /r || encoded[4]{42 89 14 80}
0024h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002ah vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0035h ret                                     ; RET || C3 || encoded[1]{c3}
0036h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 48 92 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> vcell<int>(int src, int index, Vector128<int> dst), hex://vfuncs/generic?vcell#vcell_g[32i](32i,32i,v128x32i)
; vcell_g[32i](32i,32i,v128x32i)[64] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc4,0xc1,0x79,0x10,0x01,0x41,0x83,0xf8,0x04,0x73,0x24,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x42,0x89,0x14,0x80,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe8,0x91,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[r9]                       ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[5]{c4 c1 79 10 01}
000ch cmp r8d,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 04}
0010h jae short 0036h                         ; JAE rel8 || 73 cb || encoded[2]{73 24}
0012h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8*4],edx                      ; MOV r/m32, r32 || o32 89 /r || encoded[4]{42 89 14 80}
0024h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002ah vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0035h ret                                     ; RET || C3 || encoded[1]{c3}
0036h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e8 91 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> vcell<ulong>(ulong src, int index, Vector128<ulong> dst), hex://vfuncs/generic?vcell#vcell_g[64u](64u,32i,v128x64u)
; vcell_g[64u](64u,32i,v128x64u)[64] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc4,0xc1,0x79,0x10,0x01,0x41,0x83,0xf8,0x02,0x73,0x24,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x4a,0x89,0x14,0xc0,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x88,0x91,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[r9]                       ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[5]{c4 c1 79 10 01}
000ch cmp r8d,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 02}
0010h jae short 0036h                         ; JAE rel8 || 73 cb || encoded[2]{73 24}
0012h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8*8],rdx                      ; MOV r/m64, r64 || REX.W 89 /r || encoded[4]{4a 89 14 c0}
0024h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002ah vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0035h ret                                     ; RET || C3 || encoded[1]{c3}
0036h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 88 91 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> vcell<long>(long src, int index, Vector128<long> dst), hex://vfuncs/generic?vcell#vcell_g[64i](64i,32i,v128x64i)
; vcell_g[64i](64i,32i,v128x64i)[64] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc4,0xc1,0x79,0x10,0x01,0x41,0x83,0xf8,0x02,0x73,0x24,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x4a,0x89,0x14,0xc0,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x28,0x91,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[r9]                       ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[5]{c4 c1 79 10 01}
000ch cmp r8d,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 02}
0010h jae short 0036h                         ; JAE rel8 || 73 cb || encoded[2]{73 24}
0012h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8*8],rdx                      ; MOV r/m64, r64 || REX.W 89 /r || encoded[4]{4a 89 14 c0}
0024h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002ah vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0035h ret                                     ; RET || C3 || encoded[1]{c3}
0036h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 28 91 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> vcell<float>(float src, int index, Vector128<float> dst), hex://vfuncs/generic?vcell#vcell_g[32f](32f,32i,v128x32f)
; vcell_g[32f](32f,32i,v128x32f)[65] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc4,0xc1,0x79,0x10,0x01,0x41,0x83,0xf8,0x04,0x73,0x25,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0xc5,0xfa,0x11,0x0c,0x90,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc7,0x90,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[r9]                       ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[5]{c4 c1 79 10 01}
000ch cmp r8d,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 04}
0010h jae short 0037h                         ; JAE rel8 || 73 cb || encoded[2]{73 25}
0012h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0020h vmovss dword ptr [rax+rdx*4],xmm1       ; VMOVSS m32, xmm1 || VEX.LIG.F3.0F.WIG 11 /r || encoded[5]{c5 fa 11 0c 90}
0025h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002bh vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002fh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0032h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0036h ret                                     ; RET || C3 || encoded[1]{c3}
0037h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c7 90 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> vcell<double>(double src, int index, Vector128<double> dst), hex://vfuncs/generic?vcell#vcell_g[64f](64f,32i,v128x64f)
; vcell_g[64f](64f,32i,v128x64f)[65] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc4,0xc1,0x79,0x10,0x01,0x41,0x83,0xf8,0x02,0x73,0x25,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0xc5,0xfb,0x11,0x0c,0xd0,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x67,0x90,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[r9]                       ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[5]{c4 c1 79 10 01}
000ch cmp r8d,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 02}
0010h jae short 0037h                         ; JAE rel8 || 73 cb || encoded[2]{73 25}
0012h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0020h vmovsd qword ptr [rax+rdx*8],xmm1       ; VMOVSD m64, xmm1 || VEX.LIG.F2.0F.WIG 11 /r || encoded[5]{c5 fb 11 0c d0}
0025h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002bh vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002fh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0032h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0036h ret                                     ; RET || C3 || encoded[1]{c3}
0037h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 67 90 0b ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell<byte>(Vector256<byte> src, int index), hex://vfuncs/generic?vcell#vcell_g[8u](v256x8u,32i)
; vcell_g[8u](v256x8u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x04,0x8c,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 04 8c 0b ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell<sbyte>(Vector256<sbyte> src, int index), hex://vfuncs/generic?vcell#vcell_g[8i](v256x8i,32i)
; vcell_g[8i](v256x8i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb3,0x8b,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b3 8b 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell<ushort>(Vector256<ushort> src, int index), hex://vfuncs/generic?vcell#vcell_g[16u](v256x16u,32i)
; vcell_g[16u](v256x16u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x64,0x8b,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 64 8b 0b ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell<short>(Vector256<short> src, int index), hex://vfuncs/generic?vcell#vcell_g[16i](v256x16i,32i)
; vcell_g[16i](v256x16i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x13,0x8b,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 13 8b 0b ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell<uint>(Vector256<uint> src, int index), hex://vfuncs/generic?vcell#vcell_g[32u](v256x32u,32i)
; vcell_g[32u](v256x32u,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc5,0x8a,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c5 8a 0b ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell<int>(Vector256<int> src, int index), hex://vfuncs/generic?vcell#vcell_g[32i](v256x32i,32i)
; vcell_g[32i](v256x32i,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x75,0x8a,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 75 8a 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell<ulong>(Vector256<ulong> src, int index), hex://vfuncs/generic?vcell#vcell_g[64u](v256x64u,32i)
; vcell_g[64u](v256x64u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x24,0x8a,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 24 8a 0b ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell<long>(Vector256<long> src, int index), hex://vfuncs/generic?vcell#vcell_g[64i](v256x64i,32i)
; vcell_g[64i](v256x64i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd4,0x89,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d4 89 0b ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell<float>(Vector256<float> src, int index), hex://vfuncs/generic?vcell#vcell_g[32f](v256x32f,32i)
; vcell_g[32f](v256x32f,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x83,0x89,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 83 89 0b ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell<double>(Vector256<double> src, int index), hex://vfuncs/generic?vcell#vcell_g[64f](v256x64f,32i)
; vcell_g[64f](v256x64f,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x33,0x89,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 33 89 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector256<byte> vcell<byte>(byte src, int index, Vector256<byte> dst), hex://vfuncs/generic?vcell#vcell_g[8u](8u,32i,v256x8u)
; vcell_g[8u](8u,32i,v256x8u)[67] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc4,0xc1,0x7d,0x10,0x01,0x41,0x83,0xf8,0x20,0x73,0x27,0xc5,0xfd,0x11,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x42,0x88,0x14,0x00,0xc5,0xfd,0x10,0x44,0x24,0x20,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd5,0x88,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[r9]                       ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c4 c1 7d 10 01}
000ch cmp r8d,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 20}
0010h jae short 0039h                         ; JAE rel8 || 73 cb || encoded[2]{73 27}
0012h vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8],dl                         ; MOV r/m8, r8 || 88 /r || encoded[4]{42 88 14 00}
0024h vmovupd ymm0,[rsp+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[6]{c5 fd 10 44 24 20}
002ah vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0034h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0038h ret                                     ; RET || C3 || encoded[1]{c3}
0039h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d5 88 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector256<sbyte> vcell<sbyte>(sbyte src, int index, Vector256<sbyte> dst), hex://vfuncs/generic?vcell#vcell_g[8i](8i,32i,v256x8i)
; vcell_g[8i](8i,32i,v256x8i)[67] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc4,0xc1,0x7d,0x10,0x01,0x41,0x83,0xf8,0x20,0x73,0x27,0xc5,0xfd,0x11,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x42,0x88,0x14,0x00,0xc5,0xfd,0x10,0x44,0x24,0x20,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x75,0x88,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[r9]                       ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c4 c1 7d 10 01}
000ch cmp r8d,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 20}
0010h jae short 0039h                         ; JAE rel8 || 73 cb || encoded[2]{73 27}
0012h vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8],dl                         ; MOV r/m8, r8 || 88 /r || encoded[4]{42 88 14 00}
0024h vmovupd ymm0,[rsp+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[6]{c5 fd 10 44 24 20}
002ah vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0034h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0038h ret                                     ; RET || C3 || encoded[1]{c3}
0039h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 75 88 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ushort> vcell<ushort>(ushort src, int index, Vector256<ushort> dst), hex://vfuncs/generic?vcell#vcell_g[16u](16u,32i,v256x16u)
; vcell_g[16u](16u,32i,v256x16u)[68] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc4,0xc1,0x7d,0x10,0x01,0x41,0x83,0xf8,0x10,0x73,0x28,0xc5,0xfd,0x11,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x66,0x42,0x89,0x14,0x40,0xc5,0xfd,0x10,0x44,0x24,0x20,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x14,0x88,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[r9]                       ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c4 c1 7d 10 01}
000ch cmp r8d,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 10}
0010h jae short 003ah                         ; JAE rel8 || 73 cb || encoded[2]{73 28}
0012h vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8*2],dx                       ; MOV r/m16, r16 || o16 89 /r || encoded[5]{66 42 89 14 40}
0025h vmovupd ymm0,[rsp+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[6]{c5 fd 10 44 24 20}
002bh vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
002fh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0032h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0035h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0039h ret                                     ; RET || C3 || encoded[1]{c3}
003ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 14 88 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector256<short> vcell<short>(short src, int index, Vector256<short> dst), hex://vfuncs/generic?vcell#vcell_g[16i](16i,32i,v256x16i)
; vcell_g[16i](16i,32i,v256x16i)[68] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc4,0xc1,0x7d,0x10,0x01,0x41,0x83,0xf8,0x10,0x73,0x28,0xc5,0xfd,0x11,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x66,0x42,0x89,0x14,0x40,0xc5,0xfd,0x10,0x44,0x24,0x20,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb4,0x87,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[r9]                       ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c4 c1 7d 10 01}
000ch cmp r8d,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 10}
0010h jae short 003ah                         ; JAE rel8 || 73 cb || encoded[2]{73 28}
0012h vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8*2],dx                       ; MOV r/m16, r16 || o16 89 /r || encoded[5]{66 42 89 14 40}
0025h vmovupd ymm0,[rsp+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[6]{c5 fd 10 44 24 20}
002bh vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
002fh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0032h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0035h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0039h ret                                     ; RET || C3 || encoded[1]{c3}
003ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b4 87 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector256<uint> vcell<uint>(uint src, int index, Vector256<uint> dst), hex://vfuncs/generic?vcell#vcell_g[32u](32u,32i,v256x32u)
; vcell_g[32u](32u,32i,v256x32u)[67] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc4,0xc1,0x7d,0x10,0x01,0x41,0x83,0xf8,0x08,0x73,0x27,0xc5,0xfd,0x11,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x42,0x89,0x14,0x80,0xc5,0xfd,0x10,0x44,0x24,0x20,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x55,0x87,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[r9]                       ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c4 c1 7d 10 01}
000ch cmp r8d,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 08}
0010h jae short 0039h                         ; JAE rel8 || 73 cb || encoded[2]{73 27}
0012h vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8*4],edx                      ; MOV r/m32, r32 || o32 89 /r || encoded[4]{42 89 14 80}
0024h vmovupd ymm0,[rsp+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[6]{c5 fd 10 44 24 20}
002ah vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0034h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0038h ret                                     ; RET || C3 || encoded[1]{c3}
0039h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 55 87 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector256<int> vcell<int>(int src, int index, Vector256<int> dst), hex://vfuncs/generic?vcell#vcell_g[32i](32i,32i,v256x32i)
; vcell_g[32i](32i,32i,v256x32i)[67] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc4,0xc1,0x7d,0x10,0x01,0x41,0x83,0xf8,0x08,0x73,0x27,0xc5,0xfd,0x11,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x42,0x89,0x14,0x80,0xc5,0xfd,0x10,0x44,0x24,0x20,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf5,0x86,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[r9]                       ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c4 c1 7d 10 01}
000ch cmp r8d,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 08}
0010h jae short 0039h                         ; JAE rel8 || 73 cb || encoded[2]{73 27}
0012h vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8*4],edx                      ; MOV r/m32, r32 || o32 89 /r || encoded[4]{42 89 14 80}
0024h vmovupd ymm0,[rsp+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[6]{c5 fd 10 44 24 20}
002ah vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0034h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0038h ret                                     ; RET || C3 || encoded[1]{c3}
0039h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f5 86 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ulong> vcell<ulong>(ulong src, int index, Vector256<ulong> dst), hex://vfuncs/generic?vcell#vcell_g[64u](64u,32i,v256x64u)
; vcell_g[64u](64u,32i,v256x64u)[67] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc4,0xc1,0x7d,0x10,0x01,0x41,0x83,0xf8,0x04,0x73,0x27,0xc5,0xfd,0x11,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x4a,0x89,0x14,0xc0,0xc5,0xfd,0x10,0x44,0x24,0x20,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x95,0x86,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[r9]                       ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c4 c1 7d 10 01}
000ch cmp r8d,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 04}
0010h jae short 0039h                         ; JAE rel8 || 73 cb || encoded[2]{73 27}
0012h vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8*8],rdx                      ; MOV r/m64, r64 || REX.W 89 /r || encoded[4]{4a 89 14 c0}
0024h vmovupd ymm0,[rsp+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[6]{c5 fd 10 44 24 20}
002ah vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0034h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0038h ret                                     ; RET || C3 || encoded[1]{c3}
0039h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 95 86 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector256<long> vcell<long>(long src, int index, Vector256<long> dst), hex://vfuncs/generic?vcell#vcell_g[64i](64i,32i,v256x64i)
; vcell_g[64i](64i,32i,v256x64i)[67] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc4,0xc1,0x7d,0x10,0x01,0x41,0x83,0xf8,0x04,0x73,0x27,0xc5,0xfd,0x11,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x4a,0x89,0x14,0xc0,0xc5,0xfd,0x10,0x44,0x24,0x20,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x35,0x86,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[r9]                       ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c4 c1 7d 10 01}
000ch cmp r8d,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 04}
0010h jae short 0039h                         ; JAE rel8 || 73 cb || encoded[2]{73 27}
0012h vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8*8],rdx                      ; MOV r/m64, r64 || REX.W 89 /r || encoded[4]{4a 89 14 c0}
0024h vmovupd ymm0,[rsp+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[6]{c5 fd 10 44 24 20}
002ah vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0034h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0038h ret                                     ; RET || C3 || encoded[1]{c3}
0039h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 35 86 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector256<float> vcell<float>(float src, int index, Vector256<float> dst), hex://vfuncs/generic?vcell#vcell_g[32f](32f,32i,v256x32f)
; vcell_g[32f](32f,32i,v256x32f)[68] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc4,0xc1,0x7d,0x10,0x01,0x41,0x83,0xf8,0x08,0x73,0x28,0xc5,0xfd,0x11,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0xc5,0xfa,0x11,0x0c,0x90,0xc5,0xfd,0x10,0x44,0x24,0x20,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd4,0x85,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[r9]                       ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c4 c1 7d 10 01}
000ch cmp r8d,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 08}
0010h jae short 003ah                         ; JAE rel8 || 73 cb || encoded[2]{73 28}
0012h vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0020h vmovss dword ptr [rax+rdx*4],xmm1       ; VMOVSS m32, xmm1 || VEX.LIG.F3.0F.WIG 11 /r || encoded[5]{c5 fa 11 0c 90}
0025h vmovupd ymm0,[rsp+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[6]{c5 fd 10 44 24 20}
002bh vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
002fh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0032h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0035h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0039h ret                                     ; RET || C3 || encoded[1]{c3}
003ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d4 85 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector256<double> vcell<double>(double src, int index, Vector256<double> dst), hex://vfuncs/generic?vcell#vcell_g[64f](64f,32i,v256x64f)
; vcell_g[64f](64f,32i,v256x64f)[68] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc4,0xc1,0x7d,0x10,0x01,0x41,0x83,0xf8,0x04,0x73,0x28,0xc5,0xfd,0x11,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0xc5,0xfb,0x11,0x0c,0xd0,0xc5,0xfd,0x10,0x44,0x24,0x20,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x74,0x85,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[r9]                       ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c4 c1 7d 10 01}
000ch cmp r8d,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 04}
0010h jae short 003ah                         ; JAE rel8 || 73 cb || encoded[2]{73 28}
0012h vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0020h vmovsd qword ptr [rax+rdx*8],xmm1       ; VMOVSD m64, xmm1 || VEX.LIG.F2.0F.WIG 11 /r || encoded[5]{c5 fb 11 0c d0}
0025h vmovupd ymm0,[rsp+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[6]{c5 fd 10 44 24 20}
002bh vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
002fh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0032h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0035h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0039h ret                                     ; RET || C3 || encoded[1]{c3}
003ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 74 85 0b ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<byte>(Vector128<byte> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[8u](v128x8u,32i)
; vcell8i_g[8u](v128x8u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x26,0x85,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 26 85 0b ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<sbyte>(Vector128<sbyte> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[8i](v128x8i,32i)
; vcell8i_g[8i](v128x8i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd6,0x84,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d6 84 0b ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<ushort>(Vector128<ushort> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[16u](v128x16u,32i)
; vcell8i_g[16u](v128x16u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x86,0x84,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 86 84 0b ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<short>(Vector128<short> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[16i](v128x16i,32i)
; vcell8i_g[16i](v128x16i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x26,0x80,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 26 80 0b ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<uint>(Vector128<uint> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[32u](v128x32u,32i)
; vcell8i_g[32u](v128x32u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd6,0x7f,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d6 7f 0b ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<int>(Vector128<int> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[32i](v128x32i,32i)
; vcell8i_g[32i](v128x32i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x86,0x7f,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 86 7f 0b ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<ulong>(Vector128<ulong> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[64u](v128x64u,32i)
; vcell8i_g[64u](v128x64u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x36,0x7f,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 36 7f 0b ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<long>(Vector128<long> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[64i](v128x64i,32i)
; vcell8i_g[64i](v128x64i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe6,0x7e,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e6 7e 0b ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<float>(Vector128<float> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[32f](v128x32f,32i)
; vcell8i_g[32f](v128x32f,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x96,0x7e,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 96 7e 0b ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<double>(Vector128<double> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[64f](v128x64f,32i)
; vcell8i_g[64f](v128x64f,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x46,0x7e,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 46 7e 0b ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<byte>(Vector128<byte> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[8u](v128x8u,32i)
; vcell8_g[8u](v128x8u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf7,0x7d,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f7 7d 0b ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<sbyte>(Vector128<sbyte> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[8i](v128x8i,32i)
; vcell8_g[8i](v128x8i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa7,0x7d,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a7 7d 0b ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<ushort>(Vector128<ushort> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[16u](v128x16u,32i)
; vcell8_g[16u](v128x16u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x57,0x7d,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 57 7d 0b ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<short>(Vector128<short> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[16i](v128x16i,32i)
; vcell8_g[16i](v128x16i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x07,0x7d,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 07 7d 0b ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<uint>(Vector128<uint> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[32u](v128x32u,32i)
; vcell8_g[32u](v128x32u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb7,0x7c,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b7 7c 0b ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<int>(Vector128<int> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[32i](v128x32i,32i)
; vcell8_g[32i](v128x32i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x67,0x7c,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 67 7c 0b ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<ulong>(Vector128<ulong> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[64u](v128x64u,32i)
; vcell8_g[64u](v128x64u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x17,0x7c,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 17 7c 0b ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<long>(Vector128<long> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[64i](v128x64i,32i)
; vcell8_g[64i](v128x64i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc7,0x7b,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c7 7b 0b ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<float>(Vector128<float> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[32f](v128x32f,32i)
; vcell8_g[32f](v128x32f,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x77,0x7b,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 77 7b 0b ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<double>(Vector128<double> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[64f](v128x64f,32i)
; vcell8_g[64f](v128x64f,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x27,0x7b,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 27 7b 0b ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<byte>(Vector128<byte> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[8u](v128x8u,32i)
; vcell16i_g[8u](v128x8u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd6,0x7a,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d6 7a 0b ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<sbyte>(Vector128<sbyte> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[8i](v128x8i,32i)
; vcell16i_g[8i](v128x8i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x86,0x7a,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 86 7a 0b ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<ushort>(Vector128<ushort> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[16u](v128x16u,32i)
; vcell16i_g[16u](v128x16u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x36,0x7a,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 36 7a 0b ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<short>(Vector128<short> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[16i](v128x16i,32i)
; vcell16i_g[16i](v128x16i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe6,0x79,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e6 79 0b ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<uint>(Vector128<uint> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[32u](v128x32u,32i)
; vcell16i_g[32u](v128x32u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x96,0x79,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 96 79 0b ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<int>(Vector128<int> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[32i](v128x32i,32i)
; vcell16i_g[32i](v128x32i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x46,0x79,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 46 79 0b ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<ulong>(Vector128<ulong> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[64u](v128x64u,32i)
; vcell16i_g[64u](v128x64u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf6,0x78,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f6 78 0b ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<long>(Vector128<long> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[64i](v128x64i,32i)
; vcell16i_g[64i](v128x64i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa6,0x78,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a6 78 0b ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<float>(Vector128<float> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[32f](v128x32f,32i)
; vcell16i_g[32f](v128x32f,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x56,0x78,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 56 78 0b ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<double>(Vector128<double> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[64f](v128x64f,32i)
; vcell16i_g[64f](v128x64f,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x06,0x78,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 06 78 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<byte>(Vector128<byte> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[8u](v128x8u,32i)
; vcell16_g[8u](v128x8u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa7,0x73,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a7 73 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<sbyte>(Vector128<sbyte> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[8i](v128x8i,32i)
; vcell16_g[8i](v128x8i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x57,0x73,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 57 73 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<ushort>(Vector128<ushort> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[16u](v128x16u,32i)
; vcell16_g[16u](v128x16u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x07,0x73,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 07 73 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<short>(Vector128<short> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[16i](v128x16i,32i)
; vcell16_g[16i](v128x16i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb7,0x72,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b7 72 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<uint>(Vector128<uint> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[32u](v128x32u,32i)
; vcell16_g[32u](v128x32u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x67,0x72,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 67 72 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<int>(Vector128<int> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[32i](v128x32i,32i)
; vcell16_g[32i](v128x32i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x17,0x72,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 17 72 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<ulong>(Vector128<ulong> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[64u](v128x64u,32i)
; vcell16_g[64u](v128x64u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc7,0x71,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c7 71 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<long>(Vector128<long> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[64i](v128x64i,32i)
; vcell16_g[64i](v128x64i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x77,0x71,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 77 71 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<float>(Vector128<float> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[32f](v128x32f,32i)
; vcell16_g[32f](v128x32f,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x27,0x71,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 27 71 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<double>(Vector128<double> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[64f](v128x64f,32i)
; vcell16_g[64f](v128x64f,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd7,0x70,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d7 70 0b ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<byte>(Vector128<byte> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[8u](v128x8u,32i)
; vcell32i_g[8u](v128x8u,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x88,0x70,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 88 70 0b ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<sbyte>(Vector128<sbyte> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[8i](v128x8i,32i)
; vcell32i_g[8i](v128x8i,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x38,0x70,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 38 70 0b ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<ushort>(Vector128<ushort> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[16u](v128x16u,32i)
; vcell32i_g[16u](v128x16u,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe8,0x6f,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e8 6f 0b ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<short>(Vector128<short> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[16i](v128x16i,32i)
; vcell32i_g[16i](v128x16i,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x98,0x6f,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 98 6f 0b ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<uint>(Vector128<uint> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[32u](v128x32u,32i)
; vcell32i_g[32u](v128x32u,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x48,0x6f,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 48 6f 0b ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<int>(Vector128<int> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[32i](v128x32i,32i)
; vcell32i_g[32i](v128x32i,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf8,0x6e,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f8 6e 0b ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<ulong>(Vector128<ulong> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[64u](v128x64u,32i)
; vcell32i_g[64u](v128x64u,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa8,0x6e,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a8 6e 0b ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<long>(Vector128<long> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[64i](v128x64i,32i)
; vcell32i_g[64i](v128x64i,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x58,0x6e,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 58 6e 0b ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<float>(Vector128<float> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[32f](v128x32f,32i)
; vcell32i_g[32f](v128x32f,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x08,0x6e,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 08 6e 0b ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<double>(Vector128<double> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[64f](v128x64f,32i)
; vcell32i_g[64f](v128x64f,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb8,0x6d,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b8 6d 0b ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<byte>(Vector128<byte> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[8u](v128x8u,32i)
; vcell32_g[8u](v128x8u,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x68,0x6d,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 68 6d 0b ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<sbyte>(Vector128<sbyte> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[8i](v128x8i,32i)
; vcell32_g[8i](v128x8i,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x18,0x6d,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 18 6d 0b ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<ushort>(Vector128<ushort> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[16u](v128x16u,32i)
; vcell32_g[16u](v128x16u,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc8,0x6c,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c8 6c 0b ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<short>(Vector128<short> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[16i](v128x16i,32i)
; vcell32_g[16i](v128x16i,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x78,0x6c,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 78 6c 0b ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<uint>(Vector128<uint> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[32u](v128x32u,32i)
; vcell32_g[32u](v128x32u,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x28,0x6c,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 28 6c 0b ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<int>(Vector128<int> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[32i](v128x32i,32i)
; vcell32_g[32i](v128x32i,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd8,0x6b,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d8 6b 0b ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<ulong>(Vector128<ulong> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[64u](v128x64u,32i)
; vcell32_g[64u](v128x64u,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x88,0x6b,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 88 6b 0b ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<long>(Vector128<long> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[64i](v128x64i,32i)
; vcell32_g[64i](v128x64i,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x38,0x6b,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 38 6b 0b ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<float>(Vector128<float> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[32f](v128x32f,32i)
; vcell32_g[32f](v128x32f,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe8,0x6a,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e8 6a 0b ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<double>(Vector128<double> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[64f](v128x64f,32i)
; vcell32_g[64f](v128x64f,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x98,0x6a,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 98 6a 0b ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<byte>(Vector128<byte> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[8u](v128x8u,32i)
; vcell64i_g[8u](v128x8u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x47,0x6a,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 47 6a 0b ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<sbyte>(Vector128<sbyte> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[8i](v128x8i,32i)
; vcell64i_g[8i](v128x8i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf7,0x69,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f7 69 0b ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<ushort>(Vector128<ushort> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[16u](v128x16u,32i)
; vcell64i_g[16u](v128x16u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa7,0x69,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a7 69 0b ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<short>(Vector128<short> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[16i](v128x16i,32i)
; vcell64i_g[16i](v128x16i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x57,0x69,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 57 69 0b ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<uint>(Vector128<uint> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[32u](v128x32u,32i)
; vcell64i_g[32u](v128x32u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x07,0x69,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 07 69 0b ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<int>(Vector128<int> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[32i](v128x32i,32i)
; vcell64i_g[32i](v128x32i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb7,0x64,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b7 64 0b ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<ulong>(Vector128<ulong> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[64u](v128x64u,32i)
; vcell64i_g[64u](v128x64u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x67,0x64,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 67 64 0b ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<long>(Vector128<long> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[64i](v128x64i,32i)
; vcell64i_g[64i](v128x64i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x17,0x64,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 17 64 0b ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<float>(Vector128<float> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[32f](v128x32f,32i)
; vcell64i_g[32f](v128x32f,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc7,0x63,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c7 63 0b ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<double>(Vector128<double> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[64f](v128x64f,32i)
; vcell64i_g[64f](v128x64f,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x77,0x63,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 77 63 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<byte>(Vector128<byte> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[8u](v128x8u,32i)
; vcell64_g[8u](v128x8u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x27,0x63,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 27 63 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<sbyte>(Vector128<sbyte> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[8i](v128x8i,32i)
; vcell64_g[8i](v128x8i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd7,0x62,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d7 62 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<ushort>(Vector128<ushort> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[16u](v128x16u,32i)
; vcell64_g[16u](v128x16u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x87,0x62,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 87 62 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<short>(Vector128<short> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[16i](v128x16i,32i)
; vcell64_g[16i](v128x16i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x37,0x62,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 37 62 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<uint>(Vector128<uint> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[32u](v128x32u,32i)
; vcell64_g[32u](v128x32u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe7,0x61,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e7 61 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<int>(Vector128<int> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[32i](v128x32i,32i)
; vcell64_g[32i](v128x32i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x97,0x61,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 97 61 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<ulong>(Vector128<ulong> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[64u](v128x64u,32i)
; vcell64_g[64u](v128x64u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x47,0x61,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 47 61 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<long>(Vector128<long> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[64i](v128x64i,32i)
; vcell64_g[64i](v128x64i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf7,0x60,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f7 60 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<float>(Vector128<float> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[32f](v128x32f,32i)
; vcell64_g[32f](v128x32f,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa7,0x60,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a7 60 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<double>(Vector128<double> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[64f](v128x64f,32i)
; vcell64_g[64f](v128x64f,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x57,0x60,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 57 60 0b ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<byte>(Vector128<byte> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[8u](v128x8u,32i)
; vcell32f_g[8u](v128x8u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x06,0x60,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 06 60 0b ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<sbyte>(Vector128<sbyte> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[8i](v128x8i,32i)
; vcell32f_g[8i](v128x8i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb6,0x5f,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b6 5f 0b ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<ushort>(Vector128<ushort> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[16u](v128x16u,32i)
; vcell32f_g[16u](v128x16u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x66,0x5f,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 66 5f 0b ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<short>(Vector128<short> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[16i](v128x16i,32i)
; vcell32f_g[16i](v128x16i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x16,0x5f,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 16 5f 0b ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<uint>(Vector128<uint> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[32u](v128x32u,32i)
; vcell32f_g[32u](v128x32u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc6,0x5e,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c6 5e 0b ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<int>(Vector128<int> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[32i](v128x32i,32i)
; vcell32f_g[32i](v128x32i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x76,0x5e,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 76 5e 0b ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<ulong>(Vector128<ulong> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[64u](v128x64u,32i)
; vcell32f_g[64u](v128x64u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x26,0x5e,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 26 5e 0b ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<long>(Vector128<long> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[64i](v128x64i,32i)
; vcell32f_g[64i](v128x64i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd6,0x5d,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d6 5d 0b ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<float>(Vector128<float> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[32f](v128x32f,32i)
; vcell32f_g[32f](v128x32f,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x86,0x5d,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 86 5d 0b ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<double>(Vector128<double> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[64f](v128x64f,32i)
; vcell32f_g[64f](v128x64f,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x36,0x5d,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 36 5d 0b ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<byte>(Vector128<byte> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[8u](v128x8u,32i)
; vcell64f_g[8u](v128x8u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe6,0x5c,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e6 5c 0b ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<sbyte>(Vector128<sbyte> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[8i](v128x8i,32i)
; vcell64f_g[8i](v128x8i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x96,0x5c,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 96 5c 0b ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<ushort>(Vector128<ushort> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[16u](v128x16u,32i)
; vcell64f_g[16u](v128x16u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x46,0x5c,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 46 5c 0b ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<short>(Vector128<short> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[16i](v128x16i,32i)
; vcell64f_g[16i](v128x16i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf6,0x5b,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f6 5b 0b ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<uint>(Vector128<uint> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[32u](v128x32u,32i)
; vcell64f_g[32u](v128x32u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa6,0x5b,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a6 5b 0b ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<int>(Vector128<int> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[32i](v128x32i,32i)
; vcell64f_g[32i](v128x32i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x56,0x5b,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 56 5b 0b ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<ulong>(Vector128<ulong> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[64u](v128x64u,32i)
; vcell64f_g[64u](v128x64u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x06,0x5b,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 06 5b 0b ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<long>(Vector128<long> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[64i](v128x64i,32i)
; vcell64f_g[64i](v128x64i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb6,0x5a,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b6 5a 0b ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<float>(Vector128<float> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[32f](v128x32f,32i)
; vcell64f_g[32f](v128x32f,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x66,0x5a,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 66 5a 0b ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<double>(Vector128<double> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[64f](v128x64f,32i)
; vcell64f_g[64f](v128x64f,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x16,0x5a,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 16 5a 0b ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<byte>(Vector256<byte> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[8u](v256x8u,32i)
; vcell8i_g[8u](v256x8u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb3,0x55,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b3 55 0b ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<sbyte>(Vector256<sbyte> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[8i](v256x8i,32i)
; vcell8i_g[8i](v256x8i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x63,0x55,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 63 55 0b ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<ushort>(Vector256<ushort> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[16u](v256x16u,32i)
; vcell8i_g[16u](v256x16u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x13,0x55,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 13 55 0b ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<short>(Vector256<short> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[16i](v256x16i,32i)
; vcell8i_g[16i](v256x16i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc3,0x54,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c3 54 0b ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<uint>(Vector256<uint> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[32u](v256x32u,32i)
; vcell8i_g[32u](v256x32u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x73,0x54,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 73 54 0b ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<int>(Vector256<int> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[32i](v256x32i,32i)
; vcell8i_g[32i](v256x32i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x23,0x54,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 23 54 0b ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<ulong>(Vector256<ulong> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[64u](v256x64u,32i)
; vcell8i_g[64u](v256x64u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd3,0x53,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d3 53 0b ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<long>(Vector256<long> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[64i](v256x64i,32i)
; vcell8i_g[64i](v256x64i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x83,0x53,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 83 53 0b ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<float>(Vector256<float> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[32f](v256x32f,32i)
; vcell8i_g[32f](v256x32f,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x33,0x53,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 33 53 0b ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<double>(Vector256<double> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[64f](v256x64f,32i)
; vcell8i_g[64f](v256x64f,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe3,0x52,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e3 52 0b ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<byte>(Vector256<byte> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[8u](v256x8u,32i)
; vcell8_g[8u](v256x8u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x94,0x52,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 94 52 0b ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<sbyte>(Vector256<sbyte> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[8i](v256x8i,32i)
; vcell8_g[8i](v256x8i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x44,0x52,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 44 52 0b ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<ushort>(Vector256<ushort> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[16u](v256x16u,32i)
; vcell8_g[16u](v256x16u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf4,0x51,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f4 51 0b ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<short>(Vector256<short> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[16i](v256x16i,32i)
; vcell8_g[16i](v256x16i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa4,0x51,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a4 51 0b ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<uint>(Vector256<uint> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[32u](v256x32u,32i)
; vcell8_g[32u](v256x32u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x54,0x51,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 54 51 0b ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<int>(Vector256<int> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[32i](v256x32i,32i)
; vcell8_g[32i](v256x32i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x04,0x51,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 04 51 0b ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<ulong>(Vector256<ulong> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[64u](v256x64u,32i)
; vcell8_g[64u](v256x64u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb4,0x50,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b4 50 0b ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<long>(Vector256<long> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[64i](v256x64i,32i)
; vcell8_g[64i](v256x64i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x64,0x50,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 64 50 0b ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<float>(Vector256<float> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[32f](v256x32f,32i)
; vcell8_g[32f](v256x32f,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x14,0x50,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 14 50 0b ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<double>(Vector256<double> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[64f](v256x64f,32i)
; vcell8_g[64f](v256x64f,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc4,0x4f,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c4 4f 0b ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<byte>(Vector256<byte> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[8u](v256x8u,32i)
; vcell16i_g[8u](v256x8u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x73,0x4f,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 73 4f 0b ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<sbyte>(Vector256<sbyte> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[8i](v256x8i,32i)
; vcell16i_g[8i](v256x8i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x23,0x4f,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 23 4f 0b ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<ushort>(Vector256<ushort> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[16u](v256x16u,32i)
; vcell16i_g[16u](v256x16u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd3,0x4e,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d3 4e 0b ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<short>(Vector256<short> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[16i](v256x16i,32i)
; vcell16i_g[16i](v256x16i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x83,0x4e,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 83 4e 0b ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<uint>(Vector256<uint> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[32u](v256x32u,32i)
; vcell16i_g[32u](v256x32u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x33,0x4e,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 33 4e 0b ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<int>(Vector256<int> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[32i](v256x32i,32i)
; vcell16i_g[32i](v256x32i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe3,0x4d,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e3 4d 0b ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<ulong>(Vector256<ulong> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[64u](v256x64u,32i)
; vcell16i_g[64u](v256x64u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x93,0x4d,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 93 4d 0b ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<long>(Vector256<long> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[64i](v256x64i,32i)
; vcell16i_g[64i](v256x64i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x43,0x4d,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 43 4d 0b ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<float>(Vector256<float> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[32f](v256x32f,32i)
; vcell16i_g[32f](v256x32f,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf3,0x4c,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f3 4c 0b ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<double>(Vector256<double> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[64f](v256x64f,32i)
; vcell16i_g[64f](v256x64f,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa3,0x4c,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a3 4c 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<byte>(Vector256<byte> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[8u](v256x8u,32i)
; vcell16_g[8u](v256x8u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x54,0x4c,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 54 4c 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<sbyte>(Vector256<sbyte> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[8i](v256x8i,32i)
; vcell16_g[8i](v256x8i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x04,0x4c,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 04 4c 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<ushort>(Vector256<ushort> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[16u](v256x16u,32i)
; vcell16_g[16u](v256x16u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa4,0x47,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a4 47 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<short>(Vector256<short> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[16i](v256x16i,32i)
; vcell16_g[16i](v256x16i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x54,0x47,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 54 47 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<uint>(Vector256<uint> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[32u](v256x32u,32i)
; vcell16_g[32u](v256x32u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x04,0x47,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 04 47 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<int>(Vector256<int> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[32i](v256x32i,32i)
; vcell16_g[32i](v256x32i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb4,0x46,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b4 46 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<ulong>(Vector256<ulong> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[64u](v256x64u,32i)
; vcell16_g[64u](v256x64u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x64,0x46,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 64 46 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<long>(Vector256<long> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[64i](v256x64i,32i)
; vcell16_g[64i](v256x64i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x14,0x46,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 14 46 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<float>(Vector256<float> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[32f](v256x32f,32i)
; vcell16_g[32f](v256x32f,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc4,0x45,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c4 45 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<double>(Vector256<double> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[64f](v256x64f,32i)
; vcell16_g[64f](v256x64f,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x74,0x45,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 74 45 0b ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<byte>(Vector256<byte> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[8u](v256x8u,32i)
; vcell32i_g[8u](v256x8u,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x25,0x45,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 25 45 0b ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<sbyte>(Vector256<sbyte> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[8i](v256x8i,32i)
; vcell32i_g[8i](v256x8i,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd5,0x44,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d5 44 0b ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<ushort>(Vector256<ushort> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[16u](v256x16u,32i)
; vcell32i_g[16u](v256x16u,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x85,0x44,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 85 44 0b ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<short>(Vector256<short> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[16i](v256x16i,32i)
; vcell32i_g[16i](v256x16i,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x35,0x44,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 35 44 0b ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<uint>(Vector256<uint> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[32u](v256x32u,32i)
; vcell32i_g[32u](v256x32u,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe5,0x43,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e5 43 0b ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<int>(Vector256<int> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[32i](v256x32i,32i)
; vcell32i_g[32i](v256x32i,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x95,0x43,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 95 43 0b ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<ulong>(Vector256<ulong> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[64u](v256x64u,32i)
; vcell32i_g[64u](v256x64u,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x45,0x43,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 45 43 0b ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<long>(Vector256<long> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[64i](v256x64i,32i)
; vcell32i_g[64i](v256x64i,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf5,0x42,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f5 42 0b ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<float>(Vector256<float> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[32f](v256x32f,32i)
; vcell32i_g[32f](v256x32f,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa5,0x42,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a5 42 0b ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<double>(Vector256<double> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[64f](v256x64f,32i)
; vcell32i_g[64f](v256x64f,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x55,0x42,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 55 42 0b ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<byte>(Vector256<byte> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[8u](v256x8u,32i)
; vcell32_g[8u](v256x8u,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x05,0x42,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 05 42 0b ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<sbyte>(Vector256<sbyte> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[8i](v256x8i,32i)
; vcell32_g[8i](v256x8i,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb5,0x41,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b5 41 0b ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<ushort>(Vector256<ushort> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[16u](v256x16u,32i)
; vcell32_g[16u](v256x16u,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x65,0x41,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 65 41 0b ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<short>(Vector256<short> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[16i](v256x16i,32i)
; vcell32_g[16i](v256x16i,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x15,0x41,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 15 41 0b ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<uint>(Vector256<uint> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[32u](v256x32u,32i)
; vcell32_g[32u](v256x32u,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc5,0x40,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c5 40 0b ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<int>(Vector256<int> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[32i](v256x32i,32i)
; vcell32_g[32i](v256x32i,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x75,0x40,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 75 40 0b ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<ulong>(Vector256<ulong> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[64u](v256x64u,32i)
; vcell32_g[64u](v256x64u,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x25,0x40,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 25 40 0b ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<long>(Vector256<long> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[64i](v256x64i,32i)
; vcell32_g[64i](v256x64i,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd5,0x3f,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d5 3f 0b ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<float>(Vector256<float> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[32f](v256x32f,32i)
; vcell32_g[32f](v256x32f,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x85,0x3f,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 85 3f 0b ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<double>(Vector256<double> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[64f](v256x64f,32i)
; vcell32_g[64f](v256x64f,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x35,0x3f,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 35 3f 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<byte>(Vector256<byte> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[8u](v256x8u,32i)
; vcell64_g[8u](v256x8u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe4,0x3e,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e4 3e 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<sbyte>(Vector256<sbyte> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[8i](v256x8i,32i)
; vcell64_g[8i](v256x8i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x94,0x3e,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 94 3e 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<ushort>(Vector256<ushort> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[16u](v256x16u,32i)
; vcell64_g[16u](v256x16u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x44,0x3e,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 44 3e 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<short>(Vector256<short> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[16i](v256x16i,32i)
; vcell64_g[16i](v256x16i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf4,0x3d,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f4 3d 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<uint>(Vector256<uint> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[32u](v256x32u,32i)
; vcell64_g[32u](v256x32u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa4,0x3d,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a4 3d 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<int>(Vector256<int> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[32i](v256x32i,32i)
; vcell64_g[32i](v256x32i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x54,0x3d,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 54 3d 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<ulong>(Vector256<ulong> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[64u](v256x64u,32i)
; vcell64_g[64u](v256x64u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x04,0x3d,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 04 3d 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<long>(Vector256<long> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[64i](v256x64i,32i)
; vcell64_g[64i](v256x64i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb4,0x3c,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b4 3c 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<float>(Vector256<float> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[32f](v256x32f,32i)
; vcell64_g[32f](v256x32f,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x64,0x3c,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 64 3c 0b ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<double>(Vector256<double> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[64f](v256x64f,32i)
; vcell64_g[64f](v256x64f,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x04,0x38,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 04 38 0b ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<byte>(Vector256<byte> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[8u](v256x8u,32i)
; vcell64i_g[8u](v256x8u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb4,0x37,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b4 37 0b ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<sbyte>(Vector256<sbyte> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[8i](v256x8i,32i)
; vcell64i_g[8i](v256x8i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x64,0x37,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 64 37 0b ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<ushort>(Vector256<ushort> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[16u](v256x16u,32i)
; vcell64i_g[16u](v256x16u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x14,0x37,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 14 37 0b ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<short>(Vector256<short> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[16i](v256x16i,32i)
; vcell64i_g[16i](v256x16i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc4,0x36,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c4 36 0b ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<uint>(Vector256<uint> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[32u](v256x32u,32i)
; vcell64i_g[32u](v256x32u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x74,0x36,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 74 36 0b ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<int>(Vector256<int> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[32i](v256x32i,32i)
; vcell64i_g[32i](v256x32i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x24,0x36,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 24 36 0b ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<ulong>(Vector256<ulong> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[64u](v256x64u,32i)
; vcell64i_g[64u](v256x64u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd4,0x35,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d4 35 0b ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<long>(Vector256<long> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[64i](v256x64i,32i)
; vcell64i_g[64i](v256x64i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x84,0x35,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 84 35 0b ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<float>(Vector256<float> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[32f](v256x32f,32i)
; vcell64i_g[32f](v256x32f,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x34,0x35,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 34 35 0b ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<double>(Vector256<double> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[64f](v256x64f,32i)
; vcell64i_g[64f](v256x64f,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe4,0x34,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e4 34 0b ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<byte>(Vector256<byte> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[8u](v256x8u,32i)
; vcell32f_g[8u](v256x8u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x93,0x34,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 93 34 0b ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<sbyte>(Vector256<sbyte> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[8i](v256x8i,32i)
; vcell32f_g[8i](v256x8i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x43,0x34,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 43 34 0b ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<ushort>(Vector256<ushort> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[16u](v256x16u,32i)
; vcell32f_g[16u](v256x16u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf3,0x33,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f3 33 0b ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<short>(Vector256<short> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[16i](v256x16i,32i)
; vcell32f_g[16i](v256x16i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa3,0x33,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a3 33 0b ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<uint>(Vector256<uint> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[32u](v256x32u,32i)
; vcell32f_g[32u](v256x32u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x53,0x33,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 53 33 0b ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<int>(Vector256<int> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[32i](v256x32i,32i)
; vcell32f_g[32i](v256x32i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x03,0x33,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 03 33 0b ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<ulong>(Vector256<ulong> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[64u](v256x64u,32i)
; vcell32f_g[64u](v256x64u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb3,0x32,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b3 32 0b ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<long>(Vector256<long> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[64i](v256x64i,32i)
; vcell32f_g[64i](v256x64i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x63,0x32,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 63 32 0b ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<float>(Vector256<float> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[32f](v256x32f,32i)
; vcell32f_g[32f](v256x32f,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x13,0x32,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 13 32 0b ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<double>(Vector256<double> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[64f](v256x64f,32i)
; vcell32f_g[64f](v256x64f,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc3,0x31,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c3 31 0b ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<byte>(Vector256<byte> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[8u](v256x8u,32i)
; vcell64f_g[8u](v256x8u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x73,0x31,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 73 31 0b ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<sbyte>(Vector256<sbyte> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[8i](v256x8i,32i)
; vcell64f_g[8i](v256x8i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x23,0x31,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 23 31 0b ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<ushort>(Vector256<ushort> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[16u](v256x16u,32i)
; vcell64f_g[16u](v256x16u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd3,0x30,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d3 30 0b ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<short>(Vector256<short> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[16i](v256x16i,32i)
; vcell64f_g[16i](v256x16i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x83,0x30,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 83 30 0b ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<uint>(Vector256<uint> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[32u](v256x32u,32i)
; vcell64f_g[32u](v256x32u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x33,0x30,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 33 30 0b ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<int>(Vector256<int> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[32i](v256x32i,32i)
; vcell64f_g[32i](v256x32i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe3,0x2f,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e3 2f 0b ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<ulong>(Vector256<ulong> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[64u](v256x64u,32i)
; vcell64f_g[64u](v256x64u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x93,0x2f,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 93 2f 0b ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<long>(Vector256<long> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[64i](v256x64i,32i)
; vcell64f_g[64i](v256x64i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x43,0x2f,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 43 2f 0b ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<float>(Vector256<float> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[32f](v256x32f,32i)
; vcell64f_g[32f](v256x32f,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf3,0x2e,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f3 2e 0b ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<double>(Vector256<double> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[64f](v256x64f,32i)
; vcell64f_g[64f](v256x64f,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa3,0x2e,0x0b,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7754ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a3 2e 0b ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> v8i<byte>(Vector128<byte> x), hex://vfuncs/generic?v8i#v8i_g[8u](v128x8u)
; v8i_g[8u](v128x8u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> v8i<sbyte>(Vector128<sbyte> x), hex://vfuncs/generic?v8i#v8i_g[8i](v128x8i)
; v8i_g[8i](v128x8i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> v8i<ushort>(Vector128<ushort> x), hex://vfuncs/generic?v8i#v8i_g[16u](v128x16u)
; v8i_g[16u](v128x16u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> v8i<short>(Vector128<short> x), hex://vfuncs/generic?v8i#v8i_g[16i](v128x16i)
; v8i_g[16i](v128x16i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> v8i<uint>(Vector128<uint> x), hex://vfuncs/generic?v8i#v8i_g[32u](v128x32u)
; v8i_g[32u](v128x32u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> v8i<int>(Vector128<int> x), hex://vfuncs/generic?v8i#v8i_g[32i](v128x32i)
; v8i_g[32i](v128x32i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> v8i<ulong>(Vector128<ulong> x), hex://vfuncs/generic?v8i#v8i_g[64u](v128x64u)
; v8i_g[64u](v128x64u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> v8i<long>(Vector128<long> x), hex://vfuncs/generic?v8i#v8i_g[64i](v128x64i)
; v8i_g[64i](v128x64i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> v8i<float>(Vector128<float> x), hex://vfuncs/generic?v8i#v8i_g[32f](v128x32f)
; v8i_g[32f](v128x32f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> v8i<double>(Vector128<double> x), hex://vfuncs/generic?v8i#v8i_g[64f](v128x64f)
; v8i_g[64f](v128x64f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}

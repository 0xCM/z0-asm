------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> v8u<byte>(Vector128<byte> x), hex://vfuncs/generic?v8u#v8u_g[8u](v128x8u)
; v8u_g[8u](v128x8u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> v8u<sbyte>(Vector128<sbyte> x), hex://vfuncs/generic?v8u#v8u_g[8i](v128x8i)
; v8u_g[8i](v128x8i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> v8u<ushort>(Vector128<ushort> x), hex://vfuncs/generic?v8u#v8u_g[16u](v128x16u)
; v8u_g[16u](v128x16u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> v8u<short>(Vector128<short> x), hex://vfuncs/generic?v8u#v8u_g[16i](v128x16i)
; v8u_g[16i](v128x16i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> v8u<uint>(Vector128<uint> x), hex://vfuncs/generic?v8u#v8u_g[32u](v128x32u)
; v8u_g[32u](v128x32u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> v8u<int>(Vector128<int> x), hex://vfuncs/generic?v8u#v8u_g[32i](v128x32i)
; v8u_g[32i](v128x32i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> v8u<ulong>(Vector128<ulong> x), hex://vfuncs/generic?v8u#v8u_g[64u](v128x64u)
; v8u_g[64u](v128x64u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> v8u<long>(Vector128<long> x), hex://vfuncs/generic?v8u#v8u_g[64i](v128x64i)
; v8u_g[64i](v128x64i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> v8u<float>(Vector128<float> x), hex://vfuncs/generic?v8u#v8u_g[32f](v128x32f)
; v8u_g[32f](v128x32f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> v8u<double>(Vector128<double> x), hex://vfuncs/generic?v8u#v8u_g[64f](v128x64f)
; v8u_g[64f](v128x64f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> v16i<byte>(Vector128<byte> x), hex://vfuncs/generic?v16i#v16i_g[8u](v128x8u)
; v16i_g[8u](v128x8u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> v16i<sbyte>(Vector128<sbyte> x), hex://vfuncs/generic?v16i#v16i_g[8i](v128x8i)
; v16i_g[8i](v128x8i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> v16i<ushort>(Vector128<ushort> x), hex://vfuncs/generic?v16i#v16i_g[16u](v128x16u)
; v16i_g[16u](v128x16u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> v16i<short>(Vector128<short> x), hex://vfuncs/generic?v16i#v16i_g[16i](v128x16i)
; v16i_g[16i](v128x16i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> v16i<uint>(Vector128<uint> x), hex://vfuncs/generic?v16i#v16i_g[32u](v128x32u)
; v16i_g[32u](v128x32u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> v16i<int>(Vector128<int> x), hex://vfuncs/generic?v16i#v16i_g[32i](v128x32i)
; v16i_g[32i](v128x32i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> v16i<ulong>(Vector128<ulong> x), hex://vfuncs/generic?v16i#v16i_g[64u](v128x64u)
; v16i_g[64u](v128x64u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> v16i<long>(Vector128<long> x), hex://vfuncs/generic?v16i#v16i_g[64i](v128x64i)
; v16i_g[64i](v128x64i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> v16i<float>(Vector128<float> x), hex://vfuncs/generic?v16i#v16i_g[32f](v128x32f)
; v16i_g[32f](v128x32f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> v16i<double>(Vector128<double> x), hex://vfuncs/generic?v16i#v16i_g[64f](v128x64f)
; v16i_g[64f](v128x64f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> v16u<byte>(Vector128<byte> x), hex://vfuncs/generic?v16u#v16u_g[8u](v128x8u)
; v16u_g[8u](v128x8u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> v16u<sbyte>(Vector128<sbyte> x), hex://vfuncs/generic?v16u#v16u_g[8i](v128x8i)
; v16u_g[8i](v128x8i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> v16u<ushort>(Vector128<ushort> x), hex://vfuncs/generic?v16u#v16u_g[16u](v128x16u)
; v16u_g[16u](v128x16u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> v16u<short>(Vector128<short> x), hex://vfuncs/generic?v16u#v16u_g[16i](v128x16i)
; v16u_g[16i](v128x16i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> v16u<uint>(Vector128<uint> x), hex://vfuncs/generic?v16u#v16u_g[32u](v128x32u)
; v16u_g[32u](v128x32u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> v16u<int>(Vector128<int> x), hex://vfuncs/generic?v16u#v16u_g[32i](v128x32i)
; v16u_g[32i](v128x32i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> v16u<ulong>(Vector128<ulong> x), hex://vfuncs/generic?v16u#v16u_g[64u](v128x64u)
; v16u_g[64u](v128x64u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> v16u<long>(Vector128<long> x), hex://vfuncs/generic?v16u#v16u_g[64i](v128x64i)
; v16u_g[64i](v128x64i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> v16u<float>(Vector128<float> x), hex://vfuncs/generic?v16u#v16u_g[32f](v128x32f)
; v16u_g[32f](v128x32f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> v16u<double>(Vector128<double> x), hex://vfuncs/generic?v16u#v16u_g[64f](v128x64f)
; v16u_g[64f](v128x64f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> v32i<byte>(Vector128<byte> x), hex://vfuncs/generic?v32i#v32i_g[8u](v128x8u)
; v32i_g[8u](v128x8u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> v32i<sbyte>(Vector128<sbyte> x), hex://vfuncs/generic?v32i#v32i_g[8i](v128x8i)
; v32i_g[8i](v128x8i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> v32i<ushort>(Vector128<ushort> x), hex://vfuncs/generic?v32i#v32i_g[16u](v128x16u)
; v32i_g[16u](v128x16u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> v32i<short>(Vector128<short> x), hex://vfuncs/generic?v32i#v32i_g[16i](v128x16i)
; v32i_g[16i](v128x16i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> v32i<uint>(Vector128<uint> x), hex://vfuncs/generic?v32i#v32i_g[32u](v128x32u)
; v32i_g[32u](v128x32u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> v32i<int>(Vector128<int> x), hex://vfuncs/generic?v32i#v32i_g[32i](v128x32i)
; v32i_g[32i](v128x32i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> v32i<ulong>(Vector128<ulong> x), hex://vfuncs/generic?v32i#v32i_g[64u](v128x64u)
; v32i_g[64u](v128x64u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> v32i<long>(Vector128<long> x), hex://vfuncs/generic?v32i#v32i_g[64i](v128x64i)
; v32i_g[64i](v128x64i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> v32i<float>(Vector128<float> x), hex://vfuncs/generic?v32i#v32i_g[32f](v128x32f)
; v32i_g[32f](v128x32f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> v32i<double>(Vector128<double> x), hex://vfuncs/generic?v32i#v32i_g[64f](v128x64f)
; v32i_g[64f](v128x64f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> v32u<byte>(Vector128<byte> x), hex://vfuncs/generic?v32u#v32u_g[8u](v128x8u)
; v32u_g[8u](v128x8u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> v32u<sbyte>(Vector128<sbyte> x), hex://vfuncs/generic?v32u#v32u_g[8i](v128x8i)
; v32u_g[8i](v128x8i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> v32u<ushort>(Vector128<ushort> x), hex://vfuncs/generic?v32u#v32u_g[16u](v128x16u)
; v32u_g[16u](v128x16u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> v32u<short>(Vector128<short> x), hex://vfuncs/generic?v32u#v32u_g[16i](v128x16i)
; v32u_g[16i](v128x16i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> v32u<uint>(Vector128<uint> x), hex://vfuncs/generic?v32u#v32u_g[32u](v128x32u)
; v32u_g[32u](v128x32u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> v32u<int>(Vector128<int> x), hex://vfuncs/generic?v32u#v32u_g[32i](v128x32i)
; v32u_g[32i](v128x32i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> v32u<ulong>(Vector128<ulong> x), hex://vfuncs/generic?v32u#v32u_g[64u](v128x64u)
; v32u_g[64u](v128x64u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> v32u<long>(Vector128<long> x), hex://vfuncs/generic?v32u#v32u_g[64i](v128x64i)
; v32u_g[64i](v128x64i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> v32u<float>(Vector128<float> x), hex://vfuncs/generic?v32u#v32u_g[32f](v128x32f)
; v32u_g[32f](v128x32f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> v32u<double>(Vector128<double> x), hex://vfuncs/generic?v32u#v32u_g[64f](v128x64f)
; v32u_g[64f](v128x64f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> v64i<byte>(Vector128<byte> x), hex://vfuncs/generic?v64i#v64i_g[8u](v128x8u)
; v64i_g[8u](v128x8u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> v64i<sbyte>(Vector128<sbyte> x), hex://vfuncs/generic?v64i#v64i_g[8i](v128x8i)
; v64i_g[8i](v128x8i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> v64i<ushort>(Vector128<ushort> x), hex://vfuncs/generic?v64i#v64i_g[16u](v128x16u)
; v64i_g[16u](v128x16u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> v64i<short>(Vector128<short> x), hex://vfuncs/generic?v64i#v64i_g[16i](v128x16i)
; v64i_g[16i](v128x16i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> v64i<uint>(Vector128<uint> x), hex://vfuncs/generic?v64i#v64i_g[32u](v128x32u)
; v64i_g[32u](v128x32u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> v64i<int>(Vector128<int> x), hex://vfuncs/generic?v64i#v64i_g[32i](v128x32i)
; v64i_g[32i](v128x32i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> v64i<ulong>(Vector128<ulong> x), hex://vfuncs/generic?v64i#v64i_g[64u](v128x64u)
; v64i_g[64u](v128x64u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> v64i<long>(Vector128<long> x), hex://vfuncs/generic?v64i#v64i_g[64i](v128x64i)
; v64i_g[64i](v128x64i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> v64i<float>(Vector128<float> x), hex://vfuncs/generic?v64i#v64i_g[32f](v128x32f)
; v64i_g[32f](v128x32f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> v64i<double>(Vector128<double> x), hex://vfuncs/generic?v64i#v64i_g[64f](v128x64f)
; v64i_g[64f](v128x64f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> v64u<byte>(Vector128<byte> x), hex://vfuncs/generic?v64u#v64u_g[8u](v128x8u)
; v64u_g[8u](v128x8u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> v64u<sbyte>(Vector128<sbyte> x), hex://vfuncs/generic?v64u#v64u_g[8i](v128x8i)
; v64u_g[8i](v128x8i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> v64u<ushort>(Vector128<ushort> x), hex://vfuncs/generic?v64u#v64u_g[16u](v128x16u)
; v64u_g[16u](v128x16u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> v64u<short>(Vector128<short> x), hex://vfuncs/generic?v64u#v64u_g[16i](v128x16i)
; v64u_g[16i](v128x16i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> v64u<uint>(Vector128<uint> x), hex://vfuncs/generic?v64u#v64u_g[32u](v128x32u)
; v64u_g[32u](v128x32u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> v64u<int>(Vector128<int> x), hex://vfuncs/generic?v64u#v64u_g[32i](v128x32i)
; v64u_g[32i](v128x32i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> v64u<ulong>(Vector128<ulong> x), hex://vfuncs/generic?v64u#v64u_g[64u](v128x64u)
; v64u_g[64u](v128x64u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> v64u<long>(Vector128<long> x), hex://vfuncs/generic?v64u#v64u_g[64i](v128x64i)
; v64u_g[64i](v128x64i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> v64u<float>(Vector128<float> x), hex://vfuncs/generic?v64u#v64u_g[32f](v128x32f)
; v64u_g[32f](v128x32f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> v64u<double>(Vector128<double> x), hex://vfuncs/generic?v64u#v64u_g[64f](v128x64f)
; v64u_g[64f](v128x64f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> v32f<byte>(Vector128<byte> x), hex://vfuncs/generic?v32f#v32f_g[8u](v128x8u)
; v32f_g[8u](v128x8u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> v32f<sbyte>(Vector128<sbyte> x), hex://vfuncs/generic?v32f#v32f_g[8i](v128x8i)
; v32f_g[8i](v128x8i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> v32f<ushort>(Vector128<ushort> x), hex://vfuncs/generic?v32f#v32f_g[16u](v128x16u)
; v32f_g[16u](v128x16u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> v32f<short>(Vector128<short> x), hex://vfuncs/generic?v32f#v32f_g[16i](v128x16i)
; v32f_g[16i](v128x16i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> v32f<uint>(Vector128<uint> x), hex://vfuncs/generic?v32f#v32f_g[32u](v128x32u)
; v32f_g[32u](v128x32u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> v32f<int>(Vector128<int> x), hex://vfuncs/generic?v32f#v32f_g[32i](v128x32i)
; v32f_g[32i](v128x32i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> v32f<ulong>(Vector128<ulong> x), hex://vfuncs/generic?v32f#v32f_g[64u](v128x64u)
; v32f_g[64u](v128x64u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> v32f<long>(Vector128<long> x), hex://vfuncs/generic?v32f#v32f_g[64i](v128x64i)
; v32f_g[64i](v128x64i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> v32f<float>(Vector128<float> x), hex://vfuncs/generic?v32f#v32f_g[32f](v128x32f)
; v32f_g[32f](v128x32f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> v32f<double>(Vector128<double> x), hex://vfuncs/generic?v32f#v32f_g[64f](v128x64f)
; v32f_g[64f](v128x64f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> v64f<byte>(Vector128<byte> x), hex://vfuncs/generic?v64f#v64f_g[8u](v128x8u)
; v64f_g[8u](v128x8u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> v64f<sbyte>(Vector128<sbyte> x), hex://vfuncs/generic?v64f#v64f_g[8i](v128x8i)
; v64f_g[8i](v128x8i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> v64f<ushort>(Vector128<ushort> x), hex://vfuncs/generic?v64f#v64f_g[16u](v128x16u)
; v64f_g[16u](v128x16u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> v64f<short>(Vector128<short> x), hex://vfuncs/generic?v64f#v64f_g[16i](v128x16i)
; v64f_g[16i](v128x16i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> v64f<uint>(Vector128<uint> x), hex://vfuncs/generic?v64f#v64f_g[32u](v128x32u)
; v64f_g[32u](v128x32u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> v64f<int>(Vector128<int> x), hex://vfuncs/generic?v64f#v64f_g[32i](v128x32i)
; v64f_g[32i](v128x32i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> v64f<ulong>(Vector128<ulong> x), hex://vfuncs/generic?v64f#v64f_g[64u](v128x64u)
; v64f_g[64u](v128x64u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> v64f<long>(Vector128<long> x), hex://vfuncs/generic?v64f#v64f_g[64i](v128x64i)
; v64f_g[64i](v128x64i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> v64f<float>(Vector128<float> x), hex://vfuncs/generic?v64f#v64f_g[32f](v128x32f)
; v64f_g[32f](v128x32f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> v64f<double>(Vector128<double> x), hex://vfuncs/generic?v64f#v64f_g[64f](v128x64f)
; v64f_g[64f](v128x64f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<sbyte> v8i<byte>(Vector256<byte> x), hex://vfuncs/generic?v8i#v8i_g[8u](v256x8u)
; v8i_g[8u](v256x8u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<sbyte> v8i<sbyte>(Vector256<sbyte> x), hex://vfuncs/generic?v8i#v8i_g[8i](v256x8i)
; v8i_g[8i](v256x8i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<sbyte> v8i<ushort>(Vector256<ushort> x), hex://vfuncs/generic?v8i#v8i_g[16u](v256x16u)
; v8i_g[16u](v256x16u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<sbyte> v8i<short>(Vector256<short> x), hex://vfuncs/generic?v8i#v8i_g[16i](v256x16i)
; v8i_g[16i](v256x16i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<sbyte> v8i<uint>(Vector256<uint> x), hex://vfuncs/generic?v8i#v8i_g[32u](v256x32u)
; v8i_g[32u](v256x32u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<sbyte> v8i<int>(Vector256<int> x), hex://vfuncs/generic?v8i#v8i_g[32i](v256x32i)
; v8i_g[32i](v256x32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<sbyte> v8i<ulong>(Vector256<ulong> x), hex://vfuncs/generic?v8i#v8i_g[64u](v256x64u)
; v8i_g[64u](v256x64u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<sbyte> v8i<long>(Vector256<long> x), hex://vfuncs/generic?v8i#v8i_g[64i](v256x64i)
; v8i_g[64i](v256x64i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<sbyte> v8i<float>(Vector256<float> x), hex://vfuncs/generic?v8i#v8i_g[32f](v256x32f)
; v8i_g[32f](v256x32f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<sbyte> v8i<double>(Vector256<double> x), hex://vfuncs/generic?v8i#v8i_g[64f](v256x64f)
; v8i_g[64f](v256x64f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<byte> v8u<byte>(Vector256<byte> x), hex://vfuncs/generic?v8u#v8u_g[8u](v256x8u)
; v8u_g[8u](v256x8u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<byte> v8u<sbyte>(Vector256<sbyte> x), hex://vfuncs/generic?v8u#v8u_g[8i](v256x8i)
; v8u_g[8i](v256x8i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<byte> v8u<ushort>(Vector256<ushort> x), hex://vfuncs/generic?v8u#v8u_g[16u](v256x16u)
; v8u_g[16u](v256x16u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<byte> v8u<short>(Vector256<short> x), hex://vfuncs/generic?v8u#v8u_g[16i](v256x16i)
; v8u_g[16i](v256x16i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<byte> v8u<uint>(Vector256<uint> x), hex://vfuncs/generic?v8u#v8u_g[32u](v256x32u)
; v8u_g[32u](v256x32u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<byte> v8u<int>(Vector256<int> x), hex://vfuncs/generic?v8u#v8u_g[32i](v256x32i)
; v8u_g[32i](v256x32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<byte> v8u<ulong>(Vector256<ulong> x), hex://vfuncs/generic?v8u#v8u_g[64u](v256x64u)
; v8u_g[64u](v256x64u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<byte> v8u<long>(Vector256<long> x), hex://vfuncs/generic?v8u#v8u_g[64i](v256x64i)
; v8u_g[64i](v256x64i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<byte> v8u<float>(Vector256<float> x), hex://vfuncs/generic?v8u#v8u_g[32f](v256x32f)
; v8u_g[32f](v256x32f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<byte> v8u<double>(Vector256<double> x), hex://vfuncs/generic?v8u#v8u_g[64f](v256x64f)
; v8u_g[64f](v256x64f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<short> v16i<byte>(Vector256<byte> x), hex://vfuncs/generic?v16i#v16i_g[8u](v256x8u)
; v16i_g[8u](v256x8u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<short> v16i<sbyte>(Vector256<sbyte> x), hex://vfuncs/generic?v16i#v16i_g[8i](v256x8i)
; v16i_g[8i](v256x8i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<short> v16i<ushort>(Vector256<ushort> x), hex://vfuncs/generic?v16i#v16i_g[16u](v256x16u)
; v16i_g[16u](v256x16u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<short> v16i<short>(Vector256<short> x), hex://vfuncs/generic?v16i#v16i_g[16i](v256x16i)
; v16i_g[16i](v256x16i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<short> v16i<uint>(Vector256<uint> x), hex://vfuncs/generic?v16i#v16i_g[32u](v256x32u)
; v16i_g[32u](v256x32u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<short> v16i<int>(Vector256<int> x), hex://vfuncs/generic?v16i#v16i_g[32i](v256x32i)
; v16i_g[32i](v256x32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<short> v16i<ulong>(Vector256<ulong> x), hex://vfuncs/generic?v16i#v16i_g[64u](v256x64u)
; v16i_g[64u](v256x64u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<short> v16i<long>(Vector256<long> x), hex://vfuncs/generic?v16i#v16i_g[64i](v256x64i)
; v16i_g[64i](v256x64i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<short> v16i<float>(Vector256<float> x), hex://vfuncs/generic?v16i#v16i_g[32f](v256x32f)
; v16i_g[32f](v256x32f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<short> v16i<double>(Vector256<double> x), hex://vfuncs/generic?v16i#v16i_g[64f](v256x64f)
; v16i_g[64f](v256x64f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ushort> v16u<byte>(Vector256<byte> x), hex://vfuncs/generic?v16u#v16u_g[8u](v256x8u)
; v16u_g[8u](v256x8u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ushort> v16u<sbyte>(Vector256<sbyte> x), hex://vfuncs/generic?v16u#v16u_g[8i](v256x8i)
; v16u_g[8i](v256x8i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ushort> v16u<ushort>(Vector256<ushort> x), hex://vfuncs/generic?v16u#v16u_g[16u](v256x16u)
; v16u_g[16u](v256x16u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ushort> v16u<short>(Vector256<short> x), hex://vfuncs/generic?v16u#v16u_g[16i](v256x16i)
; v16u_g[16i](v256x16i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ushort> v16u<uint>(Vector256<uint> x), hex://vfuncs/generic?v16u#v16u_g[32u](v256x32u)
; v16u_g[32u](v256x32u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ushort> v16u<int>(Vector256<int> x), hex://vfuncs/generic?v16u#v16u_g[32i](v256x32i)
; v16u_g[32i](v256x32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ushort> v16u<ulong>(Vector256<ulong> x), hex://vfuncs/generic?v16u#v16u_g[64u](v256x64u)
; v16u_g[64u](v256x64u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ushort> v16u<long>(Vector256<long> x), hex://vfuncs/generic?v16u#v16u_g[64i](v256x64i)
; v16u_g[64i](v256x64i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ushort> v16u<float>(Vector256<float> x), hex://vfuncs/generic?v16u#v16u_g[32f](v256x32f)
; v16u_g[32f](v256x32f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ushort> v16u<double>(Vector256<double> x), hex://vfuncs/generic?v16u#v16u_g[64f](v256x64f)
; v16u_g[64f](v256x64f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<int> v32i<byte>(Vector256<byte> x), hex://vfuncs/generic?v32i#v32i_g[8u](v256x8u)
; v32i_g[8u](v256x8u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<int> v32i<sbyte>(Vector256<sbyte> x), hex://vfuncs/generic?v32i#v32i_g[8i](v256x8i)
; v32i_g[8i](v256x8i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<int> v32i<ushort>(Vector256<ushort> x), hex://vfuncs/generic?v32i#v32i_g[16u](v256x16u)
; v32i_g[16u](v256x16u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<int> v32i<short>(Vector256<short> x), hex://vfuncs/generic?v32i#v32i_g[16i](v256x16i)
; v32i_g[16i](v256x16i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<int> v32i<uint>(Vector256<uint> x), hex://vfuncs/generic?v32i#v32i_g[32u](v256x32u)
; v32i_g[32u](v256x32u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<int> v32i<int>(Vector256<int> x), hex://vfuncs/generic?v32i#v32i_g[32i](v256x32i)
; v32i_g[32i](v256x32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<int> v32i<ulong>(Vector256<ulong> x), hex://vfuncs/generic?v32i#v32i_g[64u](v256x64u)
; v32i_g[64u](v256x64u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<int> v32i<long>(Vector256<long> x), hex://vfuncs/generic?v32i#v32i_g[64i](v256x64i)
; v32i_g[64i](v256x64i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<int> v32i<float>(Vector256<float> x), hex://vfuncs/generic?v32i#v32i_g[32f](v256x32f)
; v32i_g[32f](v256x32f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<int> v32i<double>(Vector256<double> x), hex://vfuncs/generic?v32i#v32i_g[64f](v256x64f)
; v32i_g[64f](v256x64f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<uint> v32u<byte>(Vector256<byte> x), hex://vfuncs/generic?v32u#v32u_g[8u](v256x8u)
; v32u_g[8u](v256x8u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<uint> v32u<sbyte>(Vector256<sbyte> x), hex://vfuncs/generic?v32u#v32u_g[8i](v256x8i)
; v32u_g[8i](v256x8i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<uint> v32u<ushort>(Vector256<ushort> x), hex://vfuncs/generic?v32u#v32u_g[16u](v256x16u)
; v32u_g[16u](v256x16u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<uint> v32u<short>(Vector256<short> x), hex://vfuncs/generic?v32u#v32u_g[16i](v256x16i)
; v32u_g[16i](v256x16i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<uint> v32u<uint>(Vector256<uint> x), hex://vfuncs/generic?v32u#v32u_g[32u](v256x32u)
; v32u_g[32u](v256x32u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<uint> v32u<int>(Vector256<int> x), hex://vfuncs/generic?v32u#v32u_g[32i](v256x32i)
; v32u_g[32i](v256x32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<uint> v32u<ulong>(Vector256<ulong> x), hex://vfuncs/generic?v32u#v32u_g[64u](v256x64u)
; v32u_g[64u](v256x64u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<uint> v32u<long>(Vector256<long> x), hex://vfuncs/generic?v32u#v32u_g[64i](v256x64i)
; v32u_g[64i](v256x64i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<uint> v32u<float>(Vector256<float> x), hex://vfuncs/generic?v32u#v32u_g[32f](v256x32f)
; v32u_g[32f](v256x32f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<uint> v32u<double>(Vector256<double> x), hex://vfuncs/generic?v32u#v32u_g[64f](v256x64f)
; v32u_g[64f](v256x64f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<long> v64i<byte>(Vector256<byte> x), hex://vfuncs/generic?v64i#v64i_g[8u](v256x8u)
; v64i_g[8u](v256x8u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<long> v64i<sbyte>(Vector256<sbyte> x), hex://vfuncs/generic?v64i#v64i_g[8i](v256x8i)
; v64i_g[8i](v256x8i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<long> v64i<ushort>(Vector256<ushort> x), hex://vfuncs/generic?v64i#v64i_g[16u](v256x16u)
; v64i_g[16u](v256x16u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<long> v64i<short>(Vector256<short> x), hex://vfuncs/generic?v64i#v64i_g[16i](v256x16i)
; v64i_g[16i](v256x16i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<long> v64i<uint>(Vector256<uint> x), hex://vfuncs/generic?v64i#v64i_g[32u](v256x32u)
; v64i_g[32u](v256x32u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<long> v64i<int>(Vector256<int> x), hex://vfuncs/generic?v64i#v64i_g[32i](v256x32i)
; v64i_g[32i](v256x32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<long> v64i<ulong>(Vector256<ulong> x), hex://vfuncs/generic?v64i#v64i_g[64u](v256x64u)
; v64i_g[64u](v256x64u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<long> v64i<long>(Vector256<long> x), hex://vfuncs/generic?v64i#v64i_g[64i](v256x64i)
; v64i_g[64i](v256x64i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<long> v64i<float>(Vector256<float> x), hex://vfuncs/generic?v64i#v64i_g[32f](v256x32f)
; v64i_g[32f](v256x32f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<long> v64i<double>(Vector256<double> x), hex://vfuncs/generic?v64i#v64i_g[64f](v256x64f)
; v64i_g[64f](v256x64f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ulong> v64u<byte>(Vector256<byte> x), hex://vfuncs/generic?v64u#v64u_g[8u](v256x8u)
; v64u_g[8u](v256x8u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ulong> v64u<sbyte>(Vector256<sbyte> x), hex://vfuncs/generic?v64u#v64u_g[8i](v256x8i)
; v64u_g[8i](v256x8i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ulong> v64u<ushort>(Vector256<ushort> x), hex://vfuncs/generic?v64u#v64u_g[16u](v256x16u)
; v64u_g[16u](v256x16u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ulong> v64u<short>(Vector256<short> x), hex://vfuncs/generic?v64u#v64u_g[16i](v256x16i)
; v64u_g[16i](v256x16i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ulong> v64u<uint>(Vector256<uint> x), hex://vfuncs/generic?v64u#v64u_g[32u](v256x32u)
; v64u_g[32u](v256x32u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ulong> v64u<int>(Vector256<int> x), hex://vfuncs/generic?v64u#v64u_g[32i](v256x32i)
; v64u_g[32i](v256x32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ulong> v64u<ulong>(Vector256<ulong> x), hex://vfuncs/generic?v64u#v64u_g[64u](v256x64u)
; v64u_g[64u](v256x64u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ulong> v64u<long>(Vector256<long> x), hex://vfuncs/generic?v64u#v64u_g[64i](v256x64i)
; v64u_g[64i](v256x64i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ulong> v64u<float>(Vector256<float> x), hex://vfuncs/generic?v64u#v64u_g[32f](v256x32f)
; v64u_g[32f](v256x32f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ulong> v64u<double>(Vector256<double> x), hex://vfuncs/generic?v64u#v64u_g[64f](v256x64f)
; v64u_g[64f](v256x64f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<float> v32f<byte>(Vector256<byte> x), hex://vfuncs/generic?v32f#v32f_g[8u](v256x8u)
; v32f_g[8u](v256x8u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<float> v32f<sbyte>(Vector256<sbyte> x), hex://vfuncs/generic?v32f#v32f_g[8i](v256x8i)
; v32f_g[8i](v256x8i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<float> v32f<ushort>(Vector256<ushort> x), hex://vfuncs/generic?v32f#v32f_g[16u](v256x16u)
; v32f_g[16u](v256x16u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<float> v32f<short>(Vector256<short> x), hex://vfuncs/generic?v32f#v32f_g[16i](v256x16i)
; v32f_g[16i](v256x16i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<float> v32f<uint>(Vector256<uint> x), hex://vfuncs/generic?v32f#v32f_g[32u](v256x32u)
; v32f_g[32u](v256x32u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<float> v32f<int>(Vector256<int> x), hex://vfuncs/generic?v32f#v32f_g[32i](v256x32i)
; v32f_g[32i](v256x32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<float> v32f<ulong>(Vector256<ulong> x), hex://vfuncs/generic?v32f#v32f_g[64u](v256x64u)
; v32f_g[64u](v256x64u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<float> v32f<long>(Vector256<long> x), hex://vfuncs/generic?v32f#v32f_g[64i](v256x64i)
; v32f_g[64i](v256x64i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<float> v32f<float>(Vector256<float> x), hex://vfuncs/generic?v32f#v32f_g[32f](v256x32f)
; v32f_g[32f](v256x32f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<float> v32f<double>(Vector256<double> x), hex://vfuncs/generic?v32f#v32f_g[64f](v256x64f)
; v32f_g[64f](v256x64f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<double> v64f<byte>(Vector256<byte> x), hex://vfuncs/generic?v64f#v64f_g[8u](v256x8u)
; v64f_g[8u](v256x8u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<double> v64f<sbyte>(Vector256<sbyte> x), hex://vfuncs/generic?v64f#v64f_g[8i](v256x8i)
; v64f_g[8i](v256x8i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<double> v64f<ushort>(Vector256<ushort> x), hex://vfuncs/generic?v64f#v64f_g[16u](v256x16u)
; v64f_g[16u](v256x16u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<double> v64f<short>(Vector256<short> x), hex://vfuncs/generic?v64f#v64f_g[16i](v256x16i)
; v64f_g[16i](v256x16i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<double> v64f<uint>(Vector256<uint> x), hex://vfuncs/generic?v64f#v64f_g[32u](v256x32u)
; v64f_g[32u](v256x32u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<double> v64f<int>(Vector256<int> x), hex://vfuncs/generic?v64f#v64f_g[32i](v256x32i)
; v64f_g[32i](v256x32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<double> v64f<ulong>(Vector256<ulong> x), hex://vfuncs/generic?v64f#v64f_g[64u](v256x64u)
; v64f_g[64u](v256x64u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<double> v64f<long>(Vector256<long> x), hex://vfuncs/generic?v64f#v64f_g[64i](v256x64i)
; v64f_g[64i](v256x64i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<double> v64f<float>(Vector256<float> x), hex://vfuncs/generic?v64f#v64f_g[32f](v256x32f)
; v64f_g[32f](v256x32f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<double> v64f<double>(Vector256<double> x), hex://vfuncs/generic?v64f#v64f_g[64f](v256x64f)
; v64f_g[64f](v256x64f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x02,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rdx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 02}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<byte>(N128 w, byte t), hex://vfuncs/generic?vcount#vcount_g[8u](n128,8u)
; vcount_g[8u](n128,8u)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x10,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,10h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 10 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<sbyte>(N128 w, sbyte t), hex://vfuncs/generic?vcount#vcount_g[8i](n128,8i)
; vcount_g[8i](n128,8i)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x10,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,10h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 10 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<ushort>(N128 w, ushort t), hex://vfuncs/generic?vcount#vcount_g[16u](n128,16u)
; vcount_g[16u](n128,16u)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x08,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,8                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 08 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<short>(N128 w, short t), hex://vfuncs/generic?vcount#vcount_g[16i](n128,16i)
; vcount_g[16i](n128,16i)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x08,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,8                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 08 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<uint>(N128 w, uint t), hex://vfuncs/generic?vcount#vcount_g[32u](n128,32u)
; vcount_g[32u](n128,32u)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x04,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,4                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 04 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<int>(N128 w, int t), hex://vfuncs/generic?vcount#vcount_g[32i](n128,32i)
; vcount_g[32i](n128,32i)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x04,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,4                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 04 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<ulong>(N128 w, ulong t), hex://vfuncs/generic?vcount#vcount_g[64u](n128,64u)
; vcount_g[64u](n128,64u)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x02,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,2                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 02 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<long>(N128 w, long t), hex://vfuncs/generic?vcount#vcount_g[64i](n128,64i)
; vcount_g[64i](n128,64i)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x02,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,2                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 02 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<float>(N128 w, float t), hex://vfuncs/generic?vcount#vcount_g[32f](n128,32f)
; vcount_g[32f](n128,32f)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x04,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,4                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 04 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<double>(N128 w, double t), hex://vfuncs/generic?vcount#vcount_g[64f](n128,64f)
; vcount_g[64f](n128,64f)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x02,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,2                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 02 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<byte>(N256 w, byte t), hex://vfuncs/generic?vcount#vcount_g[8u](n256,8u)
; vcount_g[8u](n256,8u)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x20,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,20h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 20 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<sbyte>(N256 w, sbyte t), hex://vfuncs/generic?vcount#vcount_g[8i](n256,8i)
; vcount_g[8i](n256,8i)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x20,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,20h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 20 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<ushort>(N256 w, ushort t), hex://vfuncs/generic?vcount#vcount_g[16u](n256,16u)
; vcount_g[16u](n256,16u)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x10,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,10h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 10 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<short>(N256 w, short t), hex://vfuncs/generic?vcount#vcount_g[16i](n256,16i)
; vcount_g[16i](n256,16i)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x10,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,10h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 10 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<uint>(N256 w, uint t), hex://vfuncs/generic?vcount#vcount_g[32u](n256,32u)
; vcount_g[32u](n256,32u)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x08,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,8                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 08 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<int>(N256 w, int t), hex://vfuncs/generic?vcount#vcount_g[32i](n256,32i)
; vcount_g[32i](n256,32i)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x08,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,8                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 08 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<ulong>(N256 w, ulong t), hex://vfuncs/generic?vcount#vcount_g[64u](n256,64u)
; vcount_g[64u](n256,64u)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x04,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,4                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 04 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<long>(N256 w, long t), hex://vfuncs/generic?vcount#vcount_g[64i](n256,64i)
; vcount_g[64i](n256,64i)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x04,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,4                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 04 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<float>(N256 w, float t), hex://vfuncs/generic?vcount#vcount_g[32f](n256,32f)
; vcount_g[32f](n256,32f)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x08,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,8                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 08 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<double>(N256 w, double t), hex://vfuncs/generic?vcount#vcount_g[64f](n256,64f)
; vcount_g[64f](n256,64f)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x04,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,4                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 04 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<byte>(N512 w, byte t), hex://vfuncs/generic?vcount#vcount_g[8u](n512,8u)
; vcount_g[8u](n512,8u)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x40,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,40h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 40 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<sbyte>(N512 w, sbyte t), hex://vfuncs/generic?vcount#vcount_g[8i](n512,8i)
; vcount_g[8i](n512,8i)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x40,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,40h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 40 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<ushort>(N512 w, ushort t), hex://vfuncs/generic?vcount#vcount_g[16u](n512,16u)
; vcount_g[16u](n512,16u)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x20,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,20h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 20 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<short>(N512 w, short t), hex://vfuncs/generic?vcount#vcount_g[16i](n512,16i)
; vcount_g[16i](n512,16i)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x20,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,20h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 20 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<uint>(N512 w, uint t), hex://vfuncs/generic?vcount#vcount_g[32u](n512,32u)
; vcount_g[32u](n512,32u)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x10,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,10h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 10 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<int>(N512 w, int t), hex://vfuncs/generic?vcount#vcount_g[32i](n512,32i)
; vcount_g[32i](n512,32i)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x10,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,10h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 10 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<ulong>(N512 w, ulong t), hex://vfuncs/generic?vcount#vcount_g[64u](n512,64u)
; vcount_g[64u](n512,64u)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x08,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,8                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 08 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<long>(N512 w, long t), hex://vfuncs/generic?vcount#vcount_g[64i](n512,64i)
; vcount_g[64i](n512,64i)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x08,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,8                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 08 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<float>(N512 w, float t), hex://vfuncs/generic?vcount#vcount_g[32f](n512,32f)
; vcount_g[32f](n512,32f)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x10,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,10h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 10 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vcount<double>(N512 w, double t), hex://vfuncs/generic?vcount#vcount_g[64f](n512,64f)
; vcount_g[64f](n512,64f)[11] = {0x0f,0x1f,0x44,0x00,0x00,0xb8,0x08,0x00,0x00,0x00,0xc3}
; TermCode = CTC_RET_ZED_SBB
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov eax,8                               ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b8 08 00 00 00}
000ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> vzero<byte>(N128 w, byte t), hex://vfuncs/generic?vzero#vzero_g[8u](n128,8u)
; vzero_g[8u](n128,8u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf8,0x57,0xc0,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps xmm0,xmm0,xmm0                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 f8 57 c0}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> vzero<sbyte>(N128 w, sbyte t), hex://vfuncs/generic?vzero#vzero_g[8i](n128,8i)
; vzero_g[8i](n128,8i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf8,0x57,0xc0,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps xmm0,xmm0,xmm0                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 f8 57 c0}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> vzero<ushort>(N128 w, ushort t), hex://vfuncs/generic?vzero#vzero_g[16u](n128,16u)
; vzero_g[16u](n128,16u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf8,0x57,0xc0,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps xmm0,xmm0,xmm0                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 f8 57 c0}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> vzero<short>(N128 w, short t), hex://vfuncs/generic?vzero#vzero_g[16i](n128,16i)
; vzero_g[16i](n128,16i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf8,0x57,0xc0,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps xmm0,xmm0,xmm0                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 f8 57 c0}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> vzero<uint>(N128 w, uint t), hex://vfuncs/generic?vzero#vzero_g[32u](n128,32u)
; vzero_g[32u](n128,32u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf8,0x57,0xc0,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps xmm0,xmm0,xmm0                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 f8 57 c0}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> vzero<int>(N128 w, int t), hex://vfuncs/generic?vzero#vzero_g[32i](n128,32i)
; vzero_g[32i](n128,32i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf8,0x57,0xc0,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps xmm0,xmm0,xmm0                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 f8 57 c0}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> vzero<ulong>(N128 w, ulong t), hex://vfuncs/generic?vzero#vzero_g[64u](n128,64u)
; vzero_g[64u](n128,64u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf8,0x57,0xc0,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps xmm0,xmm0,xmm0                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 f8 57 c0}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> vzero<long>(N128 w, long t), hex://vfuncs/generic?vzero#vzero_g[64i](n128,64i)
; vzero_g[64i](n128,64i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf8,0x57,0xc0,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps xmm0,xmm0,xmm0                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 f8 57 c0}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> vzero<float>(N128 w, float t), hex://vfuncs/generic?vzero#vzero_g[32f](n128,32f)
; vzero_g[32f](n128,32f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf8,0x57,0xc0,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps xmm0,xmm0,xmm0                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 f8 57 c0}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> vzero<double>(N128 w, double t), hex://vfuncs/generic?vzero#vzero_g[64f](n128,64f)
; vzero_g[64f](n128,64f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf8,0x57,0xc0,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps xmm0,xmm0,xmm0                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 f8 57 c0}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<byte> vzero<byte>(N256 w, byte t), hex://vfuncs/generic?vzero#vzero_g[8u](n256,8u)
; vzero_g[8u](n256,8u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfc,0x57,0xc0,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps ymm0,ymm0,ymm0                   ; VXORPS ymm1, ymm2, ymm3/m256 || VEX.256.0F.WIG 57 /r || encoded[4]{c5 fc 57 c0}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<sbyte> vzero<sbyte>(N256 w, sbyte t), hex://vfuncs/generic?vzero#vzero_g[8i](n256,8i)
; vzero_g[8i](n256,8i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfc,0x57,0xc0,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps ymm0,ymm0,ymm0                   ; VXORPS ymm1, ymm2, ymm3/m256 || VEX.256.0F.WIG 57 /r || encoded[4]{c5 fc 57 c0}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ushort> vzero<ushort>(N256 w, ushort t), hex://vfuncs/generic?vzero#vzero_g[16u](n256,16u)
; vzero_g[16u](n256,16u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfc,0x57,0xc0,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps ymm0,ymm0,ymm0                   ; VXORPS ymm1, ymm2, ymm3/m256 || VEX.256.0F.WIG 57 /r || encoded[4]{c5 fc 57 c0}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<short> vzero<short>(N256 w, short t), hex://vfuncs/generic?vzero#vzero_g[16i](n256,16i)
; vzero_g[16i](n256,16i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfc,0x57,0xc0,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps ymm0,ymm0,ymm0                   ; VXORPS ymm1, ymm2, ymm3/m256 || VEX.256.0F.WIG 57 /r || encoded[4]{c5 fc 57 c0}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<uint> vzero<uint>(N256 w, uint t), hex://vfuncs/generic?vzero#vzero_g[32u](n256,32u)
; vzero_g[32u](n256,32u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfc,0x57,0xc0,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps ymm0,ymm0,ymm0                   ; VXORPS ymm1, ymm2, ymm3/m256 || VEX.256.0F.WIG 57 /r || encoded[4]{c5 fc 57 c0}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<int> vzero<int>(N256 w, int t), hex://vfuncs/generic?vzero#vzero_g[32i](n256,32i)
; vzero_g[32i](n256,32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfc,0x57,0xc0,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps ymm0,ymm0,ymm0                   ; VXORPS ymm1, ymm2, ymm3/m256 || VEX.256.0F.WIG 57 /r || encoded[4]{c5 fc 57 c0}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ulong> vzero<ulong>(N256 w, ulong t), hex://vfuncs/generic?vzero#vzero_g[64u](n256,64u)
; vzero_g[64u](n256,64u)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfc,0x57,0xc0,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps ymm0,ymm0,ymm0                   ; VXORPS ymm1, ymm2, ymm3/m256 || VEX.256.0F.WIG 57 /r || encoded[4]{c5 fc 57 c0}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<long> vzero<long>(N256 w, long t), hex://vfuncs/generic?vzero#vzero_g[64i](n256,64i)
; vzero_g[64i](n256,64i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfc,0x57,0xc0,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps ymm0,ymm0,ymm0                   ; VXORPS ymm1, ymm2, ymm3/m256 || VEX.256.0F.WIG 57 /r || encoded[4]{c5 fc 57 c0}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<float> vzero<float>(N256 w, float t), hex://vfuncs/generic?vzero#vzero_g[32f](n256,32f)
; vzero_g[32f](n256,32f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfc,0x57,0xc0,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps ymm0,ymm0,ymm0                   ; VXORPS ymm1, ymm2, ymm3/m256 || VEX.256.0F.WIG 57 /r || encoded[4]{c5 fc 57 c0}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector256<double> vzero<double>(N256 w, double t), hex://vfuncs/generic?vzero#vzero_g[64f](n256,64f)
; vzero_g[64f](n256,64f)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfc,0x57,0xc0,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vxorps ymm0,ymm0,ymm0                   ; VXORPS ymm1, ymm2, ymm3/m256 || VEX.256.0F.WIG 57 /r || encoded[4]{c5 fc 57 c0}
0009h vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<byte> span<byte>(Vector128<byte> src), hex://vfuncs/generic?span#span_g[8u](v128x8u)
; span_g[8u](v128x8u)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x3d,0x7c,0xbe,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x20,0x9f,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c82c3b90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 3d 7c be ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 20 9f b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<sbyte> span<sbyte>(Vector128<sbyte> src), hex://vfuncs/generic?span#span_g[8i](v128x8i)
; span_g[8i](v128x8i)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x0d,0x78,0xbe,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x80,0x9a,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c82c3c00h                      ; CALL rel32 || E8 cd || encoded[5]{e8 0d 78 be ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 80 9a b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<ushort> span<ushort>(Vector128<ushort> src), hex://vfuncs/generic?span#span_g[16u](v128x16u)
; span_g[16u](v128x16u)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xdd,0x77,0xbe,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0xe0,0x99,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c82c3c70h                      ; CALL rel32 || E8 cd || encoded[5]{e8 dd 77 be ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e0 99 b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<short> span<short>(Vector128<short> src), hex://vfuncs/generic?span#span_g[16i](v128x16i)
; span_g[16i](v128x16i)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xad,0x77,0xbe,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x40,0x99,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c82c3ce0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ad 77 be ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 40 99 b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<uint> span<uint>(Vector128<uint> src), hex://vfuncs/generic?span#span_g[32u](v128x32u)
; span_g[32u](v128x32u)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x7d,0x77,0xbe,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0xa0,0x98,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c82c3d50h                      ; CALL rel32 || E8 cd || encoded[5]{e8 7d 77 be ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a0 98 b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<int> span<int>(Vector128<int> src), hex://vfuncs/generic?span#span_g[32i](v128x32i)
; span_g[32i](v128x32i)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x4d,0x73,0xbe,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x00,0x94,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c82c3dc0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 4d 73 be ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 00 94 b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<ulong> span<ulong>(Vector128<ulong> src), hex://vfuncs/generic?span#span_g[64u](v128x64u)
; span_g[64u](v128x64u)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x1d,0x73,0xbe,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x60,0x93,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c82c3e30h                      ; CALL rel32 || E8 cd || encoded[5]{e8 1d 73 be ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 60 93 b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<long> span<long>(Vector128<long> src), hex://vfuncs/generic?span#span_g[64i](v128x64i)
; span_g[64i](v128x64i)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0xed,0x72,0xbe,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0xc0,0x92,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c82c3ea0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ed 72 be ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c0 92 b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<float> span<float>(Vector128<float> src), hex://vfuncs/generic?span#span_g[32f](v128x32f)
; span_g[32f](v128x32f)[126] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0xc5,0xe0,0x57,0xdb,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xbc,0x6e,0xbe,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xf8,0x11,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x1f,0x8e,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h vxorps xmm3,xmm3,xmm3                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 e0 57 db}
0049h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004fh call 7ff7c82c3f10h                      ; CALL rel32 || E8 cd || encoded[5]{e8 bc 6e be ff}
0054h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0059h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005ch vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
0060h vmovups [rax],xmm0                      ; VMOVUPS xmm2/m128, xmm1 || VEX.128.0F.WIG 11 /r || encoded[4]{c5 f8 11 00}
0064h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0069h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006ch call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 1f 8e b8 5e}
0071h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0073h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0076h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ah pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007bh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007ch pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<double> span<double>(Vector128<double> src), hex://vfuncs/generic?span#span_g[64f](v128x64f)
; span_g[64f](v128x64f)[126] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0xc5,0xe0,0x57,0xdb,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x8c,0x6e,0xbe,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xf9,0x11,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x7f,0x8d,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h vxorps xmm3,xmm3,xmm3                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 e0 57 db}
0049h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004fh call 7ff7c82c3f80h                      ; CALL rel32 || E8 cd || encoded[5]{e8 8c 6e be ff}
0054h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0059h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005ch vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
0060h vmovupd [rax],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 00}
0064h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0069h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006ch call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 7f 8d b8 5e}
0071h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0073h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0076h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ah pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007bh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007ch pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<byte> span<byte>(Vector256<byte> src), hex://vfuncs/generic?span#span_g[8u](v256x8u)
; span_g[8u](v256x8u)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xdd,0x2e,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0xd0,0x88,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c8400480h                      ; CALL rel32 || E8 cd || encoded[5]{e8 dd 2e d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d0 88 b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<sbyte> span<sbyte>(Vector256<sbyte> src), hex://vfuncs/generic?span#span_g[8i](v256x8i)
; span_g[8i](v256x8i)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xad,0x2e,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x30,0x88,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c84004f0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ad 2e d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 30 88 b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<ushort> span<ushort>(Vector256<ushort> src), hex://vfuncs/generic?span#span_g[16u](v256x16u)
; span_g[16u](v256x16u)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x7d,0x2e,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x90,0x87,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c8400560h                      ; CALL rel32 || E8 cd || encoded[5]{e8 7d 2e d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 90 87 b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<short> span<short>(Vector256<short> src), hex://vfuncs/generic?span#span_g[16i](v256x16i)
; span_g[16i](v256x16i)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x4d,0x2e,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0xf0,0x86,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c84005d0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 4d 2e d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f0 86 b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<uint> span<uint>(Vector256<uint> src), hex://vfuncs/generic?span#span_g[32u](v256x32u)
; span_g[32u](v256x32u)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x1d,0x2e,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x50,0x86,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c8400640h                      ; CALL rel32 || E8 cd || encoded[5]{e8 1d 2e d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 50 86 b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<int> span<int>(Vector256<int> src), hex://vfuncs/generic?span#span_g[32i](v256x32i)
; span_g[32i](v256x32i)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0xdd,0x29,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0xa0,0x81,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c84006b0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 dd 29 d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a0 81 b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<ulong> span<ulong>(Vector256<ulong> src), hex://vfuncs/generic?span#span_g[64u](v256x64u)
; span_g[64u](v256x64u)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0xad,0x29,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x00,0x81,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c8400720h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ad 29 d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 00 81 b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<long> span<long>(Vector256<long> src), hex://vfuncs/generic?span#span_g[64i](v256x64i)
; span_g[64i](v256x64i)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x7d,0x29,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x60,0x80,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c8400790h                      ; CALL rel32 || E8 cd || encoded[5]{e8 7d 29 d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0068h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 60 80 b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<float> span<float>(Vector256<float> src), hex://vfuncs/generic?span#span_g[32f](v256x32f)
; span_g[32f](v256x32f)[129] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0xc5,0xe0,0x57,0xdb,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x4c,0x29,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfc,0x11,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0xbf,0x7f,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h vxorps xmm3,xmm3,xmm3                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 e0 57 db}
0049h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004fh call 7ff7c8400800h                      ; CALL rel32 || E8 cd || encoded[5]{e8 4c 29 d2 ff}
0054h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0059h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005ch vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
0060h vmovups [rax],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 00}
0064h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0069h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006ch call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 bf 7f b8 5e}
0071h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0073h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0076h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0079h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007dh pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007eh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007fh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
0080h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<double> span<double>(Vector256<double> src), hex://vfuncs/generic?span#span_g[64f](v256x64f)
; span_g[64f](v256x64f)[129] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0xc5,0xe0,0x57,0xdb,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x0c,0x25,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x11,0x00,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x0f,0x7b,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h vxorps xmm3,xmm3,xmm3                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 e0 57 db}
0049h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004fh call 7ff7c8400870h                      ; CALL rel32 || E8 cd || encoded[5]{e8 0c 25 d2 ff}
0054h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0059h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005ch vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
0060h vmovupd [rax],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 00}
0064h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0069h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
006ch call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 0f 7b b8 5e}
0071h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0073h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0076h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0079h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007dh pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007eh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007fh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
0080h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<byte> span<byte>(Vector512<byte> src), hex://vfuncs/generic?span#span_g[8u](v512x8u)
; span_g[8u](v512x8u)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xcd,0x20,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x50,0x76,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c84008e0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 cd 20 d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0078h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 50 76 b8 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<sbyte> span<sbyte>(Vector512<sbyte> src), hex://vfuncs/generic?span#span_g[8i](v512x8i)
; span_g[8i](v512x8i)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x8d,0x20,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0xa0,0x75,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c8400950h                      ; CALL rel32 || E8 cd || encoded[5]{e8 8d 20 d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0078h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a0 75 b8 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<ushort> span<ushort>(Vector512<ushort> src), hex://vfuncs/generic?span#span_g[16u](v512x16u)
; span_g[16u](v512x16u)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x4d,0x20,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0xf0,0x74,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c84009c0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 4d 20 d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0078h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f0 74 b8 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<short> span<short>(Vector512<short> src), hex://vfuncs/generic?span#span_g[16i](v512x16i)
; span_g[16i](v512x16i)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x0d,0x20,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x40,0x74,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c8400a30h                      ; CALL rel32 || E8 cd || encoded[5]{e8 0d 20 d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0078h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 40 74 b8 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<uint> span<uint>(Vector512<uint> src), hex://vfuncs/generic?span#span_g[32u](v512x32u)
; span_g[32u](v512x32u)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0xcd,0x1f,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x90,0x73,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c8400aa0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 cd 1f d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0078h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 90 73 b8 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<int> span<int>(Vector512<int> src), hex://vfuncs/generic?span#span_g[32i](v512x32i)
; span_g[32i](v512x32i)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x8d,0x1f,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0xe0,0x72,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c8400b10h                      ; CALL rel32 || E8 cd || encoded[5]{e8 8d 1f d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0078h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e0 72 b8 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<ulong> span<ulong>(Vector512<ulong> src), hex://vfuncs/generic?span#span_g[64u](v512x64u)
; span_g[64u](v512x64u)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x3d,0x1b,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x20,0x6e,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c8400b80h                      ; CALL rel32 || E8 cd || encoded[5]{e8 3d 1b d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0078h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 20 6e b8 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<long> span<long>(Vector512<long> src), hex://vfuncs/generic?span#span_g[64i](v512x64i)
; span_g[64i](v512x64i)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0xfd,0x1a,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x70,0x6d,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c8400bf0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 fd 1a d2 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0078h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 70 6d b8 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<float> span<float>(Vector512<float> src), hex://vfuncs/generic?span#span_g[32f](v512x32f)
; span_g[32f](v512x32f)[145] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0xc5,0xe0,0x57,0xdb,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xbc,0x1a,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfc,0x11,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfc,0x11,0x08,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0xbf,0x6c,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h vxorps xmm3,xmm3,xmm3                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 e0 57 db}
0049h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004fh call 7ff7c8400c60h                      ; CALL rel32 || E8 cd || encoded[5]{e8 bc 1a d2 ff}
0054h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0059h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005ch vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
0060h vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0065h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0068h vmovups [rdx],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 02}
006ch add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0070h vmovups [rax],ymm1                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 08}
0074h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0079h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
007ch call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 bf 6c b8 5e}
0081h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0083h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0086h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0089h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008dh pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008eh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008fh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
0090h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Span<double> span<double>(Vector512<double> src), hex://vfuncs/generic?span#span_g[64f](v512x64f)
; span_g[64f](v512x64f)[145] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0xc5,0xe0,0x57,0xdb,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x7c,0x1a,0xd2,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfd,0x11,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfd,0x11,0x08,0x48,0x8d,0x74,0x24,0x40,0x48,0x8b,0xfb,0xe8,0x0f,0x6c,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h vxorps xmm3,xmm3,xmm3                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 e0 57 db}
0049h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004fh call 7ff7c8400cd0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 7c 1a d2 ff}
0054h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0059h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005ch vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
0060h vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0065h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0068h vmovupd [rdx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 02}
006ch add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0070h vmovupd [rax],ymm1                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 08}
0074h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
0079h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
007ch call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 0f 6c b8 5e}
0081h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0083h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0086h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0089h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008dh pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008eh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008fh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
0090h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector128<byte> src, ref Fixed128 dst), hex://vfuncs/generic?vstore#vstore_g[8u](v128x8u)
; vstore_g[8u](v128x8u)[14] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x02,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovdqu xmmword ptr [rdx],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 02}
000dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector128<sbyte> src, ref Fixed128 dst), hex://vfuncs/generic?vstore#vstore_g[8i](v128x8i)
; vstore_g[8i](v128x8i)[14] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x02,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovdqu xmmword ptr [rdx],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 02}
000dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector128<ushort> src, ref Fixed128 dst), hex://vfuncs/generic?vstore#vstore_g[16u](v128x16u)
; vstore_g[16u](v128x16u)[14] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x02,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovdqu xmmword ptr [rdx],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 02}
000dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector128<short> src, ref Fixed128 dst), hex://vfuncs/generic?vstore#vstore_g[16i](v128x16i)
; vstore_g[16i](v128x16i)[14] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x02,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovdqu xmmword ptr [rdx],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 02}
000dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector128<uint> src, ref Fixed128 dst), hex://vfuncs/generic?vstore#vstore_g[32u](v128x32u)
; vstore_g[32u](v128x32u)[14] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x02,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovdqu xmmword ptr [rdx],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 02}
000dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector128<int> src, ref Fixed128 dst), hex://vfuncs/generic?vstore#vstore_g[32i](v128x32i)
; vstore_g[32i](v128x32i)[14] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x02,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovdqu xmmword ptr [rdx],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 02}
000dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector128<ulong> src, ref Fixed128 dst), hex://vfuncs/generic?vstore#vstore_g[64u](v128x64u)
; vstore_g[64u](v128x64u)[14] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x02,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovdqu xmmword ptr [rdx],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 02}
000dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector128<long> src, ref Fixed128 dst), hex://vfuncs/generic?vstore#vstore_g[64i](v128x64i)
; vstore_g[64i](v128x64i)[14] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x02,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovdqu xmmword ptr [rdx],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 02}
000dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector128<float> src, ref Fixed128 dst), hex://vfuncs/generic?vstore#vstore_g[32f](v128x32f)
; vstore_g[32f](v128x32f)[14] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xf8,0x11,0x02,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovups [rdx],xmm0                      ; VMOVUPS xmm2/m128, xmm1 || VEX.128.0F.WIG 11 /r || encoded[4]{c5 f8 11 02}
000dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector128<double> src, ref Fixed128 dst), hex://vfuncs/generic?vstore#vstore_g[64f](v128x64f)
; vstore_g[64f](v128x64f)[14] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x11,0x02,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovupd [rdx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 02}
000dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector256<byte> src, ref Fixed256 dst), hex://vfuncs/generic?vstore#vstore_g[8u](v256x8u)
; vstore_g[8u](v256x8u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x02,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
000dh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector256<sbyte> src, ref Fixed256 dst), hex://vfuncs/generic?vstore#vstore_g[8i](v256x8i)
; vstore_g[8i](v256x8i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x02,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
000dh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector256<ushort> src, ref Fixed256 dst), hex://vfuncs/generic?vstore#vstore_g[16u](v256x16u)
; vstore_g[16u](v256x16u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x02,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
000dh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector256<short> src, ref Fixed256 dst), hex://vfuncs/generic?vstore#vstore_g[16i](v256x16i)
; vstore_g[16i](v256x16i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x02,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
000dh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector256<uint> src, ref Fixed256 dst), hex://vfuncs/generic?vstore#vstore_g[32u](v256x32u)
; vstore_g[32u](v256x32u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x02,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
000dh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector256<int> src, ref Fixed256 dst), hex://vfuncs/generic?vstore#vstore_g[32i](v256x32i)
; vstore_g[32i](v256x32i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x02,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
000dh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector256<ulong> src, ref Fixed256 dst), hex://vfuncs/generic?vstore#vstore_g[64u](v256x64u)
; vstore_g[64u](v256x64u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x02,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
000dh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector256<long> src, ref Fixed256 dst), hex://vfuncs/generic?vstore#vstore_g[64i](v256x64i)
; vstore_g[64i](v256x64i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x02,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
000dh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector256<float> src, ref Fixed256 dst), hex://vfuncs/generic?vstore#vstore_g[32f](v256x32f)
; vstore_g[32f](v256x32f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0xc5,0xfc,0x11,0x02,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h vmovups [rdx],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 02}
000dh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector256<double> src, ref Fixed256 dst), hex://vfuncs/generic?vstore#vstore_g[64f](v256x64f)
; vstore_g[64f](v256x64f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x02,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h vmovupd [rdx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 02}
000dh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector128<byte> src, Span<byte> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[8u](v128x8u,span8u,32i)
; vstore_g[8u](v128x8u,span8u,32i)[23] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x03,0xc2,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
0012h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0016h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector128<sbyte> src, Span<sbyte> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[8i](v128x8i,span8i,32i)
; vstore_g[8i](v128x8i,span8i,32i)[23] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x03,0xc2,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
0012h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0016h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector128<ushort> src, Span<ushort> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[16u](v128x16u,span16u,32i)
; vstore_g[16u](v128x16u,span16u,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x50,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 50}
0013h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector128<short> src, Span<short> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[16i](v128x16i,span16i,32i)
; vstore_g[16i](v128x16i,span16i,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x50,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 50}
0013h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector128<uint> src, Span<uint> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32u](v128x32u,span32u,32i)
; vstore_g[32u](v128x32u,span32u,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0013h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector128<int> src, Span<int> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32i](v128x32i,span32i,32i)
; vstore_g[32i](v128x32i,span32i,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0013h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector128<ulong> src, Span<ulong> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64u](v128x64u,span64u,32i)
; vstore_g[64u](v128x64u,span64u,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0013h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector128<long> src, Span<long> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64i](v128x64i,span64i,32i)
; vstore_g[64i](v128x64i,span64i,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0013h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector128<float> src, Span<float> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32f](v128x32f,span32f,32i)
; vstore_g[32f](v128x32f,span32f,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xf8,0x11,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0013h vmovups [rax],xmm0                      ; VMOVUPS xmm2/m128, xmm1 || VEX.128.0F.WIG 11 /r || encoded[4]{c5 f8 11 00}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector128<double> src, Span<double> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64f](v128x64f,span64f,32i)
; vstore_g[64f](v128x64f,span64f,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xf9,0x11,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0013h vmovupd [rax],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 00}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector256<byte> src, Span<byte> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[8u](v256x8u,span8u,32i)
; vstore_g[8u](v256x8u,span8u,32i)[26] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x03,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
0012h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0016h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0019h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector256<sbyte> src, Span<sbyte> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[8i](v256x8i,span8i,32i)
; vstore_g[8i](v256x8i,span8i,32i)[26] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x03,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
0012h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0016h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0019h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector256<ushort> src, Span<ushort> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[16u](v256x16u,span16u,32i)
; vstore_g[16u](v256x16u,span16u,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x50,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 50}
0013h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0017h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector256<short> src, Span<short> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[16i](v256x16i,span16i,32i)
; vstore_g[16i](v256x16i,span16i,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x50,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 50}
0013h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0017h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector256<uint> src, Span<uint> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32u](v256x32u,span32u,32i)
; vstore_g[32u](v256x32u,span32u,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0013h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0017h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector256<int> src, Span<int> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32i](v256x32i,span32i,32i)
; vstore_g[32i](v256x32i,span32i,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0013h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0017h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector256<ulong> src, Span<ulong> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64u](v256x64u,span64u,32i)
; vstore_g[64u](v256x64u,span64u,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0013h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0017h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector256<long> src, Span<long> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64i](v256x64i,span64i,32i)
; vstore_g[64i](v256x64i,span64i,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0013h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0017h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector256<float> src, Span<float> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32f](v256x32f,span32f,32i)
; vstore_g[32f](v256x32f,span32f,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfc,0x11,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0013h vmovups [rax],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 00}
0017h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector256<double> src, Span<double> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64f](v256x64f,span64f,32i)
; vstore_g[64f](v256x64f,span64f,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfd,0x11,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
000fh lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0013h vmovupd [rax],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 00}
0017h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector512<byte> src, Span<byte> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[8u](v512x8u,span8u,32i)
; vstore_g[8u](v512x8u,span8u,32i)[45] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x03,0xd0,0xc5,0xfe,0x7f,0x02,0x41,0x83,0xc0,0x20,0x49,0x63,0xd0,0x48,0x03,0xc2,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0014h add rdx,rax                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 d0}
0017h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
001bh add r8d,20h                             ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 20}
001fh movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0022h add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
0025h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0029h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector512<sbyte> src, Span<sbyte> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[8i](v512x8i,span8i,32i)
; vstore_g[8i](v512x8i,span8i,32i)[45] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x03,0xd0,0xc5,0xfe,0x7f,0x02,0x41,0x83,0xc0,0x20,0x49,0x63,0xd0,0x48,0x03,0xc2,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0014h add rdx,rax                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 d0}
0017h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
001bh add r8d,20h                             ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 20}
001fh movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0022h add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
0025h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0029h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector512<ushort> src, Span<ushort> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[16u](v512x16u,span16u,32i)
; vstore_g[16u](v512x16u,span16u,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x14,0x50,0xc5,0xfe,0x7f,0x02,0x41,0x83,0xc0,0x10,0x49,0x63,0xd0,0x48,0x8d,0x04,0x50,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0014h lea rdx,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 14 50}
0018h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
001ch add r8d,10h                             ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 10}
0020h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0023h lea rax,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 50}
0027h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector512<short> src, Span<short> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[16i](v512x16i,span16i,32i)
; vstore_g[16i](v512x16i,span16i,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x14,0x50,0xc5,0xfe,0x7f,0x02,0x41,0x83,0xc0,0x10,0x49,0x63,0xd0,0x48,0x8d,0x04,0x50,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0014h lea rdx,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 14 50}
0018h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
001ch add r8d,10h                             ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 10}
0020h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0023h lea rax,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 50}
0027h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector512<uint> src, Span<uint> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32u](v512x32u,span32u,32i)
; vstore_g[32u](v512x32u,span32u,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x14,0x90,0xc5,0xfe,0x7f,0x02,0x41,0x83,0xc0,0x08,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0014h lea rdx,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 14 90}
0018h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
001ch add r8d,8                               ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 08}
0020h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0023h lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0027h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector512<int> src, Span<int> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32i](v512x32i,span32i,32i)
; vstore_g[32i](v512x32i,span32i,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x14,0x90,0xc5,0xfe,0x7f,0x02,0x41,0x83,0xc0,0x08,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0014h lea rdx,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 14 90}
0018h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
001ch add r8d,8                               ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 08}
0020h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0023h lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0027h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector512<ulong> src, Span<ulong> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64u](v512x64u,span64u,32i)
; vstore_g[64u](v512x64u,span64u,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x14,0xd0,0xc5,0xfe,0x7f,0x02,0x41,0x83,0xc0,0x04,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0014h lea rdx,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 14 d0}
0018h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
001ch add r8d,4                               ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 04}
0020h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0023h lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0027h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector512<long> src, Span<long> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64i](v512x64i,span64i,32i)
; vstore_g[64i](v512x64i,span64i,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x14,0xd0,0xc5,0xfe,0x7f,0x02,0x41,0x83,0xc0,0x04,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0014h lea rdx,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 14 d0}
0018h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
001ch add r8d,4                               ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 04}
0020h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0023h lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0027h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector512<float> src, Span<float> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32f](v512x32f,span32f,32i)
; vstore_g[32f](v512x32f,span32f,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x14,0x90,0xc5,0xfc,0x11,0x02,0x41,0x83,0xc0,0x08,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfc,0x11,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0014h lea rdx,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 14 90}
0018h vmovups [rdx],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 02}
001ch add r8d,8                               ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 08}
0020h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0023h lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0027h vmovups [rax],ymm1                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector512<double> src, Span<double> dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64f](v512x64f,span64f,32i)
; vstore_g[64f](v512x64f,span64f,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x14,0xd0,0xc5,0xfd,0x11,0x02,0x41,0x83,0xc0,0x04,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfd,0x11,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0014h lea rdx,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 14 d0}
0018h vmovupd [rdx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 02}
001ch add r8d,4                               ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 04}
0020h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0023h lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0027h vmovupd [rax],ymm1                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector512<byte> src, ref byte dst, int offset), hex://vfuncs/generic?vstore#vstore_g[8u](v512x8u,8u~ref,32i)
; vstore_g[8u](v512x8u,8u~ref,32i)[42] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x03,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xfd,0x10,0x41,0x20,0x41,0x83,0xc0,0x20,0x49,0x63,0xc0,0x48,0x03,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
000fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0013h vmovupd ymm0,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 41 20}
0018h add r8d,20h                             ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 20}
001ch movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
001fh add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
0022h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0026h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector512<sbyte> src, ref sbyte dst, int offset), hex://vfuncs/generic?vstore#vstore_g[8i](v512x8i,8i~ref,32i)
; vstore_g[8i](v512x8i,8i~ref,32i)[42] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x03,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xfd,0x10,0x41,0x20,0x41,0x83,0xc0,0x20,0x49,0x63,0xc0,0x48,0x03,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
000fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0013h vmovupd ymm0,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 41 20}
0018h add r8d,20h                             ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 20}
001ch movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
001fh add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
0022h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0026h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector512<ushort> src, ref ushort dst, int offset), hex://vfuncs/generic?vstore#vstore_g[16u](v512x16u,16u~ref,32i)
; vstore_g[16u](v512x16u,16u~ref,32i)[44] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x42,0xc5,0xfe,0x7f,0x00,0xc5,0xfd,0x10,0x41,0x20,0x41,0x83,0xc0,0x10,0x49,0x63,0xc0,0x48,0x8d,0x04,0x42,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 42}
0010h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0014h vmovupd ymm0,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 41 20}
0019h add r8d,10h                             ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 10}
001dh movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
0020h lea rax,[rdx+rax*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 42}
0024h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0028h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector512<short> src, ref short dst, int offset), hex://vfuncs/generic?vstore#vstore_g[16i](v512x16i,16i~ref,32i)
; vstore_g[16i](v512x16i,16i~ref,32i)[44] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x42,0xc5,0xfe,0x7f,0x00,0xc5,0xfd,0x10,0x41,0x20,0x41,0x83,0xc0,0x10,0x49,0x63,0xc0,0x48,0x8d,0x04,0x42,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 42}
0010h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0014h vmovupd ymm0,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 41 20}
0019h add r8d,10h                             ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 10}
001dh movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
0020h lea rax,[rdx+rax*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 42}
0024h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0028h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector512<uint> src, ref uint dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32u](v512x32u,32u~ref,32i)
; vstore_g[32u](v512x32u,32u~ref,32i)[44] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x82,0xc5,0xfe,0x7f,0x00,0xc5,0xfd,0x10,0x41,0x20,0x41,0x83,0xc0,0x08,0x49,0x63,0xc0,0x48,0x8d,0x04,0x82,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 82}
0010h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0014h vmovupd ymm0,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 41 20}
0019h add r8d,8                               ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 08}
001dh movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
0020h lea rax,[rdx+rax*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 82}
0024h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0028h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector512<int> src, ref int dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32i](v512x32i,32i~ref,32i)
; vstore_g[32i](v512x32i,32i~ref,32i)[44] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x82,0xc5,0xfe,0x7f,0x00,0xc5,0xfd,0x10,0x41,0x20,0x41,0x83,0xc0,0x08,0x49,0x63,0xc0,0x48,0x8d,0x04,0x82,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 82}
0010h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0014h vmovupd ymm0,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 41 20}
0019h add r8d,8                               ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 08}
001dh movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
0020h lea rax,[rdx+rax*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 82}
0024h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0028h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector512<ulong> src, ref ulong dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64u](v512x64u,64u~ref,32i)
; vstore_g[64u](v512x64u,64u~ref,32i)[44] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xfd,0x10,0x41,0x20,0x41,0x83,0xc0,0x04,0x49,0x63,0xc0,0x48,0x8d,0x04,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 c2}
0010h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0014h vmovupd ymm0,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 41 20}
0019h add r8d,4                               ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 04}
001dh movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
0020h lea rax,[rdx+rax*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 c2}
0024h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0028h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector512<long> src, ref long dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64i](v512x64i,64i~ref,32i)
; vstore_g[64i](v512x64i,64i~ref,32i)[44] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xfd,0x10,0x41,0x20,0x41,0x83,0xc0,0x04,0x49,0x63,0xc0,0x48,0x8d,0x04,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 c2}
0010h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0014h vmovupd ymm0,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 41 20}
0019h add r8d,4                               ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 04}
001dh movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
0020h lea rax,[rdx+rax*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 c2}
0024h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0028h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector512<float> src, ref float dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32f](v512x32f,32f~ref,32i)
; vstore_g[32f](v512x32f,32f~ref,32i)[44] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x82,0xc5,0xfc,0x11,0x00,0xc5,0xfd,0x10,0x41,0x20,0x41,0x83,0xc0,0x08,0x49,0x63,0xc0,0x48,0x8d,0x04,0x82,0xc5,0xfc,0x11,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 82}
0010h vmovups [rax],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 00}
0014h vmovupd ymm0,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 41 20}
0019h add r8d,8                               ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 08}
001dh movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
0020h lea rax,[rdx+rax*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 82}
0024h vmovups [rax],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 00}
0028h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector512<double> src, ref double dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64f](v512x64f,64f~ref,32i)
; vstore_g[64f](v512x64f,64f~ref,32i)[44] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0xc2,0xc5,0xfd,0x11,0x00,0xc5,0xfd,0x10,0x41,0x20,0x41,0x83,0xc0,0x04,0x49,0x63,0xc0,0x48,0x8d,0x04,0xc2,0xc5,0xfd,0x11,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 c2}
0010h vmovupd [rax],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 00}
0014h vmovupd ymm0,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 41 20}
0019h add r8d,4                               ; ADD r/m32, imm8 || o32 83 /0 ib || encoded[4]{41 83 c0 04}
001dh movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
0020h lea rax,[rdx+rax*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 c2}
0024h vmovupd [rax],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 00}
0028h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector128<byte> src, in Block128<byte> dst), hex://vfuncs/generic?vstore#vstore_g[8u](v128x8u,b128x8u~in)
; vstore_g[8u](v128x8u,b128x8u~in)[17] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector128<sbyte> src, in Block128<sbyte> dst), hex://vfuncs/generic?vstore#vstore_g[8i](v128x8i,b128x8i~in)
; vstore_g[8i](v128x8i,b128x8i~in)[17] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector128<ushort> src, in Block128<ushort> dst), hex://vfuncs/generic?vstore#vstore_g[16u](v128x16u,b128x16u~in)
; vstore_g[16u](v128x16u,b128x16u~in)[17] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector128<short> src, in Block128<short> dst), hex://vfuncs/generic?vstore#vstore_g[16i](v128x16i,b128x16i~in)
; vstore_g[16i](v128x16i,b128x16i~in)[17] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector128<uint> src, in Block128<uint> dst), hex://vfuncs/generic?vstore#vstore_g[32u](v128x32u,b128x32u~in)
; vstore_g[32u](v128x32u,b128x32u~in)[17] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector128<int> src, in Block128<int> dst), hex://vfuncs/generic?vstore#vstore_g[32i](v128x32i,b128x32i~in)
; vstore_g[32i](v128x32i,b128x32i~in)[17] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector128<ulong> src, in Block128<ulong> dst), hex://vfuncs/generic?vstore#vstore_g[64u](v128x64u,b128x64u~in)
; vstore_g[64u](v128x64u,b128x64u~in)[17] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector128<long> src, in Block128<long> dst), hex://vfuncs/generic?vstore#vstore_g[64i](v128x64i,b128x64i~in)
; vstore_g[64i](v128x64i,b128x64i~in)[17] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector128<float> src, in Block128<float> dst), hex://vfuncs/generic?vstore#vstore_g[32f](v128x32f,b128x32f~in)
; vstore_g[32f](v128x32f,b128x32f~in)[17] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0xc5,0xf8,0x11,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch vmovups [rax],xmm0                      ; VMOVUPS xmm2/m128, xmm1 || VEX.128.0F.WIG 11 /r || encoded[4]{c5 f8 11 00}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector128<double> src, in Block128<double> dst), hex://vfuncs/generic?vstore#vstore_g[64f](v128x64f,b128x64f~in)
; vstore_g[64f](v128x64f,b128x64f~in)[17] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x11,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000ch vmovupd [rax],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 00}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector128<byte> src, in Block128<byte> dst, int block), hex://vfuncs/generic?vstore#vstore_g[8u](v128x8u,b128x8u~in,32i)
; vstore_g[8u](v128x8u,b128x8u~in,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x04,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x03,0xc2,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,4                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 04}
000ch vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
0016h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector128<sbyte> src, in Block128<sbyte> dst, int block), hex://vfuncs/generic?vstore#vstore_g[8i](v128x8i,b128x8i~in,32i)
; vstore_g[8i](v128x8i,b128x8i~in,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x04,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x03,0xc2,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,4                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 04}
000ch vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
0016h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector128<ushort> src, in Block128<ushort> dst, int block), hex://vfuncs/generic?vstore#vstore_g[16u](v128x16u,b128x16u~in,32i)
; vstore_g[16u](v128x16u,b128x16u~in,32i)[28] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x03,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x50,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,3                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 03}
000ch vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 50}
0017h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
001bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector128<short> src, in Block128<short> dst, int block), hex://vfuncs/generic?vstore#vstore_g[16i](v128x16i,b128x16i~in,32i)
; vstore_g[16i](v128x16i,b128x16i~in,32i)[28] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x03,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x50,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,3                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 03}
000ch vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 50}
0017h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
001bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector128<uint> src, in Block128<uint> dst, int block), hex://vfuncs/generic?vstore#vstore_g[32u](v128x32u,b128x32u~in,32i)
; vstore_g[32u](v128x32u,b128x32u~in,32i)[28] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,2                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 02}
000ch vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0017h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
001bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector128<int> src, in Block128<int> dst, int block), hex://vfuncs/generic?vstore#vstore_g[32i](v128x32i,b128x32i~in,32i)
; vstore_g[32i](v128x32i,b128x32i~in,32i)[28] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,2                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 02}
000ch vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0017h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
001bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector128<ulong> src, in Block128<ulong> dst, int block), hex://vfuncs/generic?vstore#vstore_g[64u](v128x64u,b128x64u~in,32i)
; vstore_g[64u](v128x64u,b128x64u~in,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xd1,0xe0,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,1                               ; SHL r/m32, 1 || o32 D1 /4 || encoded[3]{41 d1 e0}
000bh vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000fh movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0012h lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0016h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector128<long> src, in Block128<long> dst, int block), hex://vfuncs/generic?vstore#vstore_g[64i](v128x64i,b128x64i~in,32i)
; vstore_g[64i](v128x64i,b128x64i~in,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xd1,0xe0,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,1                               ; SHL r/m32, 1 || o32 D1 /4 || encoded[3]{41 d1 e0}
000bh vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000fh movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0012h lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0016h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector128<float> src, in Block128<float> dst, int block), hex://vfuncs/generic?vstore#vstore_g[32f](v128x32f,b128x32f~in,32i)
; vstore_g[32f](v128x32f,b128x32f~in,32i)[28] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x02,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xf8,0x11,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,2                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 02}
000ch vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0017h vmovups [rax],xmm0                      ; VMOVUPS xmm2/m128, xmm1 || VEX.128.0F.WIG 11 /r || encoded[4]{c5 f8 11 00}
001bh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector128<double> src, in Block128<double> dst, int block), hex://vfuncs/generic?vstore#vstore_g[64f](v128x64f,b128x64f~in,32i)
; vstore_g[64f](v128x64f,b128x64f~in,32i)[27] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xd1,0xe0,0xc5,0xf9,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xf9,0x11,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,1                               ; SHL r/m32, 1 || o32 D1 /4 || encoded[3]{41 d1 e0}
000bh vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000fh movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0012h lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0016h vmovupd [rax],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 00}
001ah ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector256<byte> src, in Block256<byte> dst), hex://vfuncs/generic?vstore#vstore_g[8u](v256x8u,b256x8u~in)
; vstore_g[8u](v256x8u,b256x8u~in)[20] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector256<sbyte> src, in Block256<sbyte> dst), hex://vfuncs/generic?vstore#vstore_g[8i](v256x8i,b256x8i~in)
; vstore_g[8i](v256x8i,b256x8i~in)[20] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector256<ushort> src, in Block256<ushort> dst), hex://vfuncs/generic?vstore#vstore_g[16u](v256x16u,b256x16u~in)
; vstore_g[16u](v256x16u,b256x16u~in)[20] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector256<short> src, in Block256<short> dst), hex://vfuncs/generic?vstore#vstore_g[16i](v256x16i,b256x16i~in)
; vstore_g[16i](v256x16i,b256x16i~in)[20] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector256<uint> src, in Block256<uint> dst), hex://vfuncs/generic?vstore#vstore_g[32u](v256x32u,b256x32u~in)
; vstore_g[32u](v256x32u,b256x32u~in)[20] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector256<int> src, in Block256<int> dst), hex://vfuncs/generic?vstore#vstore_g[32i](v256x32i,b256x32i~in)
; vstore_g[32i](v256x32i,b256x32i~in)[20] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector256<ulong> src, in Block256<ulong> dst), hex://vfuncs/generic?vstore#vstore_g[64u](v256x64u,b256x64u~in)
; vstore_g[64u](v256x64u,b256x64u~in)[20] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector256<long> src, in Block256<long> dst), hex://vfuncs/generic?vstore#vstore_g[64i](v256x64i,b256x64i~in)
; vstore_g[64i](v256x64i,b256x64i~in)[20] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector256<float> src, in Block256<float> dst), hex://vfuncs/generic?vstore#vstore_g[32f](v256x32f,b256x32f~in)
; vstore_g[32f](v256x32f,b256x32f~in)[20] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfc,0x11,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovups [rax],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 00}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector256<double> src, in Block256<double> dst), hex://vfuncs/generic?vstore#vstore_g[64f](v256x64f,b256x64f~in)
; vstore_g[64f](v256x64f,b256x64f~in)[20] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd [rax],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 00}
0010h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector512<byte> src, in Block512<byte> dst), hex://vfuncs/generic?vstore#vstore_g[8u](v512x8u,b512x8u~in)
; vstore_g[8u](v512x8u,b512x8u~in)[36] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0014h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0018h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
001ch vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0020h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0023h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector512<sbyte> src, in Block512<sbyte> dst), hex://vfuncs/generic?vstore#vstore_g[8i](v512x8i,b512x8i~in)
; vstore_g[8i](v512x8i,b512x8i~in)[36] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0014h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0018h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
001ch vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0020h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0023h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector512<ushort> src, in Block512<ushort> dst), hex://vfuncs/generic?vstore#vstore_g[16u](v512x16u,b512x16u~in)
; vstore_g[16u](v512x16u,b512x16u~in)[36] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0014h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0018h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
001ch vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0020h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0023h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector512<short> src, in Block512<short> dst), hex://vfuncs/generic?vstore#vstore_g[16i](v512x16i,b512x16i~in)
; vstore_g[16i](v512x16i,b512x16i~in)[36] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0014h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0018h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
001ch vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0020h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0023h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector512<uint> src, in Block512<uint> dst), hex://vfuncs/generic?vstore#vstore_g[32u](v512x32u,b512x32u~in)
; vstore_g[32u](v512x32u,b512x32u~in)[36] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0014h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0018h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
001ch vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0020h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0023h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector512<int> src, in Block512<int> dst), hex://vfuncs/generic?vstore#vstore_g[32i](v512x32i,b512x32i~in)
; vstore_g[32i](v512x32i,b512x32i~in)[36] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0014h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0018h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
001ch vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0020h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0023h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector512<ulong> src, in Block512<ulong> dst), hex://vfuncs/generic?vstore#vstore_g[64u](v512x64u,b512x64u~in)
; vstore_g[64u](v512x64u,b512x64u~in)[36] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0014h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0018h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
001ch vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0020h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0023h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector512<long> src, in Block512<long> dst), hex://vfuncs/generic?vstore#vstore_g[64i](v512x64i,b512x64i~in)
; vstore_g[64i](v512x64i,b512x64i~in)[36] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0014h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0018h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
001ch vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0020h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0023h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector512<float> src, in Block512<float> dst), hex://vfuncs/generic?vstore#vstore_g[32f](v512x32f,b512x32f~in)
; vstore_g[32f](v512x32f,b512x32f~in)[36] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x48,0x8b,0xd0,0xc5,0xfc,0x11,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfc,0x11,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0014h vmovups [rdx],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 02}
0018h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
001ch vmovups [rax],ymm1                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 08}
0020h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0023h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector512<double> src, in Block512<double> dst), hex://vfuncs/generic?vstore#vstore_g[64f](v512x64f,b512x64f~in)
; vstore_g[64f](v512x64f,b512x64f~in)[36] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x48,0x8b,0xd0,0xc5,0xfd,0x11,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfd,0x11,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000ch vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0011h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0014h vmovupd [rdx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 02}
0018h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
001ch vmovupd [rax],ymm1                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 08}
0020h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0023h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector256<byte> src, in Block256<byte> dst, int block), hex://vfuncs/generic?vstore#vstore_g[8u](v256x8u,b256x8u~in,32i)
; vstore_g[8u](v256x8u,b256x8u~in,32i)[30] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x05,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x03,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,5                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 05}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
0016h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
001ah vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector256<sbyte> src, in Block256<sbyte> dst, int block), hex://vfuncs/generic?vstore#vstore_g[8i](v256x8i,b256x8i~in,32i)
; vstore_g[8i](v256x8i,b256x8i~in,32i)[30] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x05,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x03,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,5                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 05}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
0016h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
001ah vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector256<ushort> src, in Block256<ushort> dst, int block), hex://vfuncs/generic?vstore#vstore_g[16u](v256x16u,b256x16u~in,32i)
; vstore_g[16u](v256x16u,b256x16u~in,32i)[31] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x04,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x50,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,4                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 04}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 50}
0017h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
001bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector256<short> src, in Block256<short> dst, int block), hex://vfuncs/generic?vstore#vstore_g[16i](v256x16i,b256x16i~in,32i)
; vstore_g[16i](v256x16i,b256x16i~in,32i)[31] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x04,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x50,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,4                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 04}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 50}
0017h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
001bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector256<uint> src, in Block256<uint> dst, int block), hex://vfuncs/generic?vstore#vstore_g[32u](v256x32u,b256x32u~in,32i)
; vstore_g[32u](v256x32u,b256x32u~in,32i)[31] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x03,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,3                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 03}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0017h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
001bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector256<int> src, in Block256<int> dst, int block), hex://vfuncs/generic?vstore#vstore_g[32i](v256x32i,b256x32i~in,32i)
; vstore_g[32i](v256x32i,b256x32i~in,32i)[31] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x03,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,3                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 03}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0017h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
001bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector256<ulong> src, in Block256<ulong> dst, int block), hex://vfuncs/generic?vstore#vstore_g[64u](v256x64u,b256x64u~in,32i)
; vstore_g[64u](v256x64u,b256x64u~in,32i)[31] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,2                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 02}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0017h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
001bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector256<long> src, in Block256<long> dst, int block), hex://vfuncs/generic?vstore#vstore_g[64i](v256x64i,b256x64i~in,32i)
; vstore_g[64i](v256x64i,b256x64i~in,32i)[31] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,2                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 02}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0017h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
001bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector256<float> src, in Block256<float> dst, int block), hex://vfuncs/generic?vstore#vstore_g[32f](v256x32f,b256x32f~in,32i)
; vstore_g[32f](v256x32f,b256x32f~in,32i)[31] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x03,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0xc5,0xfc,0x11,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,3                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 03}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
0017h vmovups [rax],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 00}
001bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector256<double> src, in Block256<double> dst, int block), hex://vfuncs/generic?vstore#vstore_g[64f](v256x64f,b256x64f~in,32i)
; vstore_g[64f](v256x64f,b256x64f~in,32i)[31] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x02,0xc5,0xfd,0x10,0x01,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0xc5,0xfd,0x11,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,2                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 02}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0013h lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
0017h vmovupd [rax],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 00}
001bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
001eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector512<byte> src, in Block512<byte> dst, int block), hex://vfuncs/generic?vstore#vstore_g[8u](v512x8u,b512x8u~in,32i)
; vstore_g[8u](v512x8u,b512x8u~in,32i)[46] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x06,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x03,0xc2,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,6                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 06}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0015h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0018h add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
001bh mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
001eh vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0022h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0026h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002ah vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector512<sbyte> src, in Block512<sbyte> dst, int block), hex://vfuncs/generic?vstore#vstore_g[8i](v512x8i,b512x8i~in,32i)
; vstore_g[8i](v512x8i,b512x8i~in,32i)[46] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x06,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x03,0xc2,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,6                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 06}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0015h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0018h add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
001bh mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
001eh vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0022h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0026h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002ah vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector512<ushort> src, in Block512<ushort> dst, int block), hex://vfuncs/generic?vstore#vstore_g[16u](v512x16u,b512x16u~in,32i)
; vstore_g[16u](v512x16u,b512x16u~in,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x05,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x04,0x50,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,5                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 05}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0015h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0018h lea rax,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 50}
001ch mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
001fh vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0023h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0027h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector512<short> src, in Block512<short> dst, int block), hex://vfuncs/generic?vstore#vstore_g[16i](v512x16i,b512x16i~in,32i)
; vstore_g[16i](v512x16i,b512x16i~in,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x05,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x04,0x50,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,5                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 05}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0015h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0018h lea rax,[rax+rdx*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 50}
001ch mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
001fh vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0023h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0027h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector512<uint> src, in Block512<uint> dst, int block), hex://vfuncs/generic?vstore#vstore_g[32u](v512x32u,b512x32u~in,32i)
; vstore_g[32u](v512x32u,b512x32u~in,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x04,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,4                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 04}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0015h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0018h lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
001ch mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
001fh vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0023h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0027h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector512<int> src, in Block512<int> dst, int block), hex://vfuncs/generic?vstore#vstore_g[32i](v512x32i,b512x32i~in,32i)
; vstore_g[32i](v512x32i,b512x32i~in,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x04,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,4                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 04}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0015h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0018h lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
001ch mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
001fh vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0023h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0027h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector512<ulong> src, in Block512<ulong> dst, int block), hex://vfuncs/generic?vstore#vstore_g[64u](v512x64u,b512x64u~in,32i)
; vstore_g[64u](v512x64u,b512x64u~in,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x03,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,3                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 03}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0015h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0018h lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
001ch mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
001fh vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0023h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0027h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector512<long> src, in Block512<long> dst, int block), hex://vfuncs/generic?vstore#vstore_g[64i](v512x64i,b512x64i~in,32i)
; vstore_g[64i](v512x64i,b512x64i~in,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x03,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,3                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 03}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0015h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0018h lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
001ch mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
001fh vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
0023h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0027h vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector512<float> src, in Block512<float> dst, int block), hex://vfuncs/generic?vstore#vstore_g[32f](v512x32f,b512x32f~in,32i)
; vstore_g[32f](v512x32f,b512x32f~in,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x04,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x04,0x90,0x48,0x8b,0xd0,0xc5,0xfc,0x11,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfc,0x11,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,4                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 04}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0015h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0018h lea rax,[rax+rdx*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 90}
001ch mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
001fh vmovups [rdx],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 02}
0023h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0027h vmovups [rax],ymm1                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector512<double> src, in Block512<double> dst, int block), hex://vfuncs/generic?vstore#vstore_g[64f](v512x64f,b512x64f~in,32i)
; vstore_g[64f](v512x64f,b512x64f~in,32i)[47] = {0xc5,0xf8,0x77,0x66,0x90,0x48,0x8b,0x02,0x41,0xc1,0xe0,0x03,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x10,0x49,0x20,0x49,0x63,0xd0,0x48,0x8d,0x04,0xd0,0x48,0x8b,0xd0,0xc5,0xfd,0x11,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfd,0x11,0x08,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h mov rax,[rdx]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 02}
0008h shl r8d,3                               ; SHL r/m32, imm8 || o32 C1 /4 ib || encoded[4]{41 c1 e0 03}
000ch vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0010h vmovupd ymm1,[rcx+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 49 20}
0015h movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0018h lea rax,[rax+rdx*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 d0}
001ch mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
001fh vmovupd [rdx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 02}
0023h add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0027h vmovupd [rax],ymm1                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 08}
002bh vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
002eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector128<byte> src, ref byte dst, int offset), hex://vfuncs/generic?vstore#vstore_g[8u](v128x8u,8u~ref,32i)
; vstore_g[8u](v128x8u,8u~ref,32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0x49,0x63,0xc0,0x48,0x03,0xc2,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
000fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector128<sbyte> src, ref sbyte dst, int offset), hex://vfuncs/generic?vstore#vstore_g[8i](v128x8i,8i~ref,32i)
; vstore_g[8i](v128x8i,8i~ref,32i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0x49,0x63,0xc0,0x48,0x03,0xc2,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
000fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector128<ushort> src, ref ushort dst, int offset), hex://vfuncs/generic?vstore#vstore_g[16u](v128x16u,16u~ref,32i)
; vstore_g[16u](v128x16u,16u~ref,32i)[21] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x42,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 42}
0010h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0014h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector128<short> src, ref short dst, int offset), hex://vfuncs/generic?vstore#vstore_g[16i](v128x16i,16i~ref,32i)
; vstore_g[16i](v128x16i,16i~ref,32i)[21] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x42,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 42}
0010h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0014h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector128<uint> src, ref uint dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32u](v128x32u,32u~ref,32i)
; vstore_g[32u](v128x32u,32u~ref,32i)[21] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x82,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 82}
0010h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0014h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector128<int> src, ref int dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32i](v128x32i,32i~ref,32i)
; vstore_g[32i](v128x32i,32i~ref,32i)[21] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x82,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 82}
0010h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0014h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector128<ulong> src, ref ulong dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64u](v128x64u,64u~ref,32i)
; vstore_g[64u](v128x64u,64u~ref,32i)[21] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0xc2,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 c2}
0010h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0014h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector128<long> src, ref long dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64i](v128x64i,64i~ref,32i)
; vstore_g[64i](v128x64i,64i~ref,32i)[21] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0xc2,0xc5,0xfa,0x7f,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 c2}
0010h vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0014h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector128<float> src, ref float dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32f](v128x32f,32f~ref,32i)
; vstore_g[32f](v128x32f,32f~ref,32i)[21] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x82,0xc5,0xf8,0x11,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 82}
0010h vmovups [rax],xmm0                      ; VMOVUPS xmm2/m128, xmm1 || VEX.128.0F.WIG 11 /r || encoded[4]{c5 f8 11 00}
0014h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector128<double> src, ref double dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64f](v128x64f,64f~ref,32i)
; vstore_g[64f](v128x64f,64f~ref,32i)[21] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0xc2,0xc5,0xf9,0x11,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 c2}
0010h vmovupd [rax],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 00}
0014h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<byte>(Vector256<byte> src, ref byte dst, int offset), hex://vfuncs/generic?vstore#vstore_g[8u](v256x8u,8u~ref,32i)
; vstore_g[8u](v256x8u,8u~ref,32i)[23] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x03,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
000fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0013h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0016h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<sbyte>(Vector256<sbyte> src, ref sbyte dst, int offset), hex://vfuncs/generic?vstore#vstore_g[8i](v256x8i,8i~ref,32i)
; vstore_g[8i](v256x8i,8i~ref,32i)[23] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x03,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch add rax,rdx                             ; ADD r64, r/m64 || REX.W 03 /r || encoded[3]{48 03 c2}
000fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0013h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0016h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ushort>(Vector256<ushort> src, ref ushort dst, int offset), hex://vfuncs/generic?vstore#vstore_g[16u](v256x16u,16u~ref,32i)
; vstore_g[16u](v256x16u,16u~ref,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x42,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 42}
0010h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0014h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<short>(Vector256<short> src, ref short dst, int offset), hex://vfuncs/generic?vstore#vstore_g[16i](v256x16i,16i~ref,32i)
; vstore_g[16i](v256x16i,16i~ref,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x42,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*2]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 42}
0010h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0014h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<uint>(Vector256<uint> src, ref uint dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32u](v256x32u,32u~ref,32i)
; vstore_g[32u](v256x32u,32u~ref,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x82,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 82}
0010h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0014h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<int>(Vector256<int> src, ref int dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32i](v256x32i,32i~ref,32i)
; vstore_g[32i](v256x32i,32i~ref,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x82,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 82}
0010h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0014h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<ulong>(Vector256<ulong> src, ref ulong dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64u](v256x64u,64u~ref,32i)
; vstore_g[64u](v256x64u,64u~ref,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 c2}
0010h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0014h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<long>(Vector256<long> src, ref long dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64i](v256x64i,64i~ref,32i)
; vstore_g[64i](v256x64i,64i~ref,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0xc2,0xc5,0xfe,0x7f,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 c2}
0010h vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0014h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<float>(Vector256<float> src, ref float dst, int offset), hex://vfuncs/generic?vstore#vstore_g[32f](v256x32f,32f~ref,32i)
; vstore_g[32f](v256x32f,32f~ref,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0x82,0xc5,0xfc,0x11,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*4]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 82}
0010h vmovups [rax],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 00}
0014h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; void vstore<double>(Vector256<double> src, ref double dst, int offset), hex://vfuncs/generic?vstore#vstore_g[64f](v256x64f,64f~ref,32i)
; vstore_g[64f](v256x64f,64f~ref,32i)[24] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xfd,0x10,0x01,0x49,0x63,0xc0,0x48,0x8d,0x04,0xc2,0xc5,0xfd,0x11,0x00,0xc5,0xf8,0x77,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
0009h movsxd rax,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 c0}
000ch lea rax,[rdx+rax*8]                     ; LEA r64, m || REX.W 8D /r || encoded[4]{48 8d 04 c2}
0010h vmovupd [rax],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 00}
0014h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0017h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block128<byte> block<byte>(Vector128<byte> src), hex://vfuncs/generic?block#block_g[8u](v128x8u)
; block_g[8u](v128x8u)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x6d,0x06,0xbe,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x50,0x29,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c82c3b90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 6d 06 be ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 50 29 b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block128<sbyte> block<sbyte>(Vector128<sbyte> src), hex://vfuncs/generic?block#block_g[8i](v128x8i)
; block_g[8i](v128x8i)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x3d,0x06,0xbe,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0xb0,0x28,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c82c3c00h                      ; CALL rel32 || E8 cd || encoded[5]{e8 3d 06 be ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b0 28 b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block128<ushort> block<ushort>(Vector128<ushort> src), hex://vfuncs/generic?block#block_g[16u](v128x16u)
; block_g[16u](v128x16u)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x0d,0x06,0xbe,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x10,0x28,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c82c3c70h                      ; CALL rel32 || E8 cd || encoded[5]{e8 0d 06 be ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 10 28 b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block128<short> block<short>(Vector128<short> src), hex://vfuncs/generic?block#block_g[16i](v128x16i)
; block_g[16i](v128x16i)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xdd,0x05,0xbe,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x70,0x27,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c82c3ce0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 dd 05 be ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 70 27 b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block128<uint> block<uint>(Vector128<uint> src), hex://vfuncs/generic?block#block_g[32u](v128x32u)
; block_g[32u](v128x32u)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0xad,0x05,0xbe,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0xd0,0x26,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c82c3d50h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ad 05 be ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d0 26 b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block128<int> block<int>(Vector128<int> src), hex://vfuncs/generic?block#block_g[32i](v128x32i)
; block_g[32i](v128x32i)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x7d,0x05,0xbe,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x30,0x26,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c82c3dc0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 7d 05 be ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 30 26 b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block128<ulong> block<ulong>(Vector128<ulong> src), hex://vfuncs/generic?block#block_g[64u](v128x64u)
; block_g[64u](v128x64u)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x4d,0x05,0xbe,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x90,0x25,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c82c3e30h                      ; CALL rel32 || E8 cd || encoded[5]{e8 4d 05 be ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 90 25 b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block128<long> block<long>(Vector128<long> src), hex://vfuncs/generic?block#block_g[64i](v128x64i)
; block_g[64i](v128x64i)[125] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x1d,0x05,0xbe,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xfa,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0xf0,0x24,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c82c3ea0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 1d 05 be ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
005fh vmovdqu xmmword ptr [rax],xmm0          ; VMOVDQU xmm2/m128, xmm1 || VEX.128.F3.0F.WIG 7F /r || encoded[4]{c5 fa 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f0 24 b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
0079h pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007ah pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007bh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007ch ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block128<float> block<float>(Vector128<float> src), hex://vfuncs/generic?block#block_g[32f](v128x32f)
; block_g[32f](v128x32f)[126] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0xc5,0xe0,0x57,0xdb,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xec,0x04,0xbe,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xf8,0x11,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x4f,0x24,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h vxorps xmm3,xmm3,xmm3                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 e0 57 db}
0049h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004fh call 7ff7c82c3f10h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ec 04 be ff}
0054h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0059h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005ch vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
0060h vmovups [rax],xmm0                      ; VMOVUPS xmm2/m128, xmm1 || VEX.128.0F.WIG 11 /r || encoded[4]{c5 f8 11 00}
0064h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0067h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006ch call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 4f 24 b8 5e}
0071h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0073h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0076h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ah pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007bh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007ch pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block128<double> block<double>(Vector128<double> src), hex://vfuncs/generic?block#block_g[64f](v128x64f)
; block_g[64f](v128x64f)[126] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0xc5,0xe0,0x57,0xdb,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xbc,0x04,0xbe,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xf9,0x10,0x06,0xc5,0xf9,0x11,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0xaf,0x23,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h vxorps xmm3,xmm3,xmm3                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 e0 57 db}
0049h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004fh call 7ff7c82c3f80h                      ; CALL rel32 || E8 cd || encoded[5]{e8 bc 04 be ff}
0054h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0059h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005ch vmovupd xmm0,[rsi]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 06}
0060h vmovupd [rax],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 00}
0064h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0067h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006ch call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 af 23 b8 5e}
0071h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0073h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0076h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ah pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007bh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007ch pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block256<byte> block<byte>(Vector256<byte> src), hex://vfuncs/generic?block#block_g[8u](v256x8u)
; block_g[8u](v256x8u)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x1d,0xc9,0xd1,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x10,0x23,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c8400480h                      ; CALL rel32 || E8 cd || encoded[5]{e8 1d c9 d1 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 10 23 b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block256<sbyte> block<sbyte>(Vector256<sbyte> src), hex://vfuncs/generic?block#block_g[8i](v256x8i)
; block_g[8i](v256x8i)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xdd,0xc4,0xd1,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x60,0x1e,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c84004f0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 dd c4 d1 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 60 1e b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block256<ushort> block<ushort>(Vector256<ushort> src), hex://vfuncs/generic?block#block_g[16u](v256x16u)
; block_g[16u](v256x16u)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xad,0xc4,0xd1,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0xc0,0x1d,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c8400560h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ad c4 d1 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c0 1d b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block256<short> block<short>(Vector256<short> src), hex://vfuncs/generic?block#block_g[16i](v256x16i)
; block_g[16i](v256x16i)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x7d,0xc4,0xd1,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x20,0x1d,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c84005d0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 7d c4 d1 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 20 1d b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block256<uint> block<uint>(Vector256<uint> src), hex://vfuncs/generic?block#block_g[32u](v256x32u)
; block_g[32u](v256x32u)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x4d,0xc4,0xd1,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x80,0x1c,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c8400640h                      ; CALL rel32 || E8 cd || encoded[5]{e8 4d c4 d1 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 80 1c b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block256<int> block<int>(Vector256<int> src), hex://vfuncs/generic?block#block_g[32i](v256x32i)
; block_g[32i](v256x32i)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x1d,0xc4,0xd1,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0xe0,0x1b,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c84006b0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 1d c4 d1 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e0 1b b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block256<ulong> block<ulong>(Vector256<ulong> src), hex://vfuncs/generic?block#block_g[64u](v256x64u)
; block_g[64u](v256x64u)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0xed,0xc3,0xd1,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x40,0x1b,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c8400720h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ed c3 d1 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 40 1b b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block256<long> block<long>(Vector256<long> src), hex://vfuncs/generic?block#block_g[64i](v256x64i)
; block_g[64i](v256x64i)[128] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0xbd,0xc3,0xd1,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfe,0x7f,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0xa0,0x1a,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c8400790h                      ; CALL rel32 || E8 cd || encoded[5]{e8 bd c3 d1 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovdqu ymmword ptr [rax],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 00}
0063h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0066h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a0 1a b8 5e}
0070h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0072h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0075h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0078h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
007fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block256<float> block<float>(Vector256<float> src), hex://vfuncs/generic?block#block_g[32f](v256x32f)
; block_g[32f](v256x32f)[129] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0xc5,0xe0,0x57,0xdb,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x8c,0xc3,0xd1,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfc,0x11,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0xff,0x19,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h vxorps xmm3,xmm3,xmm3                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 e0 57 db}
0049h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004fh call 7ff7c8400800h                      ; CALL rel32 || E8 cd || encoded[5]{e8 8c c3 d1 ff}
0054h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0059h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005ch vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
0060h vmovups [rax],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 00}
0064h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0067h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006ch call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ff 19 b8 5e}
0071h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0073h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0076h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0079h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007dh pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007eh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007fh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
0080h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block256<double> block<double>(Vector256<double> src), hex://vfuncs/generic?block#block_g[64f](v256x64f)
; block_g[64f](v256x64f)[129] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0xc5,0xe0,0x57,0xdb,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x5c,0xc3,0xd1,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x11,0x00,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x5f,0x19,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h vxorps xmm3,xmm3,xmm3                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 e0 57 db}
0049h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004fh call 7ff7c8400870h                      ; CALL rel32 || E8 cd || encoded[5]{e8 5c c3 d1 ff}
0054h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0059h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005ch vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
0060h vmovupd [rax],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 00}
0064h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0067h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
006ch call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 5f 19 b8 5e}
0071h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0073h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0076h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0079h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
007dh pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
007eh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
007fh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
0080h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block512<byte> block<byte>(Vector512<byte> src), hex://vfuncs/generic?block#block_g[8u](v512x8u)
; block_g[8u](v512x8u)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x2d,0xc3,0xd1,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0xb0,0x18,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c84008e0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 2d c3 d1 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0076h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b0 18 b8 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block512<sbyte> block<sbyte>(Vector512<sbyte> src), hex://vfuncs/generic?block#block_g[8i](v512x8i)
; block_g[8i](v512x8i)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xed,0xc2,0xd1,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x00,0x18,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c8400950h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ed c2 d1 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0076h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 00 18 b8 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block512<ushort> block<ushort>(Vector512<ushort> src), hex://vfuncs/generic?block#block_g[16u](v512x16u)
; block_g[16u](v512x16u)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xad,0xc2,0xd1,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x50,0x17,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c84009c0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ad c2 d1 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0076h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 50 17 b8 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block512<short> block<short>(Vector512<short> src), hex://vfuncs/generic?block#block_g[16i](v512x16i)
; block_g[16i](v512x16i)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x45,0x33,0xc9,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x6d,0xc2,0xd1,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0xa0,0x16,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
0048h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004eh call 7ff7c8400a30h                      ; CALL rel32 || E8 cd || encoded[5]{e8 6d c2 d1 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0076h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a0 16 b8 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block512<uint> block<uint>(Vector512<uint> src), hex://vfuncs/generic?block#block_g[32u](v512x32u)
; block_g[32u](v512x32u)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x2d,0xc2,0xd1,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0xf0,0x15,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c8400aa0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 2d c2 d1 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0076h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f0 15 b8 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block512<int> block<int>(Vector512<int> src), hex://vfuncs/generic?block#block_g[32i](v512x32i)
; block_g[32i](v512x32i)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0xed,0xc1,0xd1,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x40,0x15,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c8400b10h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ed c1 d1 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0076h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 40 15 b8 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block512<ulong> block<ulong>(Vector512<ulong> src), hex://vfuncs/generic?block#block_g[64u](v512x64u)
; block_g[64u](v512x64u)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0xad,0xc1,0xd1,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x90,0x14,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c8400b80h                      ; CALL rel32 || E8 cd || encoded[5]{e8 ad c1 d1 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0076h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 90 14 b8 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block512<long> block<long>(Vector512<long> src), hex://vfuncs/generic?block#block_g[64i](v512x64i)
; block_g[64i](v512x64i)[144] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0x41,0xb8,0x01,0x00,0x00,0x00,0x45,0x33,0xc9,0xe8,0x6d,0xc1,0xd1,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfe,0x7f,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfe,0x7f,0x08,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0xe0,0x13,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004bh xor r9d,r9d                             ; XOR r32, r/m32 || o32 33 /r || encoded[3]{45 33 c9}
004eh call 7ff7c8400bf0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 6d c1 d1 ff}
0053h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0058h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005bh vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
005fh vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0064h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0067h vmovdqu ymmword ptr [rdx],ymm0          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 02}
006bh add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
006fh vmovdqu ymmword ptr [rax],ymm1          ; VMOVDQU ymm2/m256, ymm1 || VEX.256.F3.0F.WIG 7F /r || encoded[4]{c5 fe 7f 08}
0073h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0076h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
007bh call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e0 13 b8 5e}
0080h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0082h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0085h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0088h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008ch pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008dh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008eh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
008fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block512<float> block<float>(Vector512<float> src), hex://vfuncs/generic?block#block_g[32f](v512x32f)
; block_g[32f](v512x32f)[145] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0xc5,0xe0,0x57,0xdb,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0x1c,0xbd,0xd1,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfc,0x11,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfc,0x11,0x08,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x1f,0x0f,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h vxorps xmm3,xmm3,xmm3                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 e0 57 db}
0049h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004fh call 7ff7c8400c60h                      ; CALL rel32 || E8 cd || encoded[5]{e8 1c bd d1 ff}
0054h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0059h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005ch vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
0060h vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0065h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0068h vmovups [rdx],ymm0                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 02}
006ch add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0070h vmovups [rax],ymm1                      ; VMOVUPS ymm2/m256, ymm1 || VEX.256.0F.WIG 11 /r || encoded[4]{c5 fc 11 08}
0074h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0077h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
007ch call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 1f 0f b8 5e}
0081h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0083h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0086h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0089h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008dh pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008eh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008fh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
0090h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Block512<double> block<double>(Vector512<double> src), hex://vfuncs/generic?block#block_g[64f](v512x64f)
; block_g[64f](v512x64f)[145] = {0x57,0x56,0x53,0x48,0x83,0xec,0x50,0xc5,0xf8,0x77,0x33,0xc0,0x48,0x89,0x44,0x24,0x40,0x48,0x89,0x44,0x24,0x48,0x48,0x89,0x44,0x24,0x30,0x48,0x8b,0xd9,0x48,0x8b,0xf2,0xc6,0x44,0x24,0x30,0x00,0x48,0x0f,0xbe,0x4c,0x24,0x30,0x88,0x4c,0x24,0x38,0x48,0x0f,0xbe,0x4c,0x24,0x38,0x88,0x4c,0x24,0x28,0x48,0x8d,0x4c,0x24,0x40,0x48,0x0f,0xbe,0x54,0x24,0x28,0xc5,0xe0,0x57,0xdb,0x41,0xb8,0x01,0x00,0x00,0x00,0xe8,0xdc,0xbc,0xd1,0xff,0x48,0x8d,0x44,0x24,0x40,0x48,0x8b,0x00,0xc5,0xfd,0x10,0x06,0xc5,0xfd,0x10,0x4e,0x20,0x48,0x8b,0xd0,0xc5,0xfd,0x11,0x02,0x48,0x83,0xc0,0x20,0xc5,0xfd,0x11,0x08,0x48,0x8b,0xfb,0x48,0x8d,0x74,0x24,0x40,0xe8,0x6f,0x0e,0xb8,0x5e,0x48,0xa5,0x48,0x8b,0xc3,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x50,0x5b,0x5e,0x5f,0xc3}
; TermCode = CTC_RET_INTR
0000h push rdi                                ; PUSH r64 || 50+ro || encoded[1]{57}
0001h push rsi                                ; PUSH r64 || 50+ro || encoded[1]{56}
0002h push rbx                                ; PUSH r64 || 50+ro || encoded[1]{53}
0003h sub rsp,50h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 50}
0007h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
000ah xor eax,eax                             ; XOR r32, r/m32 || o32 33 /r || encoded[2]{33 c0}
000ch mov [rsp+40h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 40}
0011h mov [rsp+48h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 48}
0016h mov [rsp+30h],rax                       ; MOV r/m64, r64 || REX.W 89 /r || encoded[5]{48 89 44 24 30}
001bh mov rbx,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d9}
001eh mov rsi,rdx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b f2}
0021h mov byte ptr [rsp+30h],0                ; MOV r/m8, imm8 || C6 /0 ib || encoded[5]{c6 44 24 30 00}
0026h movsx rcx,byte ptr [rsp+30h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 30}
002ch mov [rsp+38h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 38}
0030h movsx rcx,byte ptr [rsp+38h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 4c 24 38}
0036h mov [rsp+28h],cl                        ; MOV r/m8, r8 || 88 /r || encoded[4]{88 4c 24 28}
003ah lea rcx,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 40}
003fh movsx rdx,byte ptr [rsp+28h]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[6]{48 0f be 54 24 28}
0045h vxorps xmm3,xmm3,xmm3                   ; VXORPS xmm1, xmm2, xmm3/m128 || VEX.128.0F.WIG 57 /r || encoded[4]{c5 e0 57 db}
0049h mov r8d,1                               ; MOV r32, imm32 || o32 B8+rd id || encoded[6]{41 b8 01 00 00 00}
004fh call 7ff7c8400cd0h                      ; CALL rel32 || E8 cd || encoded[5]{e8 dc bc d1 ff}
0054h lea rax,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 40}
0059h mov rax,[rax]                           ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b 00}
005ch vmovupd ymm0,[rsi]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 06}
0060h vmovupd ymm1,[rsi+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c5 fd 10 4e 20}
0065h mov rdx,rax                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b d0}
0068h vmovupd [rdx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 02}
006ch add rax,20h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c0 20}
0070h vmovupd [rax],ymm1                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 08}
0074h mov rdi,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b fb}
0077h lea rsi,[rsp+40h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 74 24 40}
007ch call 7ff827265e90h                      ; CALL rel32 || E8 cd || encoded[5]{e8 6f 0e b8 5e}
0081h movsq                                   ; MOVSQ || REX.W A5 || encoded[2]{48 a5}
0083h mov rax,rbx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c3}
0086h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0089h add rsp,50h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 50}
008dh pop rbx                                 ; POP r64 || 58+ro || encoded[1]{5b}
008eh pop rsi                                 ; POP r64 || 58+ro || encoded[1]{5e}
008fh pop rdi                                 ; POP r64 || 58+ro || encoded[1]{5f}
0090h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<sbyte> vcast8i<byte>(in Vector128<byte> src), hex://vfuncs/generic?vcast8i#vcast8i_g[8u](v128x8u~in)
; vcast8i_g[8u](v128x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<sbyte> vcast8i<sbyte>(in Vector128<sbyte> src), hex://vfuncs/generic?vcast8i#vcast8i_g[8i](v128x8i~in)
; vcast8i_g[8i](v128x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<sbyte> vcast8i<ushort>(in Vector128<ushort> src), hex://vfuncs/generic?vcast8i#vcast8i_g[16u](v128x16u~in)
; vcast8i_g[16u](v128x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<sbyte> vcast8i<short>(in Vector128<short> src), hex://vfuncs/generic?vcast8i#vcast8i_g[16i](v128x16i~in)
; vcast8i_g[16i](v128x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<sbyte> vcast8i<uint>(in Vector128<uint> src), hex://vfuncs/generic?vcast8i#vcast8i_g[32u](v128x32u~in)
; vcast8i_g[32u](v128x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<sbyte> vcast8i<int>(in Vector128<int> src), hex://vfuncs/generic?vcast8i#vcast8i_g[32i](v128x32i~in)
; vcast8i_g[32i](v128x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<sbyte> vcast8i<ulong>(in Vector128<ulong> src), hex://vfuncs/generic?vcast8i#vcast8i_g[64u](v128x64u~in)
; vcast8i_g[64u](v128x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<sbyte> vcast8i<long>(in Vector128<long> src), hex://vfuncs/generic?vcast8i#vcast8i_g[64i](v128x64i~in)
; vcast8i_g[64i](v128x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<sbyte> vcast8i<float>(in Vector128<float> src), hex://vfuncs/generic?vcast8i#vcast8i_g[32f](v128x32f~in)
; vcast8i_g[32f](v128x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<sbyte> vcast8i<double>(in Vector128<double> src), hex://vfuncs/generic?vcast8i#vcast8i_g[64f](v128x64f~in)
; vcast8i_g[64f](v128x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<byte> vcast8u<byte>(in Vector128<byte> src), hex://vfuncs/generic?vcast8u#vcast8u_g[8u](v128x8u~in)
; vcast8u_g[8u](v128x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<byte> vcast8u<sbyte>(in Vector128<sbyte> src), hex://vfuncs/generic?vcast8u#vcast8u_g[8i](v128x8i~in)
; vcast8u_g[8i](v128x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<byte> vcast8u<ushort>(in Vector128<ushort> src), hex://vfuncs/generic?vcast8u#vcast8u_g[16u](v128x16u~in)
; vcast8u_g[16u](v128x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<byte> vcast8u<short>(in Vector128<short> src), hex://vfuncs/generic?vcast8u#vcast8u_g[16i](v128x16i~in)
; vcast8u_g[16i](v128x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<byte> vcast8u<uint>(in Vector128<uint> src), hex://vfuncs/generic?vcast8u#vcast8u_g[32u](v128x32u~in)
; vcast8u_g[32u](v128x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<byte> vcast8u<int>(in Vector128<int> src), hex://vfuncs/generic?vcast8u#vcast8u_g[32i](v128x32i~in)
; vcast8u_g[32i](v128x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<byte> vcast8u<ulong>(in Vector128<ulong> src), hex://vfuncs/generic?vcast8u#vcast8u_g[64u](v128x64u~in)
; vcast8u_g[64u](v128x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<byte> vcast8u<long>(in Vector128<long> src), hex://vfuncs/generic?vcast8u#vcast8u_g[64i](v128x64i~in)
; vcast8u_g[64i](v128x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<byte> vcast8u<float>(in Vector128<float> src), hex://vfuncs/generic?vcast8u#vcast8u_g[32f](v128x32f~in)
; vcast8u_g[32f](v128x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<byte> vcast8u<double>(in Vector128<double> src), hex://vfuncs/generic?vcast8u#vcast8u_g[64f](v128x64f~in)
; vcast8u_g[64f](v128x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<short> vcast16i<byte>(in Vector128<byte> src), hex://vfuncs/generic?vcast16i#vcast16i_g[8u](v128x8u~in)
; vcast16i_g[8u](v128x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<short> vcast16i<sbyte>(in Vector128<sbyte> src), hex://vfuncs/generic?vcast16i#vcast16i_g[8i](v128x8i~in)
; vcast16i_g[8i](v128x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<short> vcast16i<ushort>(in Vector128<ushort> src), hex://vfuncs/generic?vcast16i#vcast16i_g[16u](v128x16u~in)
; vcast16i_g[16u](v128x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<short> vcast16i<short>(in Vector128<short> src), hex://vfuncs/generic?vcast16i#vcast16i_g[16i](v128x16i~in)
; vcast16i_g[16i](v128x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<short> vcast16i<uint>(in Vector128<uint> src), hex://vfuncs/generic?vcast16i#vcast16i_g[32u](v128x32u~in)
; vcast16i_g[32u](v128x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<short> vcast16i<int>(in Vector128<int> src), hex://vfuncs/generic?vcast16i#vcast16i_g[32i](v128x32i~in)
; vcast16i_g[32i](v128x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<short> vcast16i<ulong>(in Vector128<ulong> src), hex://vfuncs/generic?vcast16i#vcast16i_g[64u](v128x64u~in)
; vcast16i_g[64u](v128x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<short> vcast16i<long>(in Vector128<long> src), hex://vfuncs/generic?vcast16i#vcast16i_g[64i](v128x64i~in)
; vcast16i_g[64i](v128x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<short> vcast16i<float>(in Vector128<float> src), hex://vfuncs/generic?vcast16i#vcast16i_g[32f](v128x32f~in)
; vcast16i_g[32f](v128x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<short> vcast16i<double>(in Vector128<double> src), hex://vfuncs/generic?vcast16i#vcast16i_g[64f](v128x64f~in)
; vcast16i_g[64f](v128x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ushort> vcast16u<byte>(in Vector128<byte> src), hex://vfuncs/generic?vcast16u#vcast16u_g[8u](v128x8u~in)
; vcast16u_g[8u](v128x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ushort> vcast16u<sbyte>(in Vector128<sbyte> src), hex://vfuncs/generic?vcast16u#vcast16u_g[8i](v128x8i~in)
; vcast16u_g[8i](v128x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ushort> vcast16u<ushort>(in Vector128<ushort> src), hex://vfuncs/generic?vcast16u#vcast16u_g[16u](v128x16u~in)
; vcast16u_g[16u](v128x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ushort> vcast16u<short>(in Vector128<short> src), hex://vfuncs/generic?vcast16u#vcast16u_g[16i](v128x16i~in)
; vcast16u_g[16i](v128x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ushort> vcast16u<uint>(in Vector128<uint> src), hex://vfuncs/generic?vcast16u#vcast16u_g[32u](v128x32u~in)
; vcast16u_g[32u](v128x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ushort> vcast16u<int>(in Vector128<int> src), hex://vfuncs/generic?vcast16u#vcast16u_g[32i](v128x32i~in)
; vcast16u_g[32i](v128x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ushort> vcast16u<ulong>(in Vector128<ulong> src), hex://vfuncs/generic?vcast16u#vcast16u_g[64u](v128x64u~in)
; vcast16u_g[64u](v128x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ushort> vcast16u<long>(in Vector128<long> src), hex://vfuncs/generic?vcast16u#vcast16u_g[64i](v128x64i~in)
; vcast16u_g[64i](v128x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ushort> vcast16u<float>(in Vector128<float> src), hex://vfuncs/generic?vcast16u#vcast16u_g[32f](v128x32f~in)
; vcast16u_g[32f](v128x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ushort> vcast16u<double>(in Vector128<double> src), hex://vfuncs/generic?vcast16u#vcast16u_g[64f](v128x64f~in)
; vcast16u_g[64f](v128x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<int> vcast32i<byte>(in Vector128<byte> src), hex://vfuncs/generic?vcast32i#vcast32i_g[8u](v128x8u~in)
; vcast32i_g[8u](v128x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<int> vcast32i<sbyte>(in Vector128<sbyte> src), hex://vfuncs/generic?vcast32i#vcast32i_g[8i](v128x8i~in)
; vcast32i_g[8i](v128x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<int> vcast32i<ushort>(in Vector128<ushort> src), hex://vfuncs/generic?vcast32i#vcast32i_g[16u](v128x16u~in)
; vcast32i_g[16u](v128x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<int> vcast32i<short>(in Vector128<short> src), hex://vfuncs/generic?vcast32i#vcast32i_g[16i](v128x16i~in)
; vcast32i_g[16i](v128x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<int> vcast32i<uint>(in Vector128<uint> src), hex://vfuncs/generic?vcast32i#vcast32i_g[32u](v128x32u~in)
; vcast32i_g[32u](v128x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<int> vcast32i<int>(in Vector128<int> src), hex://vfuncs/generic?vcast32i#vcast32i_g[32i](v128x32i~in)
; vcast32i_g[32i](v128x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<int> vcast32i<ulong>(in Vector128<ulong> src), hex://vfuncs/generic?vcast32i#vcast32i_g[64u](v128x64u~in)
; vcast32i_g[64u](v128x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<int> vcast32i<long>(in Vector128<long> src), hex://vfuncs/generic?vcast32i#vcast32i_g[64i](v128x64i~in)
; vcast32i_g[64i](v128x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<int> vcast32i<float>(in Vector128<float> src), hex://vfuncs/generic?vcast32i#vcast32i_g[32f](v128x32f~in)
; vcast32i_g[32f](v128x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<int> vcast32i<double>(in Vector128<double> src), hex://vfuncs/generic?vcast32i#vcast32i_g[64f](v128x64f~in)
; vcast32i_g[64f](v128x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<uint> vcast32u<byte>(in Vector128<byte> src), hex://vfuncs/generic?vcast32u#vcast32u_g[8u](v128x8u~in)
; vcast32u_g[8u](v128x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<uint> vcast32u<sbyte>(in Vector128<sbyte> src), hex://vfuncs/generic?vcast32u#vcast32u_g[8i](v128x8i~in)
; vcast32u_g[8i](v128x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<uint> vcast32u<ushort>(in Vector128<ushort> src), hex://vfuncs/generic?vcast32u#vcast32u_g[16u](v128x16u~in)
; vcast32u_g[16u](v128x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<uint> vcast32u<short>(in Vector128<short> src), hex://vfuncs/generic?vcast32u#vcast32u_g[16i](v128x16i~in)
; vcast32u_g[16i](v128x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<uint> vcast32u<uint>(in Vector128<uint> src), hex://vfuncs/generic?vcast32u#vcast32u_g[32u](v128x32u~in)
; vcast32u_g[32u](v128x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<uint> vcast32u<int>(in Vector128<int> src), hex://vfuncs/generic?vcast32u#vcast32u_g[32i](v128x32i~in)
; vcast32u_g[32i](v128x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<uint> vcast32u<ulong>(in Vector128<ulong> src), hex://vfuncs/generic?vcast32u#vcast32u_g[64u](v128x64u~in)
; vcast32u_g[64u](v128x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<uint> vcast32u<long>(in Vector128<long> src), hex://vfuncs/generic?vcast32u#vcast32u_g[64i](v128x64i~in)
; vcast32u_g[64i](v128x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<uint> vcast32u<float>(in Vector128<float> src), hex://vfuncs/generic?vcast32u#vcast32u_g[32f](v128x32f~in)
; vcast32u_g[32f](v128x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<uint> vcast32u<double>(in Vector128<double> src), hex://vfuncs/generic?vcast32u#vcast32u_g[64f](v128x64f~in)
; vcast32u_g[64f](v128x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<long> vcast64i<byte>(in Vector128<byte> src), hex://vfuncs/generic?vcast64i#vcast64i_g[8u](v128x8u~in)
; vcast64i_g[8u](v128x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<long> vcast64i<sbyte>(in Vector128<sbyte> src), hex://vfuncs/generic?vcast64i#vcast64i_g[8i](v128x8i~in)
; vcast64i_g[8i](v128x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<long> vcast64i<ushort>(in Vector128<ushort> src), hex://vfuncs/generic?vcast64i#vcast64i_g[16u](v128x16u~in)
; vcast64i_g[16u](v128x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<long> vcast64i<short>(in Vector128<short> src), hex://vfuncs/generic?vcast64i#vcast64i_g[16i](v128x16i~in)
; vcast64i_g[16i](v128x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<long> vcast64i<uint>(in Vector128<uint> src), hex://vfuncs/generic?vcast64i#vcast64i_g[32u](v128x32u~in)
; vcast64i_g[32u](v128x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<long> vcast64i<int>(in Vector128<int> src), hex://vfuncs/generic?vcast64i#vcast64i_g[32i](v128x32i~in)
; vcast64i_g[32i](v128x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<long> vcast64i<ulong>(in Vector128<ulong> src), hex://vfuncs/generic?vcast64i#vcast64i_g[64u](v128x64u~in)
; vcast64i_g[64u](v128x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<long> vcast64i<long>(in Vector128<long> src), hex://vfuncs/generic?vcast64i#vcast64i_g[64i](v128x64i~in)
; vcast64i_g[64i](v128x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<long> vcast64i<float>(in Vector128<float> src), hex://vfuncs/generic?vcast64i#vcast64i_g[32f](v128x32f~in)
; vcast64i_g[32f](v128x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<long> vcast64i<double>(in Vector128<double> src), hex://vfuncs/generic?vcast64i#vcast64i_g[64f](v128x64f~in)
; vcast64i_g[64f](v128x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ulong> vcast64u<byte>(in Vector128<byte> src), hex://vfuncs/generic?vcast64u#vcast64u_g[8u](v128x8u~in)
; vcast64u_g[8u](v128x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ulong> vcast64u<sbyte>(in Vector128<sbyte> src), hex://vfuncs/generic?vcast64u#vcast64u_g[8i](v128x8i~in)
; vcast64u_g[8i](v128x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ulong> vcast64u<ushort>(in Vector128<ushort> src), hex://vfuncs/generic?vcast64u#vcast64u_g[16u](v128x16u~in)
; vcast64u_g[16u](v128x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ulong> vcast64u<short>(in Vector128<short> src), hex://vfuncs/generic?vcast64u#vcast64u_g[16i](v128x16i~in)
; vcast64u_g[16i](v128x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ulong> vcast64u<uint>(in Vector128<uint> src), hex://vfuncs/generic?vcast64u#vcast64u_g[32u](v128x32u~in)
; vcast64u_g[32u](v128x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ulong> vcast64u<int>(in Vector128<int> src), hex://vfuncs/generic?vcast64u#vcast64u_g[32i](v128x32i~in)
; vcast64u_g[32i](v128x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ulong> vcast64u<ulong>(in Vector128<ulong> src), hex://vfuncs/generic?vcast64u#vcast64u_g[64u](v128x64u~in)
; vcast64u_g[64u](v128x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ulong> vcast64u<long>(in Vector128<long> src), hex://vfuncs/generic?vcast64u#vcast64u_g[64i](v128x64i~in)
; vcast64u_g[64i](v128x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ulong> vcast64u<float>(in Vector128<float> src), hex://vfuncs/generic?vcast64u#vcast64u_g[32f](v128x32f~in)
; vcast64u_g[32f](v128x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<ulong> vcast64u<double>(in Vector128<double> src), hex://vfuncs/generic?vcast64u#vcast64u_g[64f](v128x64f~in)
; vcast64u_g[64f](v128x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<double> vcast64f<byte>(in Vector128<byte> src), hex://vfuncs/generic?vcast64f#vcast64f_g[8u](v128x8u~in)
; vcast64f_g[8u](v128x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<double> vcast64f<sbyte>(in Vector128<sbyte> src), hex://vfuncs/generic?vcast64f#vcast64f_g[8i](v128x8i~in)
; vcast64f_g[8i](v128x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<double> vcast64f<ushort>(in Vector128<ushort> src), hex://vfuncs/generic?vcast64f#vcast64f_g[16u](v128x16u~in)
; vcast64f_g[16u](v128x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<double> vcast64f<short>(in Vector128<short> src), hex://vfuncs/generic?vcast64f#vcast64f_g[16i](v128x16i~in)
; vcast64f_g[16i](v128x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<double> vcast64f<uint>(in Vector128<uint> src), hex://vfuncs/generic?vcast64f#vcast64f_g[32u](v128x32u~in)
; vcast64f_g[32u](v128x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<double> vcast64f<int>(in Vector128<int> src), hex://vfuncs/generic?vcast64f#vcast64f_g[32i](v128x32i~in)
; vcast64f_g[32i](v128x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<double> vcast64f<ulong>(in Vector128<ulong> src), hex://vfuncs/generic?vcast64f#vcast64f_g[64u](v128x64u~in)
; vcast64f_g[64u](v128x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<double> vcast64f<long>(in Vector128<long> src), hex://vfuncs/generic?vcast64f#vcast64f_g[64i](v128x64i~in)
; vcast64f_g[64i](v128x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<double> vcast64f<float>(in Vector128<float> src), hex://vfuncs/generic?vcast64f#vcast64f_g[32f](v128x32f~in)
; vcast64f_g[32f](v128x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<double> vcast64f<double>(in Vector128<double> src), hex://vfuncs/generic?vcast64f#vcast64f_g[64f](v128x64f~in)
; vcast64f_g[64f](v128x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<float> vcast32f<byte>(in Vector128<byte> src), hex://vfuncs/generic?vcast32f#vcast32f_g[8u](v128x8u~in)
; vcast32f_g[8u](v128x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<float> vcast32f<sbyte>(in Vector128<sbyte> src), hex://vfuncs/generic?vcast32f#vcast32f_g[8i](v128x8i~in)
; vcast32f_g[8i](v128x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<float> vcast32f<ushort>(in Vector128<ushort> src), hex://vfuncs/generic?vcast32f#vcast32f_g[16u](v128x16u~in)
; vcast32f_g[16u](v128x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<float> vcast32f<short>(in Vector128<short> src), hex://vfuncs/generic?vcast32f#vcast32f_g[16i](v128x16i~in)
; vcast32f_g[16i](v128x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<float> vcast32f<uint>(in Vector128<uint> src), hex://vfuncs/generic?vcast32f#vcast32f_g[32u](v128x32u~in)
; vcast32f_g[32u](v128x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<float> vcast32f<int>(in Vector128<int> src), hex://vfuncs/generic?vcast32f#vcast32f_g[32i](v128x32i~in)
; vcast32f_g[32i](v128x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<float> vcast32f<ulong>(in Vector128<ulong> src), hex://vfuncs/generic?vcast32f#vcast32f_g[64u](v128x64u~in)
; vcast32f_g[64u](v128x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<float> vcast32f<long>(in Vector128<long> src), hex://vfuncs/generic?vcast32f#vcast32f_g[64i](v128x64i~in)
; vcast32f_g[64i](v128x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<float> vcast32f<float>(in Vector128<float> src), hex://vfuncs/generic?vcast32f#vcast32f_g[32f](v128x32f~in)
; vcast32f_g[32f](v128x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector128<float> vcast32f<double>(in Vector128<double> src), hex://vfuncs/generic?vcast32f#vcast32f_g[64f](v128x64f~in)
; vcast32f_g[64f](v128x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<sbyte> vcast8i<byte>(in Vector256<byte> src), hex://vfuncs/generic?vcast8i#vcast8i_g[8u](v256x8u~in)
; vcast8i_g[8u](v256x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<sbyte> vcast8i<sbyte>(in Vector256<sbyte> src), hex://vfuncs/generic?vcast8i#vcast8i_g[8i](v256x8i~in)
; vcast8i_g[8i](v256x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<sbyte> vcast8i<ushort>(in Vector256<ushort> src), hex://vfuncs/generic?vcast8i#vcast8i_g[16u](v256x16u~in)
; vcast8i_g[16u](v256x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<sbyte> vcast8i<short>(in Vector256<short> src), hex://vfuncs/generic?vcast8i#vcast8i_g[16i](v256x16i~in)
; vcast8i_g[16i](v256x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<sbyte> vcast8i<uint>(in Vector256<uint> src), hex://vfuncs/generic?vcast8i#vcast8i_g[32u](v256x32u~in)
; vcast8i_g[32u](v256x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<sbyte> vcast8i<int>(in Vector256<int> src), hex://vfuncs/generic?vcast8i#vcast8i_g[32i](v256x32i~in)
; vcast8i_g[32i](v256x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<sbyte> vcast8i<ulong>(in Vector256<ulong> src), hex://vfuncs/generic?vcast8i#vcast8i_g[64u](v256x64u~in)
; vcast8i_g[64u](v256x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<sbyte> vcast8i<long>(in Vector256<long> src), hex://vfuncs/generic?vcast8i#vcast8i_g[64i](v256x64i~in)
; vcast8i_g[64i](v256x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<sbyte> vcast8i<float>(in Vector256<float> src), hex://vfuncs/generic?vcast8i#vcast8i_g[32f](v256x32f~in)
; vcast8i_g[32f](v256x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<sbyte> vcast8i<double>(in Vector256<double> src), hex://vfuncs/generic?vcast8i#vcast8i_g[64f](v256x64f~in)
; vcast8i_g[64f](v256x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<byte> vcast8u<byte>(in Vector256<byte> src), hex://vfuncs/generic?vcast8u#vcast8u_g[8u](v256x8u~in)
; vcast8u_g[8u](v256x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<byte> vcast8u<sbyte>(in Vector256<sbyte> src), hex://vfuncs/generic?vcast8u#vcast8u_g[8i](v256x8i~in)
; vcast8u_g[8i](v256x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<byte> vcast8u<ushort>(in Vector256<ushort> src), hex://vfuncs/generic?vcast8u#vcast8u_g[16u](v256x16u~in)
; vcast8u_g[16u](v256x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<byte> vcast8u<short>(in Vector256<short> src), hex://vfuncs/generic?vcast8u#vcast8u_g[16i](v256x16i~in)
; vcast8u_g[16i](v256x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<byte> vcast8u<uint>(in Vector256<uint> src), hex://vfuncs/generic?vcast8u#vcast8u_g[32u](v256x32u~in)
; vcast8u_g[32u](v256x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<byte> vcast8u<int>(in Vector256<int> src), hex://vfuncs/generic?vcast8u#vcast8u_g[32i](v256x32i~in)
; vcast8u_g[32i](v256x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<byte> vcast8u<ulong>(in Vector256<ulong> src), hex://vfuncs/generic?vcast8u#vcast8u_g[64u](v256x64u~in)
; vcast8u_g[64u](v256x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<byte> vcast8u<long>(in Vector256<long> src), hex://vfuncs/generic?vcast8u#vcast8u_g[64i](v256x64i~in)
; vcast8u_g[64i](v256x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<byte> vcast8u<float>(in Vector256<float> src), hex://vfuncs/generic?vcast8u#vcast8u_g[32f](v256x32f~in)
; vcast8u_g[32f](v256x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<byte> vcast8u<double>(in Vector256<double> src), hex://vfuncs/generic?vcast8u#vcast8u_g[64f](v256x64f~in)
; vcast8u_g[64f](v256x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<short> vcast16i<byte>(in Vector256<byte> src), hex://vfuncs/generic?vcast16i#vcast16i_g[8u](v256x8u~in)
; vcast16i_g[8u](v256x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<short> vcast16i<sbyte>(in Vector256<sbyte> src), hex://vfuncs/generic?vcast16i#vcast16i_g[8i](v256x8i~in)
; vcast16i_g[8i](v256x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<short> vcast16i<ushort>(in Vector256<ushort> src), hex://vfuncs/generic?vcast16i#vcast16i_g[16u](v256x16u~in)
; vcast16i_g[16u](v256x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<short> vcast16i<short>(in Vector256<short> src), hex://vfuncs/generic?vcast16i#vcast16i_g[16i](v256x16i~in)
; vcast16i_g[16i](v256x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<short> vcast16i<uint>(in Vector256<uint> src), hex://vfuncs/generic?vcast16i#vcast16i_g[32u](v256x32u~in)
; vcast16i_g[32u](v256x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<short> vcast16i<int>(in Vector256<int> src), hex://vfuncs/generic?vcast16i#vcast16i_g[32i](v256x32i~in)
; vcast16i_g[32i](v256x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<short> vcast16i<ulong>(in Vector256<ulong> src), hex://vfuncs/generic?vcast16i#vcast16i_g[64u](v256x64u~in)
; vcast16i_g[64u](v256x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<short> vcast16i<long>(in Vector256<long> src), hex://vfuncs/generic?vcast16i#vcast16i_g[64i](v256x64i~in)
; vcast16i_g[64i](v256x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<short> vcast16i<float>(in Vector256<float> src), hex://vfuncs/generic?vcast16i#vcast16i_g[32f](v256x32f~in)
; vcast16i_g[32f](v256x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<short> vcast16i<double>(in Vector256<double> src), hex://vfuncs/generic?vcast16i#vcast16i_g[64f](v256x64f~in)
; vcast16i_g[64f](v256x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ushort> vcast16u<byte>(in Vector256<byte> src), hex://vfuncs/generic?vcast16u#vcast16u_g[8u](v256x8u~in)
; vcast16u_g[8u](v256x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ushort> vcast16u<sbyte>(in Vector256<sbyte> src), hex://vfuncs/generic?vcast16u#vcast16u_g[8i](v256x8i~in)
; vcast16u_g[8i](v256x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ushort> vcast16u<ushort>(in Vector256<ushort> src), hex://vfuncs/generic?vcast16u#vcast16u_g[16u](v256x16u~in)
; vcast16u_g[16u](v256x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ushort> vcast16u<short>(in Vector256<short> src), hex://vfuncs/generic?vcast16u#vcast16u_g[16i](v256x16i~in)
; vcast16u_g[16i](v256x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ushort> vcast16u<uint>(in Vector256<uint> src), hex://vfuncs/generic?vcast16u#vcast16u_g[32u](v256x32u~in)
; vcast16u_g[32u](v256x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ushort> vcast16u<int>(in Vector256<int> src), hex://vfuncs/generic?vcast16u#vcast16u_g[32i](v256x32i~in)
; vcast16u_g[32i](v256x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ushort> vcast16u<ulong>(in Vector256<ulong> src), hex://vfuncs/generic?vcast16u#vcast16u_g[64u](v256x64u~in)
; vcast16u_g[64u](v256x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ushort> vcast16u<long>(in Vector256<long> src), hex://vfuncs/generic?vcast16u#vcast16u_g[64i](v256x64i~in)
; vcast16u_g[64i](v256x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ushort> vcast16u<float>(in Vector256<float> src), hex://vfuncs/generic?vcast16u#vcast16u_g[32f](v256x32f~in)
; vcast16u_g[32f](v256x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ushort> vcast16u<double>(in Vector256<double> src), hex://vfuncs/generic?vcast16u#vcast16u_g[64f](v256x64f~in)
; vcast16u_g[64f](v256x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<int> vcast32i<byte>(in Vector256<byte> src), hex://vfuncs/generic?vcast32i#vcast32i_g[8u](v256x8u~in)
; vcast32i_g[8u](v256x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<int> vcast32i<sbyte>(in Vector256<sbyte> src), hex://vfuncs/generic?vcast32i#vcast32i_g[8i](v256x8i~in)
; vcast32i_g[8i](v256x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<int> vcast32i<ushort>(in Vector256<ushort> src), hex://vfuncs/generic?vcast32i#vcast32i_g[16u](v256x16u~in)
; vcast32i_g[16u](v256x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<int> vcast32i<short>(in Vector256<short> src), hex://vfuncs/generic?vcast32i#vcast32i_g[16i](v256x16i~in)
; vcast32i_g[16i](v256x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<int> vcast32i<uint>(in Vector256<uint> src), hex://vfuncs/generic?vcast32i#vcast32i_g[32u](v256x32u~in)
; vcast32i_g[32u](v256x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<int> vcast32i<int>(in Vector256<int> src), hex://vfuncs/generic?vcast32i#vcast32i_g[32i](v256x32i~in)
; vcast32i_g[32i](v256x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<int> vcast32i<ulong>(in Vector256<ulong> src), hex://vfuncs/generic?vcast32i#vcast32i_g[64u](v256x64u~in)
; vcast32i_g[64u](v256x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<int> vcast32i<long>(in Vector256<long> src), hex://vfuncs/generic?vcast32i#vcast32i_g[64i](v256x64i~in)
; vcast32i_g[64i](v256x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<int> vcast32i<float>(in Vector256<float> src), hex://vfuncs/generic?vcast32i#vcast32i_g[32f](v256x32f~in)
; vcast32i_g[32f](v256x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<int> vcast32i<double>(in Vector256<double> src), hex://vfuncs/generic?vcast32i#vcast32i_g[64f](v256x64f~in)
; vcast32i_g[64f](v256x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<uint> vcast32u<byte>(in Vector256<byte> src), hex://vfuncs/generic?vcast32u#vcast32u_g[8u](v256x8u~in)
; vcast32u_g[8u](v256x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<uint> vcast32u<sbyte>(in Vector256<sbyte> src), hex://vfuncs/generic?vcast32u#vcast32u_g[8i](v256x8i~in)
; vcast32u_g[8i](v256x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<uint> vcast32u<ushort>(in Vector256<ushort> src), hex://vfuncs/generic?vcast32u#vcast32u_g[16u](v256x16u~in)
; vcast32u_g[16u](v256x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<uint> vcast32u<short>(in Vector256<short> src), hex://vfuncs/generic?vcast32u#vcast32u_g[16i](v256x16i~in)
; vcast32u_g[16i](v256x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<uint> vcast32u<uint>(in Vector256<uint> src), hex://vfuncs/generic?vcast32u#vcast32u_g[32u](v256x32u~in)
; vcast32u_g[32u](v256x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<uint> vcast32u<int>(in Vector256<int> src), hex://vfuncs/generic?vcast32u#vcast32u_g[32i](v256x32i~in)
; vcast32u_g[32i](v256x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<uint> vcast32u<ulong>(in Vector256<ulong> src), hex://vfuncs/generic?vcast32u#vcast32u_g[64u](v256x64u~in)
; vcast32u_g[64u](v256x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<uint> vcast32u<long>(in Vector256<long> src), hex://vfuncs/generic?vcast32u#vcast32u_g[64i](v256x64i~in)
; vcast32u_g[64i](v256x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<uint> vcast32u<float>(in Vector256<float> src), hex://vfuncs/generic?vcast32u#vcast32u_g[32f](v256x32f~in)
; vcast32u_g[32f](v256x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<uint> vcast32u<double>(in Vector256<double> src), hex://vfuncs/generic?vcast32u#vcast32u_g[64f](v256x64f~in)
; vcast32u_g[64f](v256x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<long> vcast64i<byte>(in Vector256<byte> src), hex://vfuncs/generic?vcast64i#vcast64i_g[8u](v256x8u~in)
; vcast64i_g[8u](v256x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<long> vcast64i<sbyte>(in Vector256<sbyte> src), hex://vfuncs/generic?vcast64i#vcast64i_g[8i](v256x8i~in)
; vcast64i_g[8i](v256x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<long> vcast64i<ushort>(in Vector256<ushort> src), hex://vfuncs/generic?vcast64i#vcast64i_g[16u](v256x16u~in)
; vcast64i_g[16u](v256x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<long> vcast64i<short>(in Vector256<short> src), hex://vfuncs/generic?vcast64i#vcast64i_g[16i](v256x16i~in)
; vcast64i_g[16i](v256x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<long> vcast64i<uint>(in Vector256<uint> src), hex://vfuncs/generic?vcast64i#vcast64i_g[32u](v256x32u~in)
; vcast64i_g[32u](v256x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<long> vcast64i<int>(in Vector256<int> src), hex://vfuncs/generic?vcast64i#vcast64i_g[32i](v256x32i~in)
; vcast64i_g[32i](v256x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<long> vcast64i<ulong>(in Vector256<ulong> src), hex://vfuncs/generic?vcast64i#vcast64i_g[64u](v256x64u~in)
; vcast64i_g[64u](v256x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<long> vcast64i<long>(in Vector256<long> src), hex://vfuncs/generic?vcast64i#vcast64i_g[64i](v256x64i~in)
; vcast64i_g[64i](v256x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<long> vcast64i<float>(in Vector256<float> src), hex://vfuncs/generic?vcast64i#vcast64i_g[32f](v256x32f~in)
; vcast64i_g[32f](v256x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<long> vcast64i<double>(in Vector256<double> src), hex://vfuncs/generic?vcast64i#vcast64i_g[64f](v256x64f~in)
; vcast64i_g[64f](v256x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ulong> vcast64u<byte>(in Vector256<byte> src), hex://vfuncs/generic?vcast64u#vcast64u_g[8u](v256x8u~in)
; vcast64u_g[8u](v256x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ulong> vcast64u<sbyte>(in Vector256<sbyte> src), hex://vfuncs/generic?vcast64u#vcast64u_g[8i](v256x8i~in)
; vcast64u_g[8i](v256x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ulong> vcast64u<ushort>(in Vector256<ushort> src), hex://vfuncs/generic?vcast64u#vcast64u_g[16u](v256x16u~in)
; vcast64u_g[16u](v256x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ulong> vcast64u<short>(in Vector256<short> src), hex://vfuncs/generic?vcast64u#vcast64u_g[16i](v256x16i~in)
; vcast64u_g[16i](v256x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ulong> vcast64u<uint>(in Vector256<uint> src), hex://vfuncs/generic?vcast64u#vcast64u_g[32u](v256x32u~in)
; vcast64u_g[32u](v256x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ulong> vcast64u<int>(in Vector256<int> src), hex://vfuncs/generic?vcast64u#vcast64u_g[32i](v256x32i~in)
; vcast64u_g[32i](v256x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ulong> vcast64u<ulong>(in Vector256<ulong> src), hex://vfuncs/generic?vcast64u#vcast64u_g[64u](v256x64u~in)
; vcast64u_g[64u](v256x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ulong> vcast64u<long>(in Vector256<long> src), hex://vfuncs/generic?vcast64u#vcast64u_g[64i](v256x64i~in)
; vcast64u_g[64i](v256x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ulong> vcast64u<float>(in Vector256<float> src), hex://vfuncs/generic?vcast64u#vcast64u_g[32f](v256x32f~in)
; vcast64u_g[32f](v256x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<ulong> vcast64u<double>(in Vector256<double> src), hex://vfuncs/generic?vcast64u#vcast64u_g[64f](v256x64f~in)
; vcast64u_g[64f](v256x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<float> vcast32f<byte>(in Vector256<byte> src), hex://vfuncs/generic?vcast32f#vcast32f_g[8u](v256x8u~in)
; vcast32f_g[8u](v256x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<float> vcast32f<sbyte>(in Vector256<sbyte> src), hex://vfuncs/generic?vcast32f#vcast32f_g[8i](v256x8i~in)
; vcast32f_g[8i](v256x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<float> vcast32f<ushort>(in Vector256<ushort> src), hex://vfuncs/generic?vcast32f#vcast32f_g[16u](v256x16u~in)
; vcast32f_g[16u](v256x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<float> vcast32f<short>(in Vector256<short> src), hex://vfuncs/generic?vcast32f#vcast32f_g[16i](v256x16i~in)
; vcast32f_g[16i](v256x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<float> vcast32f<uint>(in Vector256<uint> src), hex://vfuncs/generic?vcast32f#vcast32f_g[32u](v256x32u~in)
; vcast32f_g[32u](v256x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<float> vcast32f<int>(in Vector256<int> src), hex://vfuncs/generic?vcast32f#vcast32f_g[32i](v256x32i~in)
; vcast32f_g[32i](v256x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<float> vcast32f<ulong>(in Vector256<ulong> src), hex://vfuncs/generic?vcast32f#vcast32f_g[64u](v256x64u~in)
; vcast32f_g[64u](v256x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<float> vcast32f<long>(in Vector256<long> src), hex://vfuncs/generic?vcast32f#vcast32f_g[64i](v256x64i~in)
; vcast32f_g[64i](v256x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<float> vcast32f<float>(in Vector256<float> src), hex://vfuncs/generic?vcast32f#vcast32f_g[32f](v256x32f~in)
; vcast32f_g[32f](v256x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<float> vcast32f<double>(in Vector256<double> src), hex://vfuncs/generic?vcast32f#vcast32f_g[64f](v256x64f~in)
; vcast32f_g[64f](v256x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<double> vcast64f<byte>(in Vector256<byte> src), hex://vfuncs/generic?vcast64f#vcast64f_g[8u](v256x8u~in)
; vcast64f_g[8u](v256x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<double> vcast64f<sbyte>(in Vector256<sbyte> src), hex://vfuncs/generic?vcast64f#vcast64f_g[8i](v256x8i~in)
; vcast64f_g[8i](v256x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<double> vcast64f<ushort>(in Vector256<ushort> src), hex://vfuncs/generic?vcast64f#vcast64f_g[16u](v256x16u~in)
; vcast64f_g[16u](v256x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<double> vcast64f<short>(in Vector256<short> src), hex://vfuncs/generic?vcast64f#vcast64f_g[16i](v256x16i~in)
; vcast64f_g[16i](v256x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<double> vcast64f<uint>(in Vector256<uint> src), hex://vfuncs/generic?vcast64f#vcast64f_g[32u](v256x32u~in)
; vcast64f_g[32u](v256x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<double> vcast64f<int>(in Vector256<int> src), hex://vfuncs/generic?vcast64f#vcast64f_g[32i](v256x32i~in)
; vcast64f_g[32i](v256x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<double> vcast64f<ulong>(in Vector256<ulong> src), hex://vfuncs/generic?vcast64f#vcast64f_g[64u](v256x64u~in)
; vcast64f_g[64u](v256x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<double> vcast64f<long>(in Vector256<long> src), hex://vfuncs/generic?vcast64f#vcast64f_g[64i](v256x64i~in)
; vcast64f_g[64i](v256x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<double> vcast64f<float>(in Vector256<float> src), hex://vfuncs/generic?vcast64f#vcast64f_g[32f](v256x32f~in)
; vcast64f_g[32f](v256x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector256<double> vcast64f<double>(in Vector256<double> src), hex://vfuncs/generic?vcast64f#vcast64f_g[64f](v256x64f~in)
; vcast64f_g[64f](v256x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<sbyte> vcast8i<byte>(in Vector512<byte> src), hex://vfuncs/generic?vcast8i#vcast8i_g[8u](v512x8u~in)
; vcast8i_g[8u](v512x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<sbyte> vcast8i<sbyte>(in Vector512<sbyte> src), hex://vfuncs/generic?vcast8i#vcast8i_g[8i](v512x8i~in)
; vcast8i_g[8i](v512x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<sbyte> vcast8i<ushort>(in Vector512<ushort> src), hex://vfuncs/generic?vcast8i#vcast8i_g[16u](v512x16u~in)
; vcast8i_g[16u](v512x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<sbyte> vcast8i<short>(in Vector512<short> src), hex://vfuncs/generic?vcast8i#vcast8i_g[16i](v512x16i~in)
; vcast8i_g[16i](v512x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<sbyte> vcast8i<uint>(in Vector512<uint> src), hex://vfuncs/generic?vcast8i#vcast8i_g[32u](v512x32u~in)
; vcast8i_g[32u](v512x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<sbyte> vcast8i<int>(in Vector512<int> src), hex://vfuncs/generic?vcast8i#vcast8i_g[32i](v512x32i~in)
; vcast8i_g[32i](v512x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<sbyte> vcast8i<ulong>(in Vector512<ulong> src), hex://vfuncs/generic?vcast8i#vcast8i_g[64u](v512x64u~in)
; vcast8i_g[64u](v512x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<sbyte> vcast8i<long>(in Vector512<long> src), hex://vfuncs/generic?vcast8i#vcast8i_g[64i](v512x64i~in)
; vcast8i_g[64i](v512x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<sbyte> vcast8i<float>(in Vector512<float> src), hex://vfuncs/generic?vcast8i#vcast8i_g[32f](v512x32f~in)
; vcast8i_g[32f](v512x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<sbyte> vcast8i<double>(in Vector512<double> src), hex://vfuncs/generic?vcast8i#vcast8i_g[64f](v512x64f~in)
; vcast8i_g[64f](v512x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<byte> vcast8u<byte>(in Vector512<byte> src), hex://vfuncs/generic?vcast8u#vcast8u_g[8u](v512x8u~in)
; vcast8u_g[8u](v512x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<byte> vcast8u<sbyte>(in Vector512<sbyte> src), hex://vfuncs/generic?vcast8u#vcast8u_g[8i](v512x8i~in)
; vcast8u_g[8i](v512x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<byte> vcast8u<ushort>(in Vector512<ushort> src), hex://vfuncs/generic?vcast8u#vcast8u_g[16u](v512x16u~in)
; vcast8u_g[16u](v512x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<byte> vcast8u<short>(in Vector512<short> src), hex://vfuncs/generic?vcast8u#vcast8u_g[16i](v512x16i~in)
; vcast8u_g[16i](v512x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<byte> vcast8u<uint>(in Vector512<uint> src), hex://vfuncs/generic?vcast8u#vcast8u_g[32u](v512x32u~in)
; vcast8u_g[32u](v512x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<byte> vcast8u<int>(in Vector512<int> src), hex://vfuncs/generic?vcast8u#vcast8u_g[32i](v512x32i~in)
; vcast8u_g[32i](v512x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<byte> vcast8u<ulong>(in Vector512<ulong> src), hex://vfuncs/generic?vcast8u#vcast8u_g[64u](v512x64u~in)
; vcast8u_g[64u](v512x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<byte> vcast8u<long>(in Vector512<long> src), hex://vfuncs/generic?vcast8u#vcast8u_g[64i](v512x64i~in)
; vcast8u_g[64i](v512x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<byte> vcast8u<float>(in Vector512<float> src), hex://vfuncs/generic?vcast8u#vcast8u_g[32f](v512x32f~in)
; vcast8u_g[32f](v512x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<byte> vcast8u<double>(in Vector512<double> src), hex://vfuncs/generic?vcast8u#vcast8u_g[64f](v512x64f~in)
; vcast8u_g[64f](v512x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<short> vcast16i<byte>(in Vector512<byte> src), hex://vfuncs/generic?vcast16i#vcast16i_g[8u](v512x8u~in)
; vcast16i_g[8u](v512x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<short> vcast16i<sbyte>(in Vector512<sbyte> src), hex://vfuncs/generic?vcast16i#vcast16i_g[8i](v512x8i~in)
; vcast16i_g[8i](v512x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<short> vcast16i<ushort>(in Vector512<ushort> src), hex://vfuncs/generic?vcast16i#vcast16i_g[16u](v512x16u~in)
; vcast16i_g[16u](v512x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<short> vcast16i<short>(in Vector512<short> src), hex://vfuncs/generic?vcast16i#vcast16i_g[16i](v512x16i~in)
; vcast16i_g[16i](v512x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<short> vcast16i<uint>(in Vector512<uint> src), hex://vfuncs/generic?vcast16i#vcast16i_g[32u](v512x32u~in)
; vcast16i_g[32u](v512x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<short> vcast16i<int>(in Vector512<int> src), hex://vfuncs/generic?vcast16i#vcast16i_g[32i](v512x32i~in)
; vcast16i_g[32i](v512x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<short> vcast16i<ulong>(in Vector512<ulong> src), hex://vfuncs/generic?vcast16i#vcast16i_g[64u](v512x64u~in)
; vcast16i_g[64u](v512x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<short> vcast16i<long>(in Vector512<long> src), hex://vfuncs/generic?vcast16i#vcast16i_g[64i](v512x64i~in)
; vcast16i_g[64i](v512x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<short> vcast16i<float>(in Vector512<float> src), hex://vfuncs/generic?vcast16i#vcast16i_g[32f](v512x32f~in)
; vcast16i_g[32f](v512x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<short> vcast16i<double>(in Vector512<double> src), hex://vfuncs/generic?vcast16i#vcast16i_g[64f](v512x64f~in)
; vcast16i_g[64f](v512x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ushort> vcast16u<byte>(in Vector512<byte> src), hex://vfuncs/generic?vcast16u#vcast16u_g[8u](v512x8u~in)
; vcast16u_g[8u](v512x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ushort> vcast16u<sbyte>(in Vector512<sbyte> src), hex://vfuncs/generic?vcast16u#vcast16u_g[8i](v512x8i~in)
; vcast16u_g[8i](v512x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ushort> vcast16u<ushort>(in Vector512<ushort> src), hex://vfuncs/generic?vcast16u#vcast16u_g[16u](v512x16u~in)
; vcast16u_g[16u](v512x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ushort> vcast16u<short>(in Vector512<short> src), hex://vfuncs/generic?vcast16u#vcast16u_g[16i](v512x16i~in)
; vcast16u_g[16i](v512x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ushort> vcast16u<uint>(in Vector512<uint> src), hex://vfuncs/generic?vcast16u#vcast16u_g[32u](v512x32u~in)
; vcast16u_g[32u](v512x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ushort> vcast16u<int>(in Vector512<int> src), hex://vfuncs/generic?vcast16u#vcast16u_g[32i](v512x32i~in)
; vcast16u_g[32i](v512x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ushort> vcast16u<ulong>(in Vector512<ulong> src), hex://vfuncs/generic?vcast16u#vcast16u_g[64u](v512x64u~in)
; vcast16u_g[64u](v512x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ushort> vcast16u<long>(in Vector512<long> src), hex://vfuncs/generic?vcast16u#vcast16u_g[64i](v512x64i~in)
; vcast16u_g[64i](v512x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ushort> vcast16u<float>(in Vector512<float> src), hex://vfuncs/generic?vcast16u#vcast16u_g[32f](v512x32f~in)
; vcast16u_g[32f](v512x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ushort> vcast16u<double>(in Vector512<double> src), hex://vfuncs/generic?vcast16u#vcast16u_g[64f](v512x64f~in)
; vcast16u_g[64f](v512x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<int> vcast32i<byte>(in Vector512<byte> src), hex://vfuncs/generic?vcast32i#vcast32i_g[8u](v512x8u~in)
; vcast32i_g[8u](v512x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<int> vcast32i<sbyte>(in Vector512<sbyte> src), hex://vfuncs/generic?vcast32i#vcast32i_g[8i](v512x8i~in)
; vcast32i_g[8i](v512x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<int> vcast32i<ushort>(in Vector512<ushort> src), hex://vfuncs/generic?vcast32i#vcast32i_g[16u](v512x16u~in)
; vcast32i_g[16u](v512x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<int> vcast32i<short>(in Vector512<short> src), hex://vfuncs/generic?vcast32i#vcast32i_g[16i](v512x16i~in)
; vcast32i_g[16i](v512x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<int> vcast32i<uint>(in Vector512<uint> src), hex://vfuncs/generic?vcast32i#vcast32i_g[32u](v512x32u~in)
; vcast32i_g[32u](v512x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<int> vcast32i<int>(in Vector512<int> src), hex://vfuncs/generic?vcast32i#vcast32i_g[32i](v512x32i~in)
; vcast32i_g[32i](v512x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<int> vcast32i<ulong>(in Vector512<ulong> src), hex://vfuncs/generic?vcast32i#vcast32i_g[64u](v512x64u~in)
; vcast32i_g[64u](v512x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<int> vcast32i<long>(in Vector512<long> src), hex://vfuncs/generic?vcast32i#vcast32i_g[64i](v512x64i~in)
; vcast32i_g[64i](v512x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<int> vcast32i<float>(in Vector512<float> src), hex://vfuncs/generic?vcast32i#vcast32i_g[32f](v512x32f~in)
; vcast32i_g[32f](v512x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<int> vcast32i<double>(in Vector512<double> src), hex://vfuncs/generic?vcast32i#vcast32i_g[64f](v512x64f~in)
; vcast32i_g[64f](v512x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<uint> vcast32u<byte>(in Vector512<byte> src), hex://vfuncs/generic?vcast32u#vcast32u_g[8u](v512x8u~in)
; vcast32u_g[8u](v512x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<uint> vcast32u<sbyte>(in Vector512<sbyte> src), hex://vfuncs/generic?vcast32u#vcast32u_g[8i](v512x8i~in)
; vcast32u_g[8i](v512x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<uint> vcast32u<ushort>(in Vector512<ushort> src), hex://vfuncs/generic?vcast32u#vcast32u_g[16u](v512x16u~in)
; vcast32u_g[16u](v512x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<uint> vcast32u<short>(in Vector512<short> src), hex://vfuncs/generic?vcast32u#vcast32u_g[16i](v512x16i~in)
; vcast32u_g[16i](v512x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<uint> vcast32u<uint>(in Vector512<uint> src), hex://vfuncs/generic?vcast32u#vcast32u_g[32u](v512x32u~in)
; vcast32u_g[32u](v512x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<uint> vcast32u<int>(in Vector512<int> src), hex://vfuncs/generic?vcast32u#vcast32u_g[32i](v512x32i~in)
; vcast32u_g[32i](v512x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<uint> vcast32u<ulong>(in Vector512<ulong> src), hex://vfuncs/generic?vcast32u#vcast32u_g[64u](v512x64u~in)
; vcast32u_g[64u](v512x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<uint> vcast32u<long>(in Vector512<long> src), hex://vfuncs/generic?vcast32u#vcast32u_g[64i](v512x64i~in)
; vcast32u_g[64i](v512x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<uint> vcast32u<float>(in Vector512<float> src), hex://vfuncs/generic?vcast32u#vcast32u_g[32f](v512x32f~in)
; vcast32u_g[32f](v512x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<uint> vcast32u<double>(in Vector512<double> src), hex://vfuncs/generic?vcast32u#vcast32u_g[64f](v512x64f~in)
; vcast32u_g[64f](v512x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<long> vcast64i<byte>(in Vector512<byte> src), hex://vfuncs/generic?vcast64i#vcast64i_g[8u](v512x8u~in)
; vcast64i_g[8u](v512x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<long> vcast64i<sbyte>(in Vector512<sbyte> src), hex://vfuncs/generic?vcast64i#vcast64i_g[8i](v512x8i~in)
; vcast64i_g[8i](v512x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<long> vcast64i<ushort>(in Vector512<ushort> src), hex://vfuncs/generic?vcast64i#vcast64i_g[16u](v512x16u~in)
; vcast64i_g[16u](v512x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<long> vcast64i<short>(in Vector512<short> src), hex://vfuncs/generic?vcast64i#vcast64i_g[16i](v512x16i~in)
; vcast64i_g[16i](v512x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<long> vcast64i<uint>(in Vector512<uint> src), hex://vfuncs/generic?vcast64i#vcast64i_g[32u](v512x32u~in)
; vcast64i_g[32u](v512x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<long> vcast64i<int>(in Vector512<int> src), hex://vfuncs/generic?vcast64i#vcast64i_g[32i](v512x32i~in)
; vcast64i_g[32i](v512x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<long> vcast64i<ulong>(in Vector512<ulong> src), hex://vfuncs/generic?vcast64i#vcast64i_g[64u](v512x64u~in)
; vcast64i_g[64u](v512x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<long> vcast64i<long>(in Vector512<long> src), hex://vfuncs/generic?vcast64i#vcast64i_g[64i](v512x64i~in)
; vcast64i_g[64i](v512x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<long> vcast64i<float>(in Vector512<float> src), hex://vfuncs/generic?vcast64i#vcast64i_g[32f](v512x32f~in)
; vcast64i_g[32f](v512x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<long> vcast64i<double>(in Vector512<double> src), hex://vfuncs/generic?vcast64i#vcast64i_g[64f](v512x64f~in)
; vcast64i_g[64f](v512x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ulong> vcast64u<byte>(in Vector512<byte> src), hex://vfuncs/generic?vcast64u#vcast64u_g[8u](v512x8u~in)
; vcast64u_g[8u](v512x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ulong> vcast64u<sbyte>(in Vector512<sbyte> src), hex://vfuncs/generic?vcast64u#vcast64u_g[8i](v512x8i~in)
; vcast64u_g[8i](v512x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ulong> vcast64u<ushort>(in Vector512<ushort> src), hex://vfuncs/generic?vcast64u#vcast64u_g[16u](v512x16u~in)
; vcast64u_g[16u](v512x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ulong> vcast64u<short>(in Vector512<short> src), hex://vfuncs/generic?vcast64u#vcast64u_g[16i](v512x16i~in)
; vcast64u_g[16i](v512x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ulong> vcast64u<uint>(in Vector512<uint> src), hex://vfuncs/generic?vcast64u#vcast64u_g[32u](v512x32u~in)
; vcast64u_g[32u](v512x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ulong> vcast64u<int>(in Vector512<int> src), hex://vfuncs/generic?vcast64u#vcast64u_g[32i](v512x32i~in)
; vcast64u_g[32i](v512x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ulong> vcast64u<ulong>(in Vector512<ulong> src), hex://vfuncs/generic?vcast64u#vcast64u_g[64u](v512x64u~in)
; vcast64u_g[64u](v512x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ulong> vcast64u<long>(in Vector512<long> src), hex://vfuncs/generic?vcast64u#vcast64u_g[64i](v512x64i~in)
; vcast64u_g[64i](v512x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ulong> vcast64u<float>(in Vector512<float> src), hex://vfuncs/generic?vcast64u#vcast64u_g[32f](v512x32f~in)
; vcast64u_g[32f](v512x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<ulong> vcast64u<double>(in Vector512<double> src), hex://vfuncs/generic?vcast64u#vcast64u_g[64f](v512x64f~in)
; vcast64u_g[64f](v512x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<float> vcast32f<byte>(in Vector512<byte> src), hex://vfuncs/generic?vcast32f#vcast32f_g[8u](v512x8u~in)
; vcast32f_g[8u](v512x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<float> vcast32f<sbyte>(in Vector512<sbyte> src), hex://vfuncs/generic?vcast32f#vcast32f_g[8i](v512x8i~in)
; vcast32f_g[8i](v512x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<float> vcast32f<ushort>(in Vector512<ushort> src), hex://vfuncs/generic?vcast32f#vcast32f_g[16u](v512x16u~in)
; vcast32f_g[16u](v512x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<float> vcast32f<short>(in Vector512<short> src), hex://vfuncs/generic?vcast32f#vcast32f_g[16i](v512x16i~in)
; vcast32f_g[16i](v512x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<float> vcast32f<uint>(in Vector512<uint> src), hex://vfuncs/generic?vcast32f#vcast32f_g[32u](v512x32u~in)
; vcast32f_g[32u](v512x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<float> vcast32f<int>(in Vector512<int> src), hex://vfuncs/generic?vcast32f#vcast32f_g[32i](v512x32i~in)
; vcast32f_g[32i](v512x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<float> vcast32f<ulong>(in Vector512<ulong> src), hex://vfuncs/generic?vcast32f#vcast32f_g[64u](v512x64u~in)
; vcast32f_g[64u](v512x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<float> vcast32f<long>(in Vector512<long> src), hex://vfuncs/generic?vcast32f#vcast32f_g[64i](v512x64i~in)
; vcast32f_g[64i](v512x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<float> vcast32f<float>(in Vector512<float> src), hex://vfuncs/generic?vcast32f#vcast32f_g[32f](v512x32f~in)
; vcast32f_g[32f](v512x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<float> vcast32f<double>(in Vector512<double> src), hex://vfuncs/generic?vcast32f#vcast32f_g[64f](v512x64f~in)
; vcast32f_g[64f](v512x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<double> vcast64f<byte>(in Vector512<byte> src), hex://vfuncs/generic?vcast64f#vcast64f_g[8u](v512x8u~in)
; vcast64f_g[8u](v512x8u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<double> vcast64f<sbyte>(in Vector512<sbyte> src), hex://vfuncs/generic?vcast64f#vcast64f_g[8i](v512x8i~in)
; vcast64f_g[8i](v512x8i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<double> vcast64f<ushort>(in Vector512<ushort> src), hex://vfuncs/generic?vcast64f#vcast64f_g[16u](v512x16u~in)
; vcast64f_g[16u](v512x16u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<double> vcast64f<short>(in Vector512<short> src), hex://vfuncs/generic?vcast64f#vcast64f_g[16i](v512x16i~in)
; vcast64f_g[16i](v512x16i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<double> vcast64f<uint>(in Vector512<uint> src), hex://vfuncs/generic?vcast64f#vcast64f_g[32u](v512x32u~in)
; vcast64f_g[32u](v512x32u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<double> vcast64f<int>(in Vector512<int> src), hex://vfuncs/generic?vcast64f#vcast64f_g[32i](v512x32i~in)
; vcast64f_g[32i](v512x32i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<double> vcast64f<ulong>(in Vector512<ulong> src), hex://vfuncs/generic?vcast64f#vcast64f_g[64u](v512x64u~in)
; vcast64f_g[64u](v512x64u~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<double> vcast64f<long>(in Vector512<long> src), hex://vfuncs/generic?vcast64f#vcast64f_g[64i](v512x64i~in)
; vcast64f_g[64i](v512x64i~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<double> vcast64f<float>(in Vector512<float> src), hex://vfuncs/generic?vcast64f#vcast64f_g[32f](v512x32f~in)
; vcast64f_g[32f](v512x32f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ref Vector512<double> vcast64f<double>(in Vector512<double> src), hex://vfuncs/generic?vcast64f#vcast64f_g[64f](v512x64f~in)
; vcast64f_g[64f](v512x64f~in)[9] = {0x0f,0x1f,0x44,0x00,0x00,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_Zx3
0000h nop dword ptr [rax+rax]                 ; NOP r/m32 || o32 0F 1F /0 || encoded[5]{0f 1f 44 00 00}
0005h mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0008h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; byte vcell<byte>(Vector128<byte> src, int index), hex://vfuncs/generic?vcell#vcell_g[8u](v128x8u,32i)
; vcell_g[8u](v128x8u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x67,0xb8,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 67 b8 08 ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell<sbyte>(Vector128<sbyte> src, int index), hex://vfuncs/generic?vcell#vcell_g[8i](v128x8i,32i)
; vcell_g[8i](v128x8i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x16,0xb8,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 16 b8 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell<ushort>(Vector128<ushort> src, int index), hex://vfuncs/generic?vcell#vcell_g[16u](v128x16u,32i)
; vcell_g[16u](v128x16u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc7,0xb7,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c7 b7 08 ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell<short>(Vector128<short> src, int index), hex://vfuncs/generic?vcell#vcell_g[16i](v128x16i,32i)
; vcell_g[16i](v128x16i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x76,0xb7,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 76 b7 08 ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell<uint>(Vector128<uint> src, int index), hex://vfuncs/generic?vcell#vcell_g[32u](v128x32u,32i)
; vcell_g[32u](v128x32u,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x28,0xb7,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 28 b7 08 ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell<int>(Vector128<int> src, int index), hex://vfuncs/generic?vcell#vcell_g[32i](v128x32i,32i)
; vcell_g[32i](v128x32i,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd8,0xb6,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d8 b6 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell<ulong>(Vector128<ulong> src, int index), hex://vfuncs/generic?vcell#vcell_g[64u](v128x64u,32i)
; vcell_g[64u](v128x64u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x87,0xb6,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 87 b6 08 ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell<long>(Vector128<long> src, int index), hex://vfuncs/generic?vcell#vcell_g[64i](v128x64i,32i)
; vcell_g[64i](v128x64i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x37,0xb6,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 37 b6 08 ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell<float>(Vector128<float> src, int index), hex://vfuncs/generic?vcell#vcell_g[32f](v128x32f,32i)
; vcell_g[32f](v128x32f,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe6,0xb5,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e6 b5 08 ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell<double>(Vector128<double> src, int index), hex://vfuncs/generic?vcell#vcell_g[64f](v128x64f,32i)
; vcell_g[64f](v128x64f,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x86,0xb1,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 86 b1 08 ff}
------------------------------------------------------------------------------------------------------------------------
; byte vhead<byte>(Vector128<byte> src), hex://vfuncs/generic?vhead#vhead_g[8u](v128x8u)
; vhead_g[8u](v128x8u)[16] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc4,0xe3,0x79,0x14,0xc0,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vpextrb eax,xmm0,0                      ; VPEXTRB r32/m8, xmm2, imm8 || VEX.128.66.0F3A.W0 14 /r ib || encoded[6]{c4 e3 79 14 c0 00}
000fh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; sbyte vhead<sbyte>(Vector128<sbyte> src), hex://vfuncs/generic?vhead#vhead_g[8i](v128x8i)
; vhead_g[8i](v128x8i)[20] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc4,0xe3,0x79,0x14,0xc0,0x00,0x48,0x0f,0xbe,0xc0,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vpextrb eax,xmm0,0                      ; VPEXTRB r32/m8, xmm2, imm8 || VEX.128.66.0F3A.W0 14 /r ib || encoded[6]{c4 e3 79 14 c0 00}
000fh movsx rax,al                            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[4]{48 0f be c0}
0013h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ushort vhead<ushort>(Vector128<ushort> src), hex://vfuncs/generic?vhead#vhead_g[16u](v128x16u)
; vhead_g[16u](v128x16u)[15] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0xc5,0xc0,0x00,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vpextrw eax,xmm0,0                      ; VPEXTRW r32, xmm1, imm8 || VEX.128.66.0F.W0 C5 /r ib || encoded[5]{c5 f9 c5 c0 00}
000eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; short vhead<short>(Vector128<short> src), hex://vfuncs/generic?vhead#vhead_g[16i](v128x16i)
; vhead_g[16i](v128x16i)[19] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0xc5,0xc0,0x00,0x48,0x0f,0xbf,0xc0,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vpextrw eax,xmm0,0                      ; VPEXTRW r32, xmm1, imm8 || VEX.128.66.0F.W0 C5 /r ib || encoded[5]{c5 f9 c5 c0 00}
000eh movsx rax,ax                            ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[4]{48 0f bf c0}
0012h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; uint vhead<uint>(Vector128<uint> src), hex://vfuncs/generic?vhead#vhead_g[32u](v128x32u)
; vhead_g[32u](v128x32u)[14] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x7e,0xc0,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovd eax,xmm0                          ; VMOVD r/m32, xmm1 || VEX.128.66.0F.W0 7E /r || encoded[4]{c5 f9 7e c0}
000dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; int vhead<int>(Vector128<int> src), hex://vfuncs/generic?vhead#vhead_g[32i](v128x32i)
; vhead_g[32i](v128x32i)[14] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x7e,0xc0,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovd eax,xmm0                          ; VMOVD r/m32, xmm1 || VEX.128.66.0F.W0 7E /r || encoded[4]{c5 f9 7e c0}
000dh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; ulong vhead<ulong>(Vector128<ulong> src), hex://vfuncs/generic?vhead#vhead_g[64u](v128x64u)
; vhead_g[64u](v128x64u)[15] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc4,0xe1,0xf9,0x7e,0xc0,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovq rax,xmm0                          ; VMOVQ r/m64, xmm1 || VEX.128.66.0F.W1 7E /r || encoded[5]{c4 e1 f9 7e c0}
000eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; long vhead<long>(Vector128<long> src), hex://vfuncs/generic?vhead#vhead_g[64i](v128x64i)
; vhead_g[64i](v128x64i)[15] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc4,0xe1,0xf9,0x7e,0xc0,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h vmovq rax,xmm0                          ; VMOVQ r/m64, xmm1 || VEX.128.66.0F.W1 7E /r || encoded[5]{c4 e1 f9 7e c0}
000eh ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; float vhead<float>(Vector128<float> src), hex://vfuncs/generic?vhead#vhead_g[32f](v128x32f)
; vhead_g[32f](v128x32f)[10] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; double vhead<double>(Vector128<double> src), hex://vfuncs/generic?vhead#vhead_g[64f](v128x64f)
; vhead_g[64f](v128x64f)[10] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x01,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
0009h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> vcell<byte>(Vector128<byte> src, int index, byte value), hex://vfuncs/generic?vcell#vcell_g[8u](v128x8u,32i,8u)
; vcell_g[8u](v128x8u,32i,8u)[63] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x02,0x41,0x83,0xf8,0x10,0x73,0x24,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0x44,0x88,0x0c,0x10,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa9,0xaf,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
000bh cmp r8d,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 10}
000fh jae short 0035h                         ; JAE rel8 || 73 cb || encoded[2]{73 24}
0011h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0017h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
001fh mov [rax+rdx],r9b                       ; MOV r/m8, r8 || 88 /r || encoded[4]{44 88 0c 10}
0023h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
0029h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0030h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0034h ret                                     ; RET || C3 || encoded[1]{c3}
0035h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003ah call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a9 af 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> vcell<sbyte>(Vector128<sbyte> src, int index, sbyte value), hex://vfuncs/generic?vcell#vcell_g[8i](v128x8i,32i,8i)
; vcell_g[8i](v128x8i,32i,8i)[63] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x02,0x41,0x83,0xf8,0x10,0x73,0x24,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0x44,0x88,0x0c,0x10,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x49,0xaf,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
000bh cmp r8d,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 10}
000fh jae short 0035h                         ; JAE rel8 || 73 cb || encoded[2]{73 24}
0011h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0017h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
001fh mov [rax+rdx],r9b                       ; MOV r/m8, r8 || 88 /r || encoded[4]{44 88 0c 10}
0023h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
0029h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0030h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0034h ret                                     ; RET || C3 || encoded[1]{c3}
0035h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003ah call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 49 af 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> vcell<ushort>(Vector128<ushort> src, int index, ushort value), hex://vfuncs/generic?vcell#vcell_g[16u](v128x16u,32i,16u)
; vcell_g[16u](v128x16u,32i,16u)[64] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x02,0x41,0x83,0xf8,0x08,0x73,0x25,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0x66,0x44,0x89,0x0c,0x50,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe8,0xae,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
000bh cmp r8d,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 08}
000fh jae short 0036h                         ; JAE rel8 || 73 cb || encoded[2]{73 25}
0011h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0017h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
001fh mov [rax+rdx*2],r9w                     ; MOV r/m16, r16 || o16 89 /r || encoded[5]{66 44 89 0c 50}
0024h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002ah vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0035h ret                                     ; RET || C3 || encoded[1]{c3}
0036h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e8 ae 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> vcell<short>(Vector128<short> src, int index, short value), hex://vfuncs/generic?vcell#vcell_g[16i](v128x16i,32i,16i)
; vcell_g[16i](v128x16i,32i,16i)[64] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x02,0x41,0x83,0xf8,0x08,0x73,0x25,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0x66,0x44,0x89,0x0c,0x50,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x88,0xae,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
000bh cmp r8d,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 08}
000fh jae short 0036h                         ; JAE rel8 || 73 cb || encoded[2]{73 25}
0011h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0017h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
001fh mov [rax+rdx*2],r9w                     ; MOV r/m16, r16 || o16 89 /r || encoded[5]{66 44 89 0c 50}
0024h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002ah vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0035h ret                                     ; RET || C3 || encoded[1]{c3}
0036h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 88 ae 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> vcell<uint>(Vector128<uint> src, int index, uint value), hex://vfuncs/generic?vcell#vcell_g[32u](v128x32u,32i,32u)
; vcell_g[32u](v128x32u,32i,32u)[63] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x02,0x41,0x83,0xf8,0x04,0x73,0x24,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0x44,0x89,0x0c,0x90,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x29,0xae,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
000bh cmp r8d,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 04}
000fh jae short 0035h                         ; JAE rel8 || 73 cb || encoded[2]{73 24}
0011h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0017h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
001fh mov [rax+rdx*4],r9d                     ; MOV r/m32, r32 || o32 89 /r || encoded[4]{44 89 0c 90}
0023h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
0029h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0030h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0034h ret                                     ; RET || C3 || encoded[1]{c3}
0035h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003ah call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 29 ae 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> vcell<int>(Vector128<int> src, int index, int value), hex://vfuncs/generic?vcell#vcell_g[32i](v128x32i,32i,32i)
; vcell_g[32i](v128x32i,32i,32i)[63] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x02,0x41,0x83,0xf8,0x04,0x73,0x24,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0x44,0x89,0x0c,0x90,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc9,0xad,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
000bh cmp r8d,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 04}
000fh jae short 0035h                         ; JAE rel8 || 73 cb || encoded[2]{73 24}
0011h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0017h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
001fh mov [rax+rdx*4],r9d                     ; MOV r/m32, r32 || o32 89 /r || encoded[4]{44 89 0c 90}
0023h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
0029h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0030h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0034h ret                                     ; RET || C3 || encoded[1]{c3}
0035h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003ah call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c9 ad 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> vcell<ulong>(Vector128<ulong> src, int index, ulong value), hex://vfuncs/generic?vcell#vcell_g[64u](v128x64u,32i,64u)
; vcell_g[64u](v128x64u,32i,64u)[63] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x02,0x41,0x83,0xf8,0x02,0x73,0x24,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0x4c,0x89,0x0c,0xd0,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x69,0xad,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
000bh cmp r8d,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 02}
000fh jae short 0035h                         ; JAE rel8 || 73 cb || encoded[2]{73 24}
0011h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0017h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
001fh mov [rax+rdx*8],r9                      ; MOV r/m64, r64 || REX.W 89 /r || encoded[4]{4c 89 0c d0}
0023h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
0029h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0030h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0034h ret                                     ; RET || C3 || encoded[1]{c3}
0035h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003ah call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 69 ad 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> vcell<long>(Vector128<long> src, int index, long value), hex://vfuncs/generic?vcell#vcell_g[64i](v128x64i,32i,64i)
; vcell_g[64i](v128x64i,32i,64i)[63] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x02,0x41,0x83,0xf8,0x02,0x73,0x24,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0x4c,0x89,0x0c,0xd0,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x09,0xad,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
000bh cmp r8d,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 02}
000fh jae short 0035h                         ; JAE rel8 || 73 cb || encoded[2]{73 24}
0011h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0017h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
001fh mov [rax+rdx*8],r9                      ; MOV r/m64, r64 || REX.W 89 /r || encoded[4]{4c 89 0c d0}
0023h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
0029h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0030h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0034h ret                                     ; RET || C3 || encoded[1]{c3}
0035h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003ah call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 09 ad 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> vcell<float>(Vector128<float> src, int index, float value), hex://vfuncs/generic?vcell#vcell_g[32f](v128x32f,32i,32f)
; vcell_g[32f](v128x32f,32i,32f)[64] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x02,0x41,0x83,0xf8,0x04,0x73,0x25,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0xc5,0xfa,0x11,0x1c,0x90,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa8,0xac,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
000bh cmp r8d,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 04}
000fh jae short 0036h                         ; JAE rel8 || 73 cb || encoded[2]{73 25}
0011h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0017h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
001fh vmovss dword ptr [rax+rdx*4],xmm3       ; VMOVSS m32, xmm1 || VEX.LIG.F3.0F.WIG 11 /r || encoded[5]{c5 fa 11 1c 90}
0024h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002ah vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0035h ret                                     ; RET || C3 || encoded[1]{c3}
0036h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a8 ac 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> vcell<double>(Vector128<double> src, int index, double value), hex://vfuncs/generic?vcell#vcell_g[64f](v128x64f,32i,64f)
; vcell_g[64f](v128x64f,32i,64f)[64] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x02,0x41,0x83,0xf8,0x02,0x73,0x25,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0xc5,0xfb,0x11,0x1c,0xd0,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x48,0xac,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
000bh cmp r8d,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 02}
000fh jae short 0036h                         ; JAE rel8 || 73 cb || encoded[2]{73 25}
0011h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0017h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001ch movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
001fh vmovsd qword ptr [rax+rdx*8],xmm3       ; VMOVSD m64, xmm1 || VEX.LIG.F2.0F.WIG 11 /r || encoded[5]{c5 fb 11 1c d0}
0024h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002ah vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0035h ret                                     ; RET || C3 || encoded[1]{c3}
0036h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 48 ac 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<byte> vcell<byte>(byte src, int index, Vector128<byte> dst), hex://vfuncs/generic?vcell#vcell_g[8u](8u,32i,v128x8u)
; vcell_g[8u](8u,32i,v128x8u)[64] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc4,0xc1,0x79,0x10,0x01,0x41,0x83,0xf8,0x10,0x73,0x24,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x42,0x88,0x14,0x00,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe8,0xab,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[r9]                       ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[5]{c4 c1 79 10 01}
000ch cmp r8d,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 10}
0010h jae short 0036h                         ; JAE rel8 || 73 cb || encoded[2]{73 24}
0012h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8],dl                         ; MOV r/m8, r8 || 88 /r || encoded[4]{42 88 14 00}
0024h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002ah vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0035h ret                                     ; RET || C3 || encoded[1]{c3}
0036h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e8 ab 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> vcell<sbyte>(sbyte src, int index, Vector128<sbyte> dst), hex://vfuncs/generic?vcell#vcell_g[8i](8i,32i,v128x8i)
; vcell_g[8i](8i,32i,v128x8i)[64] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc4,0xc1,0x79,0x10,0x01,0x41,0x83,0xf8,0x10,0x73,0x24,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x42,0x88,0x14,0x00,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x88,0xab,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[r9]                       ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[5]{c4 c1 79 10 01}
000ch cmp r8d,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 10}
0010h jae short 0036h                         ; JAE rel8 || 73 cb || encoded[2]{73 24}
0012h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8],dl                         ; MOV r/m8, r8 || 88 /r || encoded[4]{42 88 14 00}
0024h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002ah vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0035h ret                                     ; RET || C3 || encoded[1]{c3}
0036h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 88 ab 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ushort> vcell<ushort>(ushort src, int index, Vector128<ushort> dst), hex://vfuncs/generic?vcell#vcell_g[16u](16u,32i,v128x16u)
; vcell_g[16u](16u,32i,v128x16u)[65] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc4,0xc1,0x79,0x10,0x01,0x41,0x83,0xf8,0x08,0x73,0x25,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x66,0x42,0x89,0x14,0x40,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x27,0xab,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[r9]                       ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[5]{c4 c1 79 10 01}
000ch cmp r8d,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 08}
0010h jae short 0037h                         ; JAE rel8 || 73 cb || encoded[2]{73 25}
0012h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8*2],dx                       ; MOV r/m16, r16 || o16 89 /r || encoded[5]{66 42 89 14 40}
0025h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002bh vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002fh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0032h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0036h ret                                     ; RET || C3 || encoded[1]{c3}
0037h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 27 ab 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<short> vcell<short>(short src, int index, Vector128<short> dst), hex://vfuncs/generic?vcell#vcell_g[16i](16i,32i,v128x16i)
; vcell_g[16i](16i,32i,v128x16i)[65] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc4,0xc1,0x79,0x10,0x01,0x41,0x83,0xf8,0x08,0x73,0x25,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x66,0x42,0x89,0x14,0x40,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc7,0xaa,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[r9]                       ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[5]{c4 c1 79 10 01}
000ch cmp r8d,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 08}
0010h jae short 0037h                         ; JAE rel8 || 73 cb || encoded[2]{73 25}
0012h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8*2],dx                       ; MOV r/m16, r16 || o16 89 /r || encoded[5]{66 42 89 14 40}
0025h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002bh vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002fh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0032h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0036h ret                                     ; RET || C3 || encoded[1]{c3}
0037h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c7 aa 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<uint> vcell<uint>(uint src, int index, Vector128<uint> dst), hex://vfuncs/generic?vcell#vcell_g[32u](32u,32i,v128x32u)
; vcell_g[32u](32u,32i,v128x32u)[64] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc4,0xc1,0x79,0x10,0x01,0x41,0x83,0xf8,0x04,0x73,0x24,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x42,0x89,0x14,0x80,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x68,0xaa,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[r9]                       ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[5]{c4 c1 79 10 01}
000ch cmp r8d,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 04}
0010h jae short 0036h                         ; JAE rel8 || 73 cb || encoded[2]{73 24}
0012h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8*4],edx                      ; MOV r/m32, r32 || o32 89 /r || encoded[4]{42 89 14 80}
0024h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002ah vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0035h ret                                     ; RET || C3 || encoded[1]{c3}
0036h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 68 aa 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<int> vcell<int>(int src, int index, Vector128<int> dst), hex://vfuncs/generic?vcell#vcell_g[32i](32i,32i,v128x32i)
; vcell_g[32i](32i,32i,v128x32i)[64] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc4,0xc1,0x79,0x10,0x01,0x41,0x83,0xf8,0x04,0x73,0x24,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x42,0x89,0x14,0x80,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x08,0xaa,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[r9]                       ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[5]{c4 c1 79 10 01}
000ch cmp r8d,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 04}
0010h jae short 0036h                         ; JAE rel8 || 73 cb || encoded[2]{73 24}
0012h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8*4],edx                      ; MOV r/m32, r32 || o32 89 /r || encoded[4]{42 89 14 80}
0024h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002ah vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0035h ret                                     ; RET || C3 || encoded[1]{c3}
0036h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 08 aa 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<ulong> vcell<ulong>(ulong src, int index, Vector128<ulong> dst), hex://vfuncs/generic?vcell#vcell_g[64u](64u,32i,v128x64u)
; vcell_g[64u](64u,32i,v128x64u)[64] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc4,0xc1,0x79,0x10,0x01,0x41,0x83,0xf8,0x02,0x73,0x24,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x4a,0x89,0x14,0xc0,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa8,0xa9,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[r9]                       ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[5]{c4 c1 79 10 01}
000ch cmp r8d,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 02}
0010h jae short 0036h                         ; JAE rel8 || 73 cb || encoded[2]{73 24}
0012h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8*8],rdx                      ; MOV r/m64, r64 || REX.W 89 /r || encoded[4]{4a 89 14 c0}
0024h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002ah vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0035h ret                                     ; RET || C3 || encoded[1]{c3}
0036h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a8 a9 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<long> vcell<long>(long src, int index, Vector128<long> dst), hex://vfuncs/generic?vcell#vcell_g[64i](64i,32i,v128x64i)
; vcell_g[64i](64i,32i,v128x64i)[64] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc4,0xc1,0x79,0x10,0x01,0x41,0x83,0xf8,0x02,0x73,0x24,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x4a,0x89,0x14,0xc0,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x48,0xa9,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[r9]                       ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[5]{c4 c1 79 10 01}
000ch cmp r8d,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 02}
0010h jae short 0036h                         ; JAE rel8 || 73 cb || encoded[2]{73 24}
0012h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8*8],rdx                      ; MOV r/m64, r64 || REX.W 89 /r || encoded[4]{4a 89 14 c0}
0024h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002ah vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0035h ret                                     ; RET || C3 || encoded[1]{c3}
0036h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 48 a9 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<float> vcell<float>(float src, int index, Vector128<float> dst), hex://vfuncs/generic?vcell#vcell_g[32f](32f,32i,v128x32f)
; vcell_g[32f](32f,32i,v128x32f)[65] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc4,0xc1,0x79,0x10,0x01,0x41,0x83,0xf8,0x04,0x73,0x25,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0xc5,0xfa,0x11,0x0c,0x90,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe7,0xa8,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[r9]                       ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[5]{c4 c1 79 10 01}
000ch cmp r8d,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 04}
0010h jae short 0037h                         ; JAE rel8 || 73 cb || encoded[2]{73 25}
0012h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0020h vmovss dword ptr [rax+rdx*4],xmm1       ; VMOVSS m32, xmm1 || VEX.LIG.F3.0F.WIG 11 /r || encoded[5]{c5 fa 11 0c 90}
0025h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002bh vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002fh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0032h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0036h ret                                     ; RET || C3 || encoded[1]{c3}
0037h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e7 a8 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<double> vcell<double>(double src, int index, Vector128<double> dst), hex://vfuncs/generic?vcell#vcell_g[64f](64f,32i,v128x64f)
; vcell_g[64f](64f,32i,v128x64f)[65] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc4,0xc1,0x79,0x10,0x01,0x41,0x83,0xf8,0x02,0x73,0x25,0xc5,0xf9,0x29,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0xc5,0xfb,0x11,0x0c,0xd0,0xc5,0xf9,0x28,0x44,0x24,0x20,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x87,0xa8,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[r9]                       ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[5]{c4 c1 79 10 01}
000ch cmp r8d,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 02}
0010h jae short 0037h                         ; JAE rel8 || 73 cb || encoded[2]{73 25}
0012h vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0020h vmovsd qword ptr [rax+rdx*8],xmm1       ; VMOVSD m64, xmm1 || VEX.LIG.F2.0F.WIG 11 /r || encoded[5]{c5 fb 11 0c d0}
0025h vmovapd xmm0,[rsp+20h]                  ; VMOVAPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 28 /r || encoded[6]{c5 f9 28 44 24 20}
002bh vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
002fh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0032h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0036h ret                                     ; RET || C3 || encoded[1]{c3}
0037h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 87 a8 08 ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell<byte>(Vector256<byte> src, int index), hex://vfuncs/generic?vcell#vcell_g[8u](v256x8u,32i)
; vcell_g[8u](v256x8u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x24,0xa4,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 24 a4 08 ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell<sbyte>(Vector256<sbyte> src, int index), hex://vfuncs/generic?vcell#vcell_g[8i](v256x8i,32i)
; vcell_g[8i](v256x8i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd3,0xa3,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d3 a3 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell<ushort>(Vector256<ushort> src, int index), hex://vfuncs/generic?vcell#vcell_g[16u](v256x16u,32i)
; vcell_g[16u](v256x16u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x84,0xa3,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 84 a3 08 ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell<short>(Vector256<short> src, int index), hex://vfuncs/generic?vcell#vcell_g[16i](v256x16i,32i)
; vcell_g[16i](v256x16i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x33,0xa3,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 33 a3 08 ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell<uint>(Vector256<uint> src, int index), hex://vfuncs/generic?vcell#vcell_g[32u](v256x32u,32i)
; vcell_g[32u](v256x32u,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe5,0xa2,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e5 a2 08 ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell<int>(Vector256<int> src, int index), hex://vfuncs/generic?vcell#vcell_g[32i](v256x32i,32i)
; vcell_g[32i](v256x32i,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x95,0xa2,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 95 a2 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell<ulong>(Vector256<ulong> src, int index), hex://vfuncs/generic?vcell#vcell_g[64u](v256x64u,32i)
; vcell_g[64u](v256x64u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x44,0xa2,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 44 a2 08 ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell<long>(Vector256<long> src, int index), hex://vfuncs/generic?vcell#vcell_g[64i](v256x64i,32i)
; vcell_g[64i](v256x64i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf4,0xa1,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f4 a1 08 ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell<float>(Vector256<float> src, int index), hex://vfuncs/generic?vcell#vcell_g[32f](v256x32f,32i)
; vcell_g[32f](v256x32f,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa3,0xa1,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a3 a1 08 ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell<double>(Vector256<double> src, int index), hex://vfuncs/generic?vcell#vcell_g[64f](v256x64f,32i)
; vcell_g[64f](v256x64f,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x53,0xa1,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 53 a1 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector256<byte> vcell<byte>(byte src, int index, Vector256<byte> dst), hex://vfuncs/generic?vcell#vcell_g[8u](8u,32i,v256x8u)
; vcell_g[8u](8u,32i,v256x8u)[67] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc4,0xc1,0x7d,0x10,0x01,0x41,0x83,0xf8,0x20,0x73,0x27,0xc5,0xfd,0x11,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x42,0x88,0x14,0x00,0xc5,0xfd,0x10,0x44,0x24,0x20,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf5,0xa0,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[r9]                       ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c4 c1 7d 10 01}
000ch cmp r8d,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 20}
0010h jae short 0039h                         ; JAE rel8 || 73 cb || encoded[2]{73 27}
0012h vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8],dl                         ; MOV r/m8, r8 || 88 /r || encoded[4]{42 88 14 00}
0024h vmovupd ymm0,[rsp+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[6]{c5 fd 10 44 24 20}
002ah vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0034h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0038h ret                                     ; RET || C3 || encoded[1]{c3}
0039h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f5 a0 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector256<sbyte> vcell<sbyte>(sbyte src, int index, Vector256<sbyte> dst), hex://vfuncs/generic?vcell#vcell_g[8i](8i,32i,v256x8i)
; vcell_g[8i](8i,32i,v256x8i)[67] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc4,0xc1,0x7d,0x10,0x01,0x41,0x83,0xf8,0x20,0x73,0x27,0xc5,0xfd,0x11,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x42,0x88,0x14,0x00,0xc5,0xfd,0x10,0x44,0x24,0x20,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x95,0xa0,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[r9]                       ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c4 c1 7d 10 01}
000ch cmp r8d,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 20}
0010h jae short 0039h                         ; JAE rel8 || 73 cb || encoded[2]{73 27}
0012h vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8],dl                         ; MOV r/m8, r8 || 88 /r || encoded[4]{42 88 14 00}
0024h vmovupd ymm0,[rsp+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[6]{c5 fd 10 44 24 20}
002ah vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0034h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0038h ret                                     ; RET || C3 || encoded[1]{c3}
0039h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 95 a0 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ushort> vcell<ushort>(ushort src, int index, Vector256<ushort> dst), hex://vfuncs/generic?vcell#vcell_g[16u](16u,32i,v256x16u)
; vcell_g[16u](16u,32i,v256x16u)[68] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc4,0xc1,0x7d,0x10,0x01,0x41,0x83,0xf8,0x10,0x73,0x28,0xc5,0xfd,0x11,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x66,0x42,0x89,0x14,0x40,0xc5,0xfd,0x10,0x44,0x24,0x20,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x34,0xa0,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[r9]                       ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c4 c1 7d 10 01}
000ch cmp r8d,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 10}
0010h jae short 003ah                         ; JAE rel8 || 73 cb || encoded[2]{73 28}
0012h vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8*2],dx                       ; MOV r/m16, r16 || o16 89 /r || encoded[5]{66 42 89 14 40}
0025h vmovupd ymm0,[rsp+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[6]{c5 fd 10 44 24 20}
002bh vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
002fh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0032h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0035h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0039h ret                                     ; RET || C3 || encoded[1]{c3}
003ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 34 a0 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector256<short> vcell<short>(short src, int index, Vector256<short> dst), hex://vfuncs/generic?vcell#vcell_g[16i](16i,32i,v256x16i)
; vcell_g[16i](16i,32i,v256x16i)[68] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc4,0xc1,0x7d,0x10,0x01,0x41,0x83,0xf8,0x10,0x73,0x28,0xc5,0xfd,0x11,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x66,0x42,0x89,0x14,0x40,0xc5,0xfd,0x10,0x44,0x24,0x20,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd4,0x9f,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[r9]                       ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c4 c1 7d 10 01}
000ch cmp r8d,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 10}
0010h jae short 003ah                         ; JAE rel8 || 73 cb || encoded[2]{73 28}
0012h vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8*2],dx                       ; MOV r/m16, r16 || o16 89 /r || encoded[5]{66 42 89 14 40}
0025h vmovupd ymm0,[rsp+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[6]{c5 fd 10 44 24 20}
002bh vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
002fh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0032h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0035h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0039h ret                                     ; RET || C3 || encoded[1]{c3}
003ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d4 9f 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector256<uint> vcell<uint>(uint src, int index, Vector256<uint> dst), hex://vfuncs/generic?vcell#vcell_g[32u](32u,32i,v256x32u)
; vcell_g[32u](32u,32i,v256x32u)[67] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc4,0xc1,0x7d,0x10,0x01,0x41,0x83,0xf8,0x08,0x73,0x27,0xc5,0xfd,0x11,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x42,0x89,0x14,0x80,0xc5,0xfd,0x10,0x44,0x24,0x20,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x75,0x9f,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[r9]                       ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c4 c1 7d 10 01}
000ch cmp r8d,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 08}
0010h jae short 0039h                         ; JAE rel8 || 73 cb || encoded[2]{73 27}
0012h vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8*4],edx                      ; MOV r/m32, r32 || o32 89 /r || encoded[4]{42 89 14 80}
0024h vmovupd ymm0,[rsp+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[6]{c5 fd 10 44 24 20}
002ah vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0034h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0038h ret                                     ; RET || C3 || encoded[1]{c3}
0039h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 75 9f 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector256<int> vcell<int>(int src, int index, Vector256<int> dst), hex://vfuncs/generic?vcell#vcell_g[32i](32i,32i,v256x32i)
; vcell_g[32i](32i,32i,v256x32i)[67] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc4,0xc1,0x7d,0x10,0x01,0x41,0x83,0xf8,0x08,0x73,0x27,0xc5,0xfd,0x11,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x42,0x89,0x14,0x80,0xc5,0xfd,0x10,0x44,0x24,0x20,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x15,0x9f,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[r9]                       ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c4 c1 7d 10 01}
000ch cmp r8d,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 08}
0010h jae short 0039h                         ; JAE rel8 || 73 cb || encoded[2]{73 27}
0012h vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8*4],edx                      ; MOV r/m32, r32 || o32 89 /r || encoded[4]{42 89 14 80}
0024h vmovupd ymm0,[rsp+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[6]{c5 fd 10 44 24 20}
002ah vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0034h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0038h ret                                     ; RET || C3 || encoded[1]{c3}
0039h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 15 9f 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector256<ulong> vcell<ulong>(ulong src, int index, Vector256<ulong> dst), hex://vfuncs/generic?vcell#vcell_g[64u](64u,32i,v256x64u)
; vcell_g[64u](64u,32i,v256x64u)[67] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc4,0xc1,0x7d,0x10,0x01,0x41,0x83,0xf8,0x04,0x73,0x27,0xc5,0xfd,0x11,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x4a,0x89,0x14,0xc0,0xc5,0xfd,0x10,0x44,0x24,0x20,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb5,0x9e,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[r9]                       ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c4 c1 7d 10 01}
000ch cmp r8d,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 04}
0010h jae short 0039h                         ; JAE rel8 || 73 cb || encoded[2]{73 27}
0012h vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8*8],rdx                      ; MOV r/m64, r64 || REX.W 89 /r || encoded[4]{4a 89 14 c0}
0024h vmovupd ymm0,[rsp+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[6]{c5 fd 10 44 24 20}
002ah vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0034h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0038h ret                                     ; RET || C3 || encoded[1]{c3}
0039h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b5 9e 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector256<long> vcell<long>(long src, int index, Vector256<long> dst), hex://vfuncs/generic?vcell#vcell_g[64i](64i,32i,v256x64i)
; vcell_g[64i](64i,32i,v256x64i)[67] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc4,0xc1,0x7d,0x10,0x01,0x41,0x83,0xf8,0x04,0x73,0x27,0xc5,0xfd,0x11,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x4d,0x63,0xc0,0x4a,0x89,0x14,0xc0,0xc5,0xfd,0x10,0x44,0x24,0x20,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x55,0x9e,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[r9]                       ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c4 c1 7d 10 01}
000ch cmp r8d,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 04}
0010h jae short 0039h                         ; JAE rel8 || 73 cb || encoded[2]{73 27}
0012h vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd r8,r8d                           ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{4d 63 c0}
0020h mov [rax+r8*8],rdx                      ; MOV r/m64, r64 || REX.W 89 /r || encoded[4]{4a 89 14 c0}
0024h vmovupd ymm0,[rsp+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[6]{c5 fd 10 44 24 20}
002ah vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
002eh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0031h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0034h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0038h ret                                     ; RET || C3 || encoded[1]{c3}
0039h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 55 9e 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector256<float> vcell<float>(float src, int index, Vector256<float> dst), hex://vfuncs/generic?vcell#vcell_g[32f](32f,32i,v256x32f)
; vcell_g[32f](32f,32i,v256x32f)[68] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc4,0xc1,0x7d,0x10,0x01,0x41,0x83,0xf8,0x08,0x73,0x28,0xc5,0xfd,0x11,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0xc5,0xfa,0x11,0x0c,0x90,0xc5,0xfd,0x10,0x44,0x24,0x20,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf4,0x9d,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[r9]                       ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c4 c1 7d 10 01}
000ch cmp r8d,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 08}
0010h jae short 003ah                         ; JAE rel8 || 73 cb || encoded[2]{73 28}
0012h vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0020h vmovss dword ptr [rax+rdx*4],xmm1       ; VMOVSS m32, xmm1 || VEX.LIG.F3.0F.WIG 11 /r || encoded[5]{c5 fa 11 0c 90}
0025h vmovupd ymm0,[rsp+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[6]{c5 fd 10 44 24 20}
002bh vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
002fh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0032h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0035h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0039h ret                                     ; RET || C3 || encoded[1]{c3}
003ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f4 9d 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector256<double> vcell<double>(double src, int index, Vector256<double> dst), hex://vfuncs/generic?vcell#vcell_g[64f](64f,32i,v256x64f)
; vcell_g[64f](64f,32i,v256x64f)[68] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc4,0xc1,0x7d,0x10,0x01,0x41,0x83,0xf8,0x04,0x73,0x28,0xc5,0xfd,0x11,0x44,0x24,0x20,0x48,0x8d,0x44,0x24,0x20,0x49,0x63,0xd0,0xc5,0xfb,0x11,0x0c,0xd0,0xc5,0xfd,0x10,0x44,0x24,0x20,0xc5,0xfd,0x11,0x01,0x48,0x8b,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x94,0x9d,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[r9]                       ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[5]{c4 c1 7d 10 01}
000ch cmp r8d,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[4]{41 83 f8 04}
0010h jae short 003ah                         ; JAE rel8 || 73 cb || encoded[2]{73 28}
0012h vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0018h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001dh movsxd rdx,r8d                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{49 63 d0}
0020h vmovsd qword ptr [rax+rdx*8],xmm1       ; VMOVSD m64, xmm1 || VEX.LIG.F2.0F.WIG 11 /r || encoded[5]{c5 fb 11 0c d0}
0025h vmovupd ymm0,[rsp+20h]                  ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[6]{c5 fd 10 44 24 20}
002bh vmovupd [rcx],ymm0                      ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[4]{c5 fd 11 01}
002fh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0032h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0035h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0039h ret                                     ; RET || C3 || encoded[1]{c3}
003ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
003fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 94 9d 08 ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<byte>(Vector128<byte> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[8u](v128x8u,32i)
; vcell8i_g[8u](v128x8u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x46,0x9d,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 46 9d 08 ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<sbyte>(Vector128<sbyte> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[8i](v128x8i,32i)
; vcell8i_g[8i](v128x8i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf6,0x9c,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f6 9c 08 ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<ushort>(Vector128<ushort> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[16u](v128x16u,32i)
; vcell8i_g[16u](v128x16u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa6,0x9c,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a6 9c 08 ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<short>(Vector128<short> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[16i](v128x16i,32i)
; vcell8i_g[16i](v128x16i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x46,0x98,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 46 98 08 ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<uint>(Vector128<uint> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[32u](v128x32u,32i)
; vcell8i_g[32u](v128x32u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf6,0x97,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f6 97 08 ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<int>(Vector128<int> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[32i](v128x32i,32i)
; vcell8i_g[32i](v128x32i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa6,0x97,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a6 97 08 ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<ulong>(Vector128<ulong> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[64u](v128x64u,32i)
; vcell8i_g[64u](v128x64u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x56,0x97,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 56 97 08 ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<long>(Vector128<long> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[64i](v128x64i,32i)
; vcell8i_g[64i](v128x64i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x06,0x97,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 06 97 08 ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<float>(Vector128<float> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[32f](v128x32f,32i)
; vcell8i_g[32f](v128x32f,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb6,0x96,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b6 96 08 ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<double>(Vector128<double> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[64f](v128x64f,32i)
; vcell8i_g[64f](v128x64f,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x66,0x96,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 66 96 08 ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<byte>(Vector128<byte> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[8u](v128x8u,32i)
; vcell8_g[8u](v128x8u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x17,0x96,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 17 96 08 ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<sbyte>(Vector128<sbyte> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[8i](v128x8i,32i)
; vcell8_g[8i](v128x8i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc7,0x95,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c7 95 08 ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<ushort>(Vector128<ushort> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[16u](v128x16u,32i)
; vcell8_g[16u](v128x16u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x77,0x95,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 77 95 08 ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<short>(Vector128<short> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[16i](v128x16i,32i)
; vcell8_g[16i](v128x16i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x27,0x95,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 27 95 08 ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<uint>(Vector128<uint> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[32u](v128x32u,32i)
; vcell8_g[32u](v128x32u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd7,0x94,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d7 94 08 ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<int>(Vector128<int> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[32i](v128x32i,32i)
; vcell8_g[32i](v128x32i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x87,0x94,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 87 94 08 ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<ulong>(Vector128<ulong> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[64u](v128x64u,32i)
; vcell8_g[64u](v128x64u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x37,0x94,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 37 94 08 ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<long>(Vector128<long> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[64i](v128x64i,32i)
; vcell8_g[64i](v128x64i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe7,0x93,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e7 93 08 ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<float>(Vector128<float> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[32f](v128x32f,32i)
; vcell8_g[32f](v128x32f,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x97,0x93,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 97 93 08 ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<double>(Vector128<double> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[64f](v128x64f,32i)
; vcell8_g[64f](v128x64f,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x47,0x93,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 47 93 08 ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<byte>(Vector128<byte> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[8u](v128x8u,32i)
; vcell16i_g[8u](v128x8u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf6,0x92,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f6 92 08 ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<sbyte>(Vector128<sbyte> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[8i](v128x8i,32i)
; vcell16i_g[8i](v128x8i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa6,0x92,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a6 92 08 ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<ushort>(Vector128<ushort> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[16u](v128x16u,32i)
; vcell16i_g[16u](v128x16u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x56,0x92,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 56 92 08 ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<short>(Vector128<short> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[16i](v128x16i,32i)
; vcell16i_g[16i](v128x16i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x06,0x92,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 06 92 08 ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<uint>(Vector128<uint> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[32u](v128x32u,32i)
; vcell16i_g[32u](v128x32u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb6,0x91,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b6 91 08 ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<int>(Vector128<int> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[32i](v128x32i,32i)
; vcell16i_g[32i](v128x32i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x66,0x91,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 66 91 08 ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<ulong>(Vector128<ulong> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[64u](v128x64u,32i)
; vcell16i_g[64u](v128x64u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x16,0x91,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 16 91 08 ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<long>(Vector128<long> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[64i](v128x64i,32i)
; vcell16i_g[64i](v128x64i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc6,0x90,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c6 90 08 ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<float>(Vector128<float> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[32f](v128x32f,32i)
; vcell16i_g[32f](v128x32f,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x76,0x90,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 76 90 08 ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<double>(Vector128<double> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[64f](v128x64f,32i)
; vcell16i_g[64f](v128x64f,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x12,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x26,0x90,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 26 90 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<byte>(Vector128<byte> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[8u](v128x8u,32i)
; vcell16_g[8u](v128x8u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc7,0x8b,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c7 8b 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<sbyte>(Vector128<sbyte> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[8i](v128x8i,32i)
; vcell16_g[8i](v128x8i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x77,0x8b,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 77 8b 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<ushort>(Vector128<ushort> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[16u](v128x16u,32i)
; vcell16_g[16u](v128x16u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x27,0x8b,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 27 8b 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<short>(Vector128<short> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[16i](v128x16i,32i)
; vcell16_g[16i](v128x16i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd7,0x8a,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d7 8a 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<uint>(Vector128<uint> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[32u](v128x32u,32i)
; vcell16_g[32u](v128x32u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x87,0x8a,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 87 8a 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<int>(Vector128<int> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[32i](v128x32i,32i)
; vcell16_g[32i](v128x32i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x37,0x8a,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 37 8a 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<ulong>(Vector128<ulong> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[64u](v128x64u,32i)
; vcell16_g[64u](v128x64u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe7,0x89,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e7 89 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<long>(Vector128<long> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[64i](v128x64i,32i)
; vcell16_g[64i](v128x64i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x97,0x89,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 97 89 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<float>(Vector128<float> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[32f](v128x32f,32i)
; vcell16_g[32f](v128x32f,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x47,0x89,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 47 89 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<double>(Vector128<double> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[64f](v128x64f,32i)
; vcell16_g[64f](v128x64f,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf7,0x88,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f7 88 08 ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<byte>(Vector128<byte> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[8u](v128x8u,32i)
; vcell32i_g[8u](v128x8u,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa8,0x88,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a8 88 08 ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<sbyte>(Vector128<sbyte> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[8i](v128x8i,32i)
; vcell32i_g[8i](v128x8i,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x58,0x88,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 58 88 08 ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<ushort>(Vector128<ushort> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[16u](v128x16u,32i)
; vcell32i_g[16u](v128x16u,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x08,0x88,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 08 88 08 ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<short>(Vector128<short> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[16i](v128x16i,32i)
; vcell32i_g[16i](v128x16i,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb8,0x87,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b8 87 08 ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<uint>(Vector128<uint> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[32u](v128x32u,32i)
; vcell32i_g[32u](v128x32u,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x68,0x87,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 68 87 08 ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<int>(Vector128<int> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[32i](v128x32i,32i)
; vcell32i_g[32i](v128x32i,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x18,0x87,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 18 87 08 ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<ulong>(Vector128<ulong> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[64u](v128x64u,32i)
; vcell32i_g[64u](v128x64u,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc8,0x86,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c8 86 08 ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<long>(Vector128<long> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[64i](v128x64i,32i)
; vcell32i_g[64i](v128x64i,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x78,0x86,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 78 86 08 ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<float>(Vector128<float> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[32f](v128x32f,32i)
; vcell32i_g[32f](v128x32f,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x28,0x86,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 28 86 08 ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<double>(Vector128<double> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[64f](v128x64f,32i)
; vcell32i_g[64f](v128x64f,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd8,0x85,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d8 85 08 ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<byte>(Vector128<byte> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[8u](v128x8u,32i)
; vcell32_g[8u](v128x8u,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x88,0x85,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 88 85 08 ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<sbyte>(Vector128<sbyte> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[8i](v128x8i,32i)
; vcell32_g[8i](v128x8i,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x38,0x85,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 38 85 08 ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<ushort>(Vector128<ushort> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[16u](v128x16u,32i)
; vcell32_g[16u](v128x16u,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe8,0x84,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e8 84 08 ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<short>(Vector128<short> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[16i](v128x16i,32i)
; vcell32_g[16i](v128x16i,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x98,0x84,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 98 84 08 ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<uint>(Vector128<uint> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[32u](v128x32u,32i)
; vcell32_g[32u](v128x32u,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x48,0x84,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 48 84 08 ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<int>(Vector128<int> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[32i](v128x32i,32i)
; vcell32_g[32i](v128x32i,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf8,0x83,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f8 83 08 ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<ulong>(Vector128<ulong> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[64u](v128x64u,32i)
; vcell32_g[64u](v128x64u,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa8,0x83,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a8 83 08 ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<long>(Vector128<long> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[64i](v128x64i,32i)
; vcell32_g[64i](v128x64i,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x58,0x83,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 58 83 08 ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<float>(Vector128<float> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[32f](v128x32f,32i)
; vcell32_g[32f](v128x32f,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x08,0x83,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 08 83 08 ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<double>(Vector128<double> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[64f](v128x64f,32i)
; vcell32_g[64f](v128x64f,32i)[48] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x10,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb8,0x82,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0026h                         ; JAE rel8 || 73 cb || encoded[2]{73 10}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0025h ret                                     ; RET || C3 || encoded[1]{c3}
0026h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002bh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b8 82 08 ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<byte>(Vector128<byte> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[8u](v128x8u,32i)
; vcell64i_g[8u](v128x8u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x67,0x82,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 67 82 08 ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<sbyte>(Vector128<sbyte> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[8i](v128x8i,32i)
; vcell64i_g[8i](v128x8i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x17,0x82,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 17 82 08 ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<ushort>(Vector128<ushort> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[16u](v128x16u,32i)
; vcell64i_g[16u](v128x16u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc7,0x81,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c7 81 08 ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<short>(Vector128<short> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[16i](v128x16i,32i)
; vcell64i_g[16i](v128x16i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x77,0x81,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 77 81 08 ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<uint>(Vector128<uint> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[32u](v128x32u,32i)
; vcell64i_g[32u](v128x32u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x27,0x81,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 27 81 08 ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<int>(Vector128<int> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[32i](v128x32i,32i)
; vcell64i_g[32i](v128x32i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd7,0x80,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d7 80 08 ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<ulong>(Vector128<ulong> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[64u](v128x64u,32i)
; vcell64i_g[64u](v128x64u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x87,0x7c,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 87 7c 08 ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<long>(Vector128<long> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[64i](v128x64i,32i)
; vcell64i_g[64i](v128x64i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x37,0x7c,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 37 7c 08 ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<float>(Vector128<float> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[32f](v128x32f,32i)
; vcell64i_g[32f](v128x32f,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe7,0x7b,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e7 7b 08 ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<double>(Vector128<double> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[64f](v128x64f,32i)
; vcell64i_g[64f](v128x64f,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x97,0x7b,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 97 7b 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<byte>(Vector128<byte> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[8u](v128x8u,32i)
; vcell64_g[8u](v128x8u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x47,0x7b,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 47 7b 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<sbyte>(Vector128<sbyte> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[8i](v128x8i,32i)
; vcell64_g[8i](v128x8i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf7,0x7a,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f7 7a 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<ushort>(Vector128<ushort> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[16u](v128x16u,32i)
; vcell64_g[16u](v128x16u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa7,0x7a,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a7 7a 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<short>(Vector128<short> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[16i](v128x16i,32i)
; vcell64_g[16i](v128x16i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x57,0x7a,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 57 7a 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<uint>(Vector128<uint> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[32u](v128x32u,32i)
; vcell64_g[32u](v128x32u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x07,0x7a,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 07 7a 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<int>(Vector128<int> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[32i](v128x32i,32i)
; vcell64_g[32i](v128x32i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb7,0x79,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b7 79 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<ulong>(Vector128<ulong> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[64u](v128x64u,32i)
; vcell64_g[64u](v128x64u,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x67,0x79,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 67 79 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<long>(Vector128<long> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[64i](v128x64i,32i)
; vcell64_g[64i](v128x64i,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x17,0x79,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 17 79 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<float>(Vector128<float> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[32f](v128x32f,32i)
; vcell64_g[32f](v128x32f,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc7,0x78,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c7 78 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<double>(Vector128<double> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[64f](v128x64f,32i)
; vcell64_g[64f](v128x64f,32i)[49] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x11,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x77,0x78,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0027h                         ; JAE rel8 || 73 cb || encoded[2]{73 11}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0026h ret                                     ; RET || C3 || encoded[1]{c3}
0027h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002ch call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 77 78 08 ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<byte>(Vector128<byte> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[8u](v128x8u,32i)
; vcell32f_g[8u](v128x8u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x26,0x78,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 26 78 08 ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<sbyte>(Vector128<sbyte> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[8i](v128x8i,32i)
; vcell32f_g[8i](v128x8i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd6,0x77,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d6 77 08 ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<ushort>(Vector128<ushort> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[16u](v128x16u,32i)
; vcell32f_g[16u](v128x16u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x86,0x77,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 86 77 08 ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<short>(Vector128<short> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[16i](v128x16i,32i)
; vcell32f_g[16i](v128x16i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x36,0x77,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 36 77 08 ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<uint>(Vector128<uint> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[32u](v128x32u,32i)
; vcell32f_g[32u](v128x32u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe6,0x76,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e6 76 08 ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<int>(Vector128<int> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[32i](v128x32i,32i)
; vcell32f_g[32i](v128x32i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x96,0x76,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 96 76 08 ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<ulong>(Vector128<ulong> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[64u](v128x64u,32i)
; vcell32f_g[64u](v128x64u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x46,0x76,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 46 76 08 ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<long>(Vector128<long> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[64i](v128x64i,32i)
; vcell32f_g[64i](v128x64i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf6,0x75,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f6 75 08 ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<float>(Vector128<float> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[32f](v128x32f,32i)
; vcell32f_g[32f](v128x32f,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa6,0x75,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a6 75 08 ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<double>(Vector128<double> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[64f](v128x64f,32i)
; vcell32f_g[64f](v128x64f,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x56,0x75,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 56 75 08 ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<byte>(Vector128<byte> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[8u](v128x8u,32i)
; vcell64f_g[8u](v128x8u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x06,0x75,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 06 75 08 ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<sbyte>(Vector128<sbyte> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[8i](v128x8i,32i)
; vcell64f_g[8i](v128x8i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb6,0x74,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b6 74 08 ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<ushort>(Vector128<ushort> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[16u](v128x16u,32i)
; vcell64f_g[16u](v128x16u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x66,0x74,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 66 74 08 ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<short>(Vector128<short> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[16i](v128x16i,32i)
; vcell64f_g[16i](v128x16i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x16,0x74,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 16 74 08 ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<uint>(Vector128<uint> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[32u](v128x32u,32i)
; vcell64f_g[32u](v128x32u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc6,0x73,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c6 73 08 ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<int>(Vector128<int> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[32i](v128x32i,32i)
; vcell64f_g[32i](v128x32i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x76,0x73,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 76 73 08 ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<ulong>(Vector128<ulong> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[64u](v128x64u,32i)
; vcell64f_g[64u](v128x64u,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x26,0x73,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 26 73 08 ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<long>(Vector128<long> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[64i](v128x64i,32i)
; vcell64f_g[64i](v128x64i,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd6,0x72,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d6 72 08 ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<float>(Vector128<float> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[32f](v128x32f,32i)
; vcell64f_g[32f](v128x32f,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x86,0x72,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 86 72 08 ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<double>(Vector128<double> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[64f](v128x64f,32i)
; vcell64f_g[64f](v128x64f,32i)[50] = {0x48,0x83,0xec,0x38,0xc5,0xf8,0x77,0xc5,0xf9,0x10,0x01,0xc5,0xf9,0x29,0x44,0x24,0x20,0x83,0xfa,0x02,0x73,0x12,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0x48,0x83,0xc4,0x38,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x36,0x72,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,38h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 38}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd xmm0,[rcx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 01}
000bh vmovapd [rsp+20h],xmm0                  ; VMOVAPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 29 /r || encoded[6]{c5 f9 29 44 24 20}
0011h cmp edx,2                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 02}
0014h jae short 0028h                         ; JAE rel8 || 73 cb || encoded[2]{73 12}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h add rsp,38h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 38}
0027h ret                                     ; RET || C3 || encoded[1]{c3}
0028h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002dh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 36 72 08 ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<byte>(Vector256<byte> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[8u](v256x8u,32i)
; vcell8i_g[8u](v256x8u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd3,0x6d,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d3 6d 08 ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<sbyte>(Vector256<sbyte> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[8i](v256x8i,32i)
; vcell8i_g[8i](v256x8i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x83,0x6d,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 83 6d 08 ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<ushort>(Vector256<ushort> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[16u](v256x16u,32i)
; vcell8i_g[16u](v256x16u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x33,0x6d,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 33 6d 08 ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<short>(Vector256<short> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[16i](v256x16i,32i)
; vcell8i_g[16i](v256x16i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe3,0x6c,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e3 6c 08 ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<uint>(Vector256<uint> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[32u](v256x32u,32i)
; vcell8i_g[32u](v256x32u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x93,0x6c,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 93 6c 08 ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<int>(Vector256<int> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[32i](v256x32i,32i)
; vcell8i_g[32i](v256x32i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x43,0x6c,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 43 6c 08 ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<ulong>(Vector256<ulong> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[64u](v256x64u,32i)
; vcell8i_g[64u](v256x64u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf3,0x6b,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f3 6b 08 ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<long>(Vector256<long> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[64i](v256x64i,32i)
; vcell8i_g[64i](v256x64i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa3,0x6b,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a3 6b 08 ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<float>(Vector256<float> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[32f](v256x32f,32i)
; vcell8i_g[32f](v256x32f,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x53,0x6b,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 53 6b 08 ff}
------------------------------------------------------------------------------------------------------------------------
; sbyte vcell8i<double>(Vector256<double> x, int index), hex://vfuncs/generic?vcell8i#vcell8i_g[64f](v256x64f,32i)
; vcell8i_g[64f](v256x64f,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbe,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x03,0x6b,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,byte ptr [rax+rcx]            ; MOVSX r64, r/m8 || REX.W 0F BE /r || encoded[5]{48 0f be 04 08}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 03 6b 08 ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<byte>(Vector256<byte> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[8u](v256x8u,32i)
; vcell8_g[8u](v256x8u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb4,0x6a,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b4 6a 08 ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<sbyte>(Vector256<sbyte> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[8i](v256x8i,32i)
; vcell8_g[8i](v256x8i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x64,0x6a,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 64 6a 08 ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<ushort>(Vector256<ushort> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[16u](v256x16u,32i)
; vcell8_g[16u](v256x16u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x14,0x6a,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 14 6a 08 ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<short>(Vector256<short> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[16i](v256x16i,32i)
; vcell8_g[16i](v256x16i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc4,0x69,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c4 69 08 ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<uint>(Vector256<uint> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[32u](v256x32u,32i)
; vcell8_g[32u](v256x32u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x74,0x69,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 74 69 08 ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<int>(Vector256<int> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[32i](v256x32i,32i)
; vcell8_g[32i](v256x32i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x24,0x69,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 24 69 08 ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<ulong>(Vector256<ulong> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[64u](v256x64u,32i)
; vcell8_g[64u](v256x64u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd4,0x68,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d4 68 08 ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<long>(Vector256<long> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[64i](v256x64i,32i)
; vcell8_g[64i](v256x64i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x84,0x68,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 84 68 08 ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<float>(Vector256<float> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[32f](v256x32f,32i)
; vcell8_g[32f](v256x32f,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x34,0x68,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 34 68 08 ff}
------------------------------------------------------------------------------------------------------------------------
; byte vcell8<double>(Vector256<double> x, int index), hex://vfuncs/generic?vcell8#vcell8_g[64f](v256x64f,32i)
; vcell8_g[64f](v256x64f,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x20,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb6,0x04,0x08,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe4,0x67,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,20h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 20}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,byte ptr [rax+rcx]            ; MOVZX r32, r/m8 || o32 0F B6 /r || encoded[4]{0f b6 04 08}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e4 67 08 ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<byte>(Vector256<byte> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[8u](v256x8u,32i)
; vcell16i_g[8u](v256x8u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x93,0x67,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 93 67 08 ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<sbyte>(Vector256<sbyte> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[8i](v256x8i,32i)
; vcell16i_g[8i](v256x8i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x43,0x67,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 43 67 08 ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<ushort>(Vector256<ushort> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[16u](v256x16u,32i)
; vcell16i_g[16u](v256x16u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf3,0x66,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f3 66 08 ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<short>(Vector256<short> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[16i](v256x16i,32i)
; vcell16i_g[16i](v256x16i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa3,0x66,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a3 66 08 ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<uint>(Vector256<uint> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[32u](v256x32u,32i)
; vcell16i_g[32u](v256x32u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x53,0x66,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 53 66 08 ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<int>(Vector256<int> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[32i](v256x32i,32i)
; vcell16i_g[32i](v256x32i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x03,0x66,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 03 66 08 ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<ulong>(Vector256<ulong> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[64u](v256x64u,32i)
; vcell16i_g[64u](v256x64u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb3,0x65,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b3 65 08 ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<long>(Vector256<long> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[64i](v256x64i,32i)
; vcell16i_g[64i](v256x64i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x63,0x65,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 63 65 08 ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<float>(Vector256<float> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[32f](v256x32f,32i)
; vcell16i_g[32f](v256x32f,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x13,0x65,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 13 65 08 ff}
------------------------------------------------------------------------------------------------------------------------
; short vcell16i<double>(Vector256<double> x, int index), hex://vfuncs/generic?vcell16i#vcell16i_g[64f](v256x64f,32i)
; vcell16i_g[64f](v256x64f,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x15,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x0f,0xbf,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc3,0x64,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movsx rax,word ptr [rax+rcx*2]          ; MOVSX r64, r/m16 || REX.W 0F BF /r || encoded[5]{48 0f bf 04 48}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c3 64 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<byte>(Vector256<byte> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[8u](v256x8u,32i)
; vcell16_g[8u](v256x8u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x74,0x64,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 74 64 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<sbyte>(Vector256<sbyte> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[8i](v256x8i,32i)
; vcell16_g[8i](v256x8i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x24,0x64,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 24 64 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<ushort>(Vector256<ushort> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[16u](v256x16u,32i)
; vcell16_g[16u](v256x16u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd4,0x63,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d4 63 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<short>(Vector256<short> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[16i](v256x16i,32i)
; vcell16_g[16i](v256x16i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x74,0x5f,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 74 5f 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<uint>(Vector256<uint> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[32u](v256x32u,32i)
; vcell16_g[32u](v256x32u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x24,0x5f,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 24 5f 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<int>(Vector256<int> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[32i](v256x32i,32i)
; vcell16_g[32i](v256x32i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd4,0x5e,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d4 5e 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<ulong>(Vector256<ulong> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[64u](v256x64u,32i)
; vcell16_g[64u](v256x64u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x84,0x5e,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 84 5e 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<long>(Vector256<long> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[64i](v256x64i,32i)
; vcell16_g[64i](v256x64i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x34,0x5e,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 34 5e 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<float>(Vector256<float> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[32f](v256x32f,32i)
; vcell16_g[32f](v256x32f,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe4,0x5d,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e4 5d 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ushort vcell16<double>(Vector256<double> x, int index), hex://vfuncs/generic?vcell16#vcell16_g[64f](v256x64f,32i)
; vcell16_g[64f](v256x64f,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x10,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x0f,0xb7,0x04,0x48,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x94,0x5d,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,10h                             ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 10}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh movzx eax,word ptr [rax+rcx*2]          ; MOVZX r32, r/m16 || o32 0F B7 /r || encoded[4]{0f b7 04 48}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 94 5d 08 ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<byte>(Vector256<byte> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[8u](v256x8u,32i)
; vcell32i_g[8u](v256x8u,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x45,0x5d,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 45 5d 08 ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<sbyte>(Vector256<sbyte> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[8i](v256x8i,32i)
; vcell32i_g[8i](v256x8i,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf5,0x5c,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f5 5c 08 ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<ushort>(Vector256<ushort> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[16u](v256x16u,32i)
; vcell32i_g[16u](v256x16u,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa5,0x5c,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a5 5c 08 ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<short>(Vector256<short> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[16i](v256x16i,32i)
; vcell32i_g[16i](v256x16i,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x55,0x5c,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 55 5c 08 ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<uint>(Vector256<uint> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[32u](v256x32u,32i)
; vcell32i_g[32u](v256x32u,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x05,0x5c,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 05 5c 08 ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<int>(Vector256<int> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[32i](v256x32i,32i)
; vcell32i_g[32i](v256x32i,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb5,0x5b,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b5 5b 08 ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<ulong>(Vector256<ulong> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[64u](v256x64u,32i)
; vcell32i_g[64u](v256x64u,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x65,0x5b,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 65 5b 08 ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<long>(Vector256<long> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[64i](v256x64i,32i)
; vcell32i_g[64i](v256x64i,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x15,0x5b,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 15 5b 08 ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<float>(Vector256<float> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[32f](v256x32f,32i)
; vcell32i_g[32f](v256x32f,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc5,0x5a,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c5 5a 08 ff}
------------------------------------------------------------------------------------------------------------------------
; int vcell32i<double>(Vector256<double> x, int index), hex://vfuncs/generic?vcell32i#vcell32i_g[64f](v256x64f,32i)
; vcell32i_g[64f](v256x64f,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x75,0x5a,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 75 5a 08 ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<byte>(Vector256<byte> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[8u](v256x8u,32i)
; vcell32_g[8u](v256x8u,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x25,0x5a,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 25 5a 08 ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<sbyte>(Vector256<sbyte> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[8i](v256x8i,32i)
; vcell32_g[8i](v256x8i,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd5,0x59,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d5 59 08 ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<ushort>(Vector256<ushort> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[16u](v256x16u,32i)
; vcell32_g[16u](v256x16u,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x85,0x59,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 85 59 08 ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<short>(Vector256<short> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[16i](v256x16i,32i)
; vcell32_g[16i](v256x16i,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x35,0x59,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 35 59 08 ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<uint>(Vector256<uint> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[32u](v256x32u,32i)
; vcell32_g[32u](v256x32u,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe5,0x58,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e5 58 08 ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<int>(Vector256<int> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[32i](v256x32i,32i)
; vcell32_g[32i](v256x32i,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x95,0x58,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 95 58 08 ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<ulong>(Vector256<ulong> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[64u](v256x64u,32i)
; vcell32_g[64u](v256x64u,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x45,0x58,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 45 58 08 ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<long>(Vector256<long> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[64i](v256x64i,32i)
; vcell32_g[64i](v256x64i,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf5,0x57,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f5 57 08 ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<float>(Vector256<float> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[32f](v256x32f,32i)
; vcell32_g[32f](v256x32f,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa5,0x57,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a5 57 08 ff}
------------------------------------------------------------------------------------------------------------------------
; uint vcell32<double>(Vector256<double> x, int index), hex://vfuncs/generic?vcell32#vcell32_g[64f](v256x64f,32i)
; vcell32_g[64f](v256x64f,32i)[51] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x13,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x8b,0x04,0x88,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x55,0x57,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 0029h                         ; JAE rel8 || 73 cb || encoded[2]{73 13}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov eax,[rax+rcx*4]                     ; MOV r32, r/m32 || o32 8B /r || encoded[3]{8b 04 88}
0021h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0024h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0028h ret                                     ; RET || C3 || encoded[1]{c3}
0029h mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002eh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 55 57 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<byte>(Vector256<byte> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[8u](v256x8u,32i)
; vcell64_g[8u](v256x8u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x04,0x57,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 04 57 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<sbyte>(Vector256<sbyte> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[8i](v256x8i,32i)
; vcell64_g[8i](v256x8i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb4,0x56,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b4 56 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<ushort>(Vector256<ushort> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[16u](v256x16u,32i)
; vcell64_g[16u](v256x16u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x64,0x56,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 64 56 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<short>(Vector256<short> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[16i](v256x16i,32i)
; vcell64_g[16i](v256x16i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x14,0x56,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 14 56 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<uint>(Vector256<uint> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[32u](v256x32u,32i)
; vcell64_g[32u](v256x32u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc4,0x55,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c4 55 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<int>(Vector256<int> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[32i](v256x32i,32i)
; vcell64_g[32i](v256x32i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x74,0x55,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 74 55 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<ulong>(Vector256<ulong> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[64u](v256x64u,32i)
; vcell64_g[64u](v256x64u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x24,0x55,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 24 55 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<long>(Vector256<long> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[64i](v256x64i,32i)
; vcell64_g[64i](v256x64i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd4,0x54,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d4 54 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<float>(Vector256<float> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[32f](v256x32f,32i)
; vcell64_g[32f](v256x32f,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x84,0x54,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 84 54 08 ff}
------------------------------------------------------------------------------------------------------------------------
; ulong vcell64<double>(Vector256<double> x, int index), hex://vfuncs/generic?vcell64#vcell64_g[64f](v256x64f,32i)
; vcell64_g[64f](v256x64f,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x34,0x54,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 34 54 08 ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<byte>(Vector256<byte> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[8u](v256x8u,32i)
; vcell64i_g[8u](v256x8u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd4,0x4f,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d4 4f 08 ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<sbyte>(Vector256<sbyte> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[8i](v256x8i,32i)
; vcell64i_g[8i](v256x8i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x84,0x4f,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 84 4f 08 ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<ushort>(Vector256<ushort> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[16u](v256x16u,32i)
; vcell64i_g[16u](v256x16u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x34,0x4f,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 34 4f 08 ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<short>(Vector256<short> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[16i](v256x16i,32i)
; vcell64i_g[16i](v256x16i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe4,0x4e,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e4 4e 08 ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<uint>(Vector256<uint> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[32u](v256x32u,32i)
; vcell64i_g[32u](v256x32u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x94,0x4e,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 94 4e 08 ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<int>(Vector256<int> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[32i](v256x32i,32i)
; vcell64i_g[32i](v256x32i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x44,0x4e,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 44 4e 08 ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<ulong>(Vector256<ulong> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[64u](v256x64u,32i)
; vcell64i_g[64u](v256x64u,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf4,0x4d,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f4 4d 08 ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<long>(Vector256<long> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[64i](v256x64i,32i)
; vcell64i_g[64i](v256x64i,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa4,0x4d,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a4 4d 08 ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<float>(Vector256<float> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[32f](v256x32f,32i)
; vcell64i_g[32f](v256x32f,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x54,0x4d,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 54 4d 08 ff}
------------------------------------------------------------------------------------------------------------------------
; long vcell64i<double>(Vector256<double> x, int index), hex://vfuncs/generic?vcell64i#vcell64i_g[64f](v256x64f,32i)
; vcell64i_g[64f](v256x64f,32i)[52] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x14,0x48,0x8d,0x44,0x24,0x20,0x48,0x63,0xca,0x48,0x8b,0x04,0xc8,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x04,0x4d,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002ah                         ; JAE rel8 || 73 cb || encoded[2]{73 14}
0016h lea rax,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 44 24 20}
001bh movsxd rcx,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 ca}
001eh mov rax,[rax+rcx*8]                     ; MOV r64, r/m64 || REX.W 8B /r || encoded[4]{48 8b 04 c8}
0022h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0025h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
0029h ret                                     ; RET || C3 || encoded[1]{c3}
002ah mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
002fh call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 04 4d 08 ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<byte>(Vector256<byte> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[8u](v256x8u,32i)
; vcell32f_g[8u](v256x8u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb3,0x4c,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b3 4c 08 ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<sbyte>(Vector256<sbyte> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[8i](v256x8i,32i)
; vcell32f_g[8i](v256x8i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x63,0x4c,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 63 4c 08 ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<ushort>(Vector256<ushort> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[16u](v256x16u,32i)
; vcell32f_g[16u](v256x16u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x13,0x4c,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 13 4c 08 ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<short>(Vector256<short> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[16i](v256x16i,32i)
; vcell32f_g[16i](v256x16i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc3,0x4b,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c3 4b 08 ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<uint>(Vector256<uint> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[32u](v256x32u,32i)
; vcell32f_g[32u](v256x32u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x73,0x4b,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 73 4b 08 ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<int>(Vector256<int> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[32i](v256x32i,32i)
; vcell32f_g[32i](v256x32i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x23,0x4b,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 23 4b 08 ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<ulong>(Vector256<ulong> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[64u](v256x64u,32i)
; vcell32f_g[64u](v256x64u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xd3,0x4a,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 d3 4a 08 ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<long>(Vector256<long> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[64i](v256x64i,32i)
; vcell32f_g[64i](v256x64i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x83,0x4a,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 83 4a 08 ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<float>(Vector256<float> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[32f](v256x32f,32i)
; vcell32f_g[32f](v256x32f,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x33,0x4a,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 33 4a 08 ff}
------------------------------------------------------------------------------------------------------------------------
; float vcell32f<double>(Vector256<double> x, int index), hex://vfuncs/generic?vcell32f#vcell32f_g[64f](v256x64f,32i)
; vcell32f_g[64f](v256x64f,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x08,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfa,0x10,0x04,0x81,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xe3,0x49,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,8                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 08}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovss xmm0,dword ptr [rcx+rax*4]       ; VMOVSS xmm1, m32 || VEX.LIG.F3.0F.WIG 10 /r || encoded[5]{c5 fa 10 04 81}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 e3 49 08 ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<byte>(Vector256<byte> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[8u](v256x8u,32i)
; vcell64f_g[8u](v256x8u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x93,0x49,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 93 49 08 ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<sbyte>(Vector256<sbyte> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[8i](v256x8i,32i)
; vcell64f_g[8i](v256x8i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x43,0x49,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 43 49 08 ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<ushort>(Vector256<ushort> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[16u](v256x16u,32i)
; vcell64f_g[16u](v256x16u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xf3,0x48,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 f3 48 08 ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<short>(Vector256<short> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[16i](v256x16i,32i)
; vcell64f_g[16i](v256x16i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xa3,0x48,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 a3 48 08 ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<uint>(Vector256<uint> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[32u](v256x32u,32i)
; vcell64f_g[32u](v256x32u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x53,0x48,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 53 48 08 ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<int>(Vector256<int> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[32i](v256x32i,32i)
; vcell64f_g[32i](v256x32i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x03,0x48,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 03 48 08 ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<ulong>(Vector256<ulong> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[64u](v256x64u,32i)
; vcell64f_g[64u](v256x64u,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xb3,0x47,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 b3 47 08 ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<long>(Vector256<long> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[64i](v256x64i,32i)
; vcell64f_g[64i](v256x64i,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x63,0x47,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 63 47 08 ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<float>(Vector256<float> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[32f](v256x32f,32i)
; vcell64f_g[32f](v256x32f,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0x13,0x47,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 13 47 08 ff}
------------------------------------------------------------------------------------------------------------------------
; double vcell64f<double>(Vector256<double> x, int index), hex://vfuncs/generic?vcell64f#vcell64f_g[64f](v256x64f,32i)
; vcell64f_g[64f](v256x64f,32i)[53] = {0x48,0x83,0xec,0x58,0xc5,0xf8,0x77,0xc5,0xfd,0x10,0x01,0xc5,0xfd,0x11,0x44,0x24,0x20,0x83,0xfa,0x04,0x73,0x15,0x48,0x8d,0x4c,0x24,0x20,0x48,0x63,0xc2,0xc5,0xfb,0x10,0x04,0xc1,0xc5,0xf8,0x77,0x48,0x83,0xc4,0x58,0xc3,0xb9,0x15,0x00,0x00,0x00,0xe8,0xc3,0x46,0x08,0xff}
; TermCode = CTC_INTRx2
0000h sub rsp,58h                             ; SUB r/m64, imm8 || REX.W 83 /5 ib || encoded[4]{48 83 ec 58}
0004h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0007h vmovupd ymm0,[rcx]                      ; VMOVUPD ymm1, ymm2/m256 || VEX.256.66.0F.WIG 10 /r || encoded[4]{c5 fd 10 01}
000bh vmovupd [rsp+20h],ymm0                  ; VMOVUPD ymm2/m256, ymm1 || VEX.256.66.0F.WIG 11 /r || encoded[6]{c5 fd 11 44 24 20}
0011h cmp edx,4                               ; CMP r/m32, imm8 || o32 83 /7 ib || encoded[3]{83 fa 04}
0014h jae short 002bh                         ; JAE rel8 || 73 cb || encoded[2]{73 15}
0016h lea rcx,[rsp+20h]                       ; LEA r64, m || REX.W 8D /r || encoded[5]{48 8d 4c 24 20}
001bh movsxd rax,edx                          ; MOVSXD r64, r/m32 || REX.W 63 /r || encoded[3]{48 63 c2}
001eh vmovsd xmm0,qword ptr [rcx+rax*8]       ; VMOVSD xmm1, m64 || VEX.LIG.F2.0F.WIG 10 /r || encoded[5]{c5 fb 10 04 c1}
0023h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0026h add rsp,58h                             ; ADD r/m64, imm8 || REX.W 83 /0 ib || encoded[4]{48 83 c4 58}
002ah ret                                     ; RET || C3 || encoded[1]{c3}
002bh mov ecx,15h                             ; MOV r32, imm32 || o32 B8+rd id || encoded[5]{b9 15 00 00 00}
0030h call 7ff7c7774ad8h                      ; CALL rel32 || E8 cd || encoded[5]{e8 c3 46 08 ff}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> v8i<byte>(Vector128<byte> x), hex://vfuncs/generic?v8i#v8i_g[8u](v128x8u)
; v8i_g[8u](v128x8u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> v8i<sbyte>(Vector128<sbyte> x), hex://vfuncs/generic?v8i#v8i_g[8i](v128x8i)
; v8i_g[8i](v128x8i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> v8i<ushort>(Vector128<ushort> x), hex://vfuncs/generic?v8i#v8i_g[16u](v128x16u)
; v8i_g[16u](v128x16u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> v8i<short>(Vector128<short> x), hex://vfuncs/generic?v8i#v8i_g[16i](v128x16i)
; v8i_g[16i](v128x16i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> v8i<uint>(Vector128<uint> x), hex://vfuncs/generic?v8i#v8i_g[32u](v128x32u)
; v8i_g[32u](v128x32u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> v8i<int>(Vector128<int> x), hex://vfuncs/generic?v8i#v8i_g[32i](v128x32i)
; v8i_g[32i](v128x32i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> v8i<ulong>(Vector128<ulong> x), hex://vfuncs/generic?v8i#v8i_g[64u](v128x64u)
; v8i_g[64u](v128x64u)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> v8i<long>(Vector128<long> x), hex://vfuncs/generic?v8i#v8i_g[64i](v128x64i)
; v8i_g[64i](v128x64i)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> v8i<float>(Vector128<float> x), hex://vfuncs/generic?v8i#v8i_g[32f](v128x32f)
; v8i_g[32f](v128x32f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
------------------------------------------------------------------------------------------------------------------------
; Vector128<sbyte> v8i<double>(Vector128<double> x), hex://vfuncs/generic?v8i#v8i_g[64f](v128x64f)
; v8i_g[64f](v128x64f)[17] = {0xc5,0xf8,0x77,0x66,0x90,0xc5,0xf9,0x10,0x02,0xc5,0xf9,0x11,0x01,0x48,0x8b,0xc1,0xc3}
; TermCode = CTC_RET_INTR
0000h vzeroupper                              ; VZEROUPPER || VEX.128.0F.WIG 77 || encoded[3]{c5 f8 77}
0003h xchg ax,ax                              ; NOP || o16 90 || encoded[2]{66 90}
0005h vmovupd xmm0,[rdx]                      ; VMOVUPD xmm1, xmm2/m128 || VEX.128.66.0F.WIG 10 /r || encoded[4]{c5 f9 10 02}
0009h vmovupd [rcx],xmm0                      ; VMOVUPD xmm2/m128, xmm1 || VEX.128.66.0F.WIG 11 /r || encoded[4]{c5 f9 11 01}
000dh mov rax,rcx                             ; MOV r64, r/m64 || REX.W 8B /r || encoded[3]{48 8b c1}
0010h ret                                     ; RET || C3 || encoded[1]{c3}
